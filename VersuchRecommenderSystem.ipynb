{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Recommender Systeme\n",
    "\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 30.09.2015\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* __Ähnlichkeit:__ Verfahren zur Bestimmung der Ähnlichkeit zwischen Personen (Kunden) und Elementen (Produkten)\n",
    "* __Empfehlungssysteme__ Collaborative Filtering \n",
    "* __Collaborative Filtering:__ Nutzerbezogener Ansatz und elementbasierter Ansatz\n",
    "\n",
    "Sämtliche Verfahren und Algorithmen werden in Python implementiert.\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "### Recommender Systeme\n",
    "Recommender Systeme werden im E-Commerce eingesetzt um Werbung in Form von kundenspezifischen Empfehlungen zu verteilen. Weitläufig bekannt sind die Amazon-Empfehlungen, die entweder per e-mail geschickt oder nach dem Log-In in der Web-Page angezeigt werden. Diese Empfehlungen werden in Abhängigkeit von den bisher vom jeweiligen Kunden gekauften bzw. bewerteten Produkten erstellt. In diesem Versuch werden die derzeit wohl am weitest verbreiteteten Verfahren für die Erzeugung kundenspezifischer Empfehlungen vorgestellt, darunter das elementweise Collaborative Filtering, welches z.B. auch von Amazon eingesetzt wird.     \n",
    "\n",
    "Direkt-Marketing Methoden wie die kundenspezifische Erzeugung und Bereitstellung von Werbung erfordern detaillierte Kunden- und Warenkorbanalysen. Kunden mit ähnlichem Kaufverhalten werden in Kundengruppen zusammengefasst. Die Warenkorbanalyse untersucht u.a. welche Waren bevorzugt im Verbund von der gleichen Person gekauft werden. Damit kann ein Händler Werbung in Form von Empfehlungen individuell und gezielt an seine Kunden richten, abhängig davon welcher Kundengruppe er angehört und welche Produkte bevorzugt von dieser Kundengruppe nachgefragt werden. \n",
    "\n",
    "Im ersten Teil der Übung werden fiktive Daten in einer überschaubaren Menge verwendet. Es handelt sich hier um Filmbewertungen. Anhand dieses Beispiels sollen die notwendigen Methoden und Abläufe implementiert und getestet werden. Diese werden im zweiten Teil der Übung auf echte Daten angewandt. Hierzu werden über eine Python-API Daten vom Internet-Meta-Radio _last.fm_ integriert. Auf der Basis dieser Daten sollen dann Musikempfehlungen für last.fm User berechnet werden. \n",
    "\n",
    "Recommender Systeme lassen sich mit\n",
    "\n",
    "* Clustering Verfahren\n",
    "* Suchalgorithmen\n",
    "* Collaborativen Filtering \n",
    " \n",
    "realisieren. Am häufigsten wird hierbei das Collaborative Filtering eingesetzt. Für das Collaborative Filtering wird jeder der $M$ User durch einen $N$-dimensionalen Vektor beschrieben, wobei $N$ die Anzahl der Produkte im Angebot des Händlers ist. Jedes Element im Vektor gehört zu einem speziellen Produkt. Das Element hat den Wert 1, wenn der User dieses Produkt bereits gekauft hat, sonst 0 (andere Wertbelegungen sind möglich, z.B. wenn Produktbewertungen vorliegen). Alle $M$ Zeilenvektoren können zur _User/Item_ Matrix zusammengefasst werden (siehe Abbildung).\n",
    "\n",
    "![Abbildung User Item Matrix](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/UserItemMatrix.png \"User Item Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das traditionelle __userbasierte Collaborative Filtering (UCF)__, benutzt die Ähnlichkeit zwischen Benutzern: Um für User $U_i$ eine Empfehlung zu erzeugen wird zunächst der diesem User ähnlichste Kunde (oder eine Menge vom ähnlichsten Kunden) ermittelt. Dann werden $U_i$ die Produkte (Items) empfohlen, welche der ähnlichste Kunde gekauft hat, $U_i$ selbst jedoch noch nicht. \n",
    "\n",
    "Dieser Ansatz skaliert schlecht im Fall sehr großer _User/Item_-Matrizen. Ausserdem ist er für User, welche erst wenige Produkte gekauft haben unzuverlässig. Besser eignet sich in diesen Fällen das __itembasierte Collaborative Filtering (ICF)__. Es wird u.a. von Amazon.com eingesetzt. Diese Variante benutzt die Ähnlichkeit zwischen Produkten (Items). Dabei sind Produkte umso ähnlicher je mehr Kunden diese Produkte gemeinsam gekauft haben. Für die Produkte welche ein Referenzuser $U_i$ bereits gekauft hat, werden die ähnlichsten Produkte ermittelt. Diese ähnlichsten Produkte werden $U_i$ empfohlen, wenn er sie nicht schon selbst gekauft hat.\n",
    "\n",
    "Im folgenden Abschnitt werden einige gebräuchliche Metriken für die Berechnung der Ähnlichkeit zwischen Benutzern oder Artikeln vorgestellt. Für Collaboratives Filtering wird sehr häufig das Cosinus - Ähnlichkeitsmaß eingesetzt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gebräuchliche Ähnlichkeitsmaße\n",
    "\n",
    "Die __euklidische Distanz__ $d_E(\\underline{a},\\underline{b})$ zwischen zwei n-dimensionalen Vektoren $\\underline{a}=(a_1,\\ldots,a_n)$ und $\\underline{b}=(b_1,\\ldots,b_n)$ berechnet sich zu\n",
    "\t$$\n",
    "\td_E(\\underline{a},\\underline{b})=\\sqrt{\\sum_{i=1}^n (a_i-b_i)^2}\n",
    "\t$$\n",
    "Zwei Vektoren können als umso ähnlicher erachtet werden, je kleiner deren euklidische Distanz ist. \n",
    "Ein auf der euklidischen Metrik basierendes Ähnlichkeitsmaß zwischen zwei Vektoren $\\underline{a}$ und $\\underline{b}$ kann durch \n",
    "$$\n",
    "s_E(\\underline{a},\\underline{b})=\\frac{1}{1+d_E(\\underline{a},\\underline{b})}\n",
    "$$\n",
    "angegeben werden.\n",
    "\n",
    "\n",
    "__Pearson Korrelation__\n",
    "Die Ähnlichkeit zwischen zwei Vektoren kann auch durch den Pearson-Korrelationskoeffizient $\\rho_{\\underline{a},\\underline{b}}$ ausgedrückt werden. Er berechnet sich zu\n",
    "$$\n",
    "\\rho_{\\underline{a},\\underline{b}}= \\frac{1}{N}\\cdot \\sum\\limits_{i=1}^{N}\\frac{(a_i-\\overline{a})}{\\sigma_a} \\frac{(b_i-\\overline{b})}{\\sigma_b}\n",
    "$$\n",
    "Dabei bezeichnet $N$ die Länge der Vektoren, $\\overline{a}$ den Mittelwert und $\\sigma_a$ die Standardabweichung des Vektors $\\underline{a}$. \n",
    "\n",
    "Der Pearson-Korrelationskoeffizient misst die lineare Abhängigkeit zwischen zwei Vektoren. Der maximale Wert von $+1$ wird erreicht, wenn die durch die beiden Vektoren definierten N Punkte im 2-dimensionalen Raum auf einer ansteigenden Geraden liegen. Der Minimalwert von $-1$ wird erreicht, wenn die Punkte auf einer abfallenden Geraden liegen. Der Betrag des Koeffizienten ist umso kleiner, je stärker die Punkte von einer fiktiven Geraden (kann durch lineare Regression berechnet werden) abweichen. Der Koeffizient ist $0$ wenn keine lineare Abhängigkeit zwischen den Vektoren besteht.\n",
    "\n",
    "\n",
    "__Cosinus Ähnlichkeitsmaß__\n",
    "Die Ähnlichkeit zwischen zwei Vektoren kann auch durch den Cosinus $\\cos(\\underline{a},\\underline{b})$ ausgedrückt werden. Er berechnet sich zu\n",
    "$$\n",
    "\\cos(\\underline{a},\\underline{b})= \\frac{\\underline{a} \\cdot \\underline{b}}{\\left\\|\\underline{a}\\right\\|\\cdot \\left\\|\\underline{b}\\right\\|}\n",
    "$$\n",
    "wobei im Zähler das Skalarprodukt der beiden Vektoren steht und mit $\\left\\|\\underline{x}\\right\\|$ der Betrag des Vektors $\\underline{x}$ bezeichnet wird.\n",
    "\n",
    "Falls die Vektoren $\\underline{a}$ und $\\underline{b}$ mittelwertfrei sind, ist der Cosinus-Ähnlichkeitswert gleich dem Pearson-Korrelationswert. In der Dokument- und Textanalyse wird vornehmlich das Cosinus-Ähnlichkeitsmaß verwendet. \n",
    "\n",
    "\n",
    "__Russel Rao Ähnlichkeitsmaß__\n",
    "Die Russel Rao-Ähnlichkeit zwischen zwei binären Vektoren $\\underline{a}$ und $\\underline{b}$ mißt das Verhältnis zwischen der Anzahl $\\alpha$ der Stellen in denen beide Vektoren den Wert 1 haben und der Länge $n$ der Vektoren. Z.B. ist für die Vektoren $\\underline{a}=(1,0,1,0,0,1)$ und $\\underline{b}=(0,1,1,1,0,1)$ die Russel-Rao-Ähnlichkeit $s_{RR}(\\underline{a},\\underline{b})=2/6=0.333$.\n",
    "\n",
    "__Jaccard Ähnlichkeitsmaß__\n",
    "Die Jaccard-Ähnlichkeit zwischen zwei binären Vektoren $\\underline{a}$ und $\\underline{b}$ mißt das Verhältnis zwischen der Anzahl $\\alpha$ der Stellen in denen beide Vektoren den Wert $1$ haben und der Anzahl der Stellen in denen mindestens einer der beiden Vektoren ungleich $1$ ist. Z.B. ist für die Vektoren $\\underline{a}=(1,0,1,0,0,1)$ und $\\underline{b}=(0,1,1,1,0,1)$ die Jaccard-Ähnlichkeit $s_{J}(\\underline{a},\\underline{b})=2/5=0.5$. %Die Jaccard Metrik wird in diesem Versuch für die Bestimmung der Ähnlichkeit von _last.fm_-Usern eingesetzt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vor dem Versuch zu klärende Fragen\n",
    "Eine Untermenge der im Folgenden aufgeführten Fragen wird zu Beginn des Versuchs im Rahmen eines Gruppenkolloqs abgefragt. Auf jede Frage sollte von mindestens einem Gruppenmitglied eine Antwort geliefert werden und jedes Gruppenmitglied muss mindestens eine der gestellten Fragen beantworten können.\n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "* Beschreiben Sie das Prinzip des userbasierten Collaborativen Filtering (UCF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Antwort\n",
    "\n",
    "UFC nutzt Änlichkeiten zwischen Nutzern um ihnen Produkte vorzuschlagen. Einem Nutzer werden die von einem ähnlichen Nutzer gekauften Produkte vorgeschlagen.\n",
    "\n",
    "Es werden Kaufverhalten von Benutzergruppen beobachtet, um auf die interessen Einzelner zu schließen.\n",
    "1. Schritt: Suche nach einer Nutzergruppe die ein ähnliches Kaufverhalten wie der aktive Nutzer vorweist. \n",
    "2. Schritt: Verwende die Kaufentscheidungen der Gruppe um Vorhersagungen für den aktiven Nutzer zu treffen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Welche Nachteile hat das UCF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Antwort\n",
    "\n",
    "Bei Nutzern die erst wenig gekauft haben sind die Vorschläge nicht präzise. Außerdem skaliert es schlecht da sehr große Matrize über alle Nutzer und Produkte erstellt werden muss (User/Item Matrizen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Worin besteht der Unterschied zwischen UCF und itembasierten Collaborativen Filtering (ICF)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Antwort\n",
    "\n",
    "Es wird der Betrachrungswinkel geändert.\n",
    "Anders als UFC wird bei IFC die Ähnlichkeit zwischen Produkten genutzt und nicht Ähnlichkeit zwischen Nutzern. Anhand eines Produktes werden ähnlich Produkte vorgeschlagen, ohne dass Nutzer verglichen werden müssen.\n",
    "Die Ähnlichkeit zwischen Produkten werden gemessen, an der häufigkeit der Käufe, die für die Produkte gemeinsam getätigt wurden.\n",
    "\n",
    "##### UFC\n",
    "Bei einem UCF werden Userprofile erzeugt und der jenige der dem aktiven User am ähnlichsten ist zugeschrieben.\n",
    "Das heißt, es werden die Produkte vorgeschlagen, die ein anderer User gekauft hat, man selbst aber nicht.\n",
    "\n",
    "##### ICF\n",
    "ICF fokussiert sich auf Produkte.\n",
    "Es existieren 500 potenzielle Käufer auf der Plattform.\n",
    "300 davon kaufen ein IPhone und davon kaufen 290 User zusätzlich eine Hülle. Dann ergibt das für Produkt IPhone und\n",
    "Produkt Hülle eine Ähnlichkeit die den Produkten zugeschrieben werden. Einem neuen User, der ein IPhone kauft werden nun ähnliche Produkte z. B. die Hülle vorgeschlagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gegeben seien die Vektoren \n",
    "\n",
    "    \\begin{eqnarray*}\n",
    "    \\underline{a} & = & [1,2,3,4,5,6] \\\\\n",
    "    \\underline{b} & = & [3,3,5,6,7,8] \\\\\n",
    "    \\end{eqnarray*}\n",
    "    \n",
    "    Schreiben Sie eine Python Funktion, die den Mittelwert derartiger Vektoren berechnet. Schreiben Sie eine weitere Funktion, die die Varianz berechnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average  A: 3.5             numpy: 3.5\n",
      "average  B: 5.33333333333   numpy: 5.33333333333\n",
      "variance A: 2.91666666667   numpy: 2.91666666667\n",
      "variance B: 3.55555555556   numpy: 3.55555555556\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "vA= [1,2,3,4,5,6]\n",
    "vB= [3,3,5,6,7,8]\n",
    "\n",
    "def avg(vector):\n",
    "    return sum(vector) / float(len(vector))\n",
    "\n",
    "def var(vector):\n",
    "    return sum([(val - avg(vector))**2 for val in vector]) / len(vector)\n",
    "\n",
    "print 'average  A:',avg(vA),'            numpy:', np.mean(vA)\n",
    "print 'average  B:',avg(vB),'  numpy:', np.mean(vB)\n",
    "print 'variance A:',var(vA),'  numpy:', np.var(vA)\n",
    "print 'variance B:',var(vB),'  numpy:', np.var(vB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wie groß ist die\n",
    "\n",
    "    - Euklidische Ähnlichkeit\n",
    "    - Pearson Ähnlichkeit\n",
    "    - Cosinus Ähnlichkeit\n",
    "    \n",
    "    zwischen den Vektoren $\\underline{a}$ und $\\underline{b}$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euklidische Distanz: 4.58257569496     scipy: 4.58257569496\n",
      "\n",
      "Pearson Ähnlichkeit: 0.983343422063    scipy: (0.98334342206285474, 0.0004138517691427288)\n",
      "\n",
      "Cosinus Ähnlichkeit: 0.991060084745\n"
     ]
    }
   ],
   "source": [
    "def euclideanDist(vA,vB):\n",
    "    if (len(vA) != len(vB)): raise ValueError(\"Vectors are not the same size\")\n",
    "    return math.sqrt(sum([(a-b)**2 for a,b in zip(vA,vB)]))\n",
    "\n",
    "def pearsonCorr(vA,vB):\n",
    "    '''\n",
    "    Erklärung: http://www.crashkurs-statistik.de/der-korrelationskoeffizient-nach-pearson/\n",
    "    '''\n",
    "    if (len(vA) != len(vB)): raise ValueError(\"Vectors are not the same size\")\n",
    "        \n",
    "    avgA = avg(vA)\n",
    "    avgB = avg(vB)\n",
    "        \n",
    "    x = [a-(avg(vA)) for a in vA]\n",
    "    y = [b-(avg(vB)) for b in vB]\n",
    "        \n",
    "    z = sum([a*b for a,b in zip(x,y)])\n",
    "        \n",
    "    v = math.sqrt(sum([(a-avgA)**2 for a in vA]))\n",
    "    w = math.sqrt(sum([(b-avgB)**2 for b in vB]))\n",
    "\n",
    "    return z/(v*w)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as dc\n",
    "\n",
    "def cosine(vA, vB):\n",
    "    return 1 - dc.cosine(vA,vB)\n",
    "\n",
    "# eucliddis\n",
    "print 'Euklidische Distanz:', euclideanDist(vA,vB), '    scipy:', dc.euclidean(vA,vB)\n",
    "#print np.linalg.norm(a)\n",
    "# pearson \n",
    "print '\\nPearson Ähnlichkeit:', pearsonCorr(vA,vB), '   scipy:', stats.pearsonr(vA,vB)\n",
    "#print '\\n\\n', np.corrcoef(vA,vB)\n",
    "# cosine\n",
    "print \"\\nCosinus Ähnlichkeit:\", cosine(vA,vB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In welchen Fällen sind Cosinus- und Pearsonähnlichkeit der euklidischen Ähnlichkeit vorzuziehen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Antwort\n",
    "Die euklidische Distanz besitz die Eigenschaft, dass Sie nur Auskunft über die absolute Ähnlichkeit treffen kann.\n",
    "Desto kleiner der Abstand desto ähnlicher die Daten.\n",
    "\n",
    "In fällen in denen wir nur wissen wollen ob sich Werte gleich verändern, sollte Cosinus oder Pearson genutz werden.\n",
    "Sie haben die eigenschaft nicht von skalierung oder linearer verschiebung der Daten beeinflusst zu werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex\n",
    "from IPython.display import Image\n",
    "import pylast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versuchsdurchführung\n",
    "## Teil 1: Fiktive Filmbewertung\n",
    "### Daten\n",
    "Folgende Tabelle enthält die Filmbewertungen von 7 Personen.\n",
    "from IPython.display import Latex\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "![Abbildung Bewertung Fiktive Kunden](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining/Bilder/recommenderFilmRecommendations.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Tabelle ist als Python dictionary _critics_ implementiert. Die Keys des Python-Dictionary definieren die Namen von Personen (Zeilen in der Matrix), die Filme bewertet haben. Die Values sind selbst wieder Dictionarys, welche als Keys die Filmnamen (Spalten in der Matrix) und als Values die jeweilige Filmbewertung (Matrixelment) enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics={\n",
    "    'Lisa Rose': \n",
    "        {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5,\n",
    " 'Just My Luck': 3.0, 'Superman Returns': 3.5, 'You, Me and Dupree': 2.5, \n",
    " 'The Night Listener': 3.0},\n",
    "    'Gene Seymour': \n",
    "        {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5, \n",
    " 'Just My Luck': 1.5, 'Superman Returns': 5.0, 'The Night Listener': 3.0, \n",
    " 'You, Me and Dupree': 3.5},\n",
    "    'Michael Phillips': \n",
    "        {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.0,\n",
    " 'Superman Returns': 3.5, 'The Night Listener': 4.0},\n",
    "    'Claudia Puig': \n",
    "        {'Snakes on a Plane': 3.5, 'Just My Luck': 3.0,\n",
    " 'The Night Listener': 4.5, 'Superman Returns': 4.0, \n",
    " 'You, Me and Dupree': 2.5},\n",
    "    'Mick LaSalle': \n",
    "        {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0, \n",
    " 'Just My Luck': 2.0, 'Superman Returns': 3.0, 'The Night Listener': 3.0,\n",
    " 'You, Me and Dupree': 2.0}, \n",
    "    'Jack Matthews': \n",
    "        {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0,\n",
    " 'The Night Listener': 3.0, 'Superman Returns': 5.0, 'You, Me and Dupree': 3.5},\n",
    "    'Toby': \n",
    "        {'Snakes on a Plane':4.5,'You, Me and Dupree':1.0,'Superman Returns':4.0}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ähnlichkeiten berechnen\n",
    "\n",
    "Für die Bestimmung der Ähnlichkeit zwischen Personen und Produkten werden in diesem Versuch ein auf der euklidischen Distanz basierendes Ähnlichkeitsmaß und die Pearson-Korrelation verwendet. Beide Ähnlichkeitsmaße sind in den unten definierten Funktionen implementiert. Alle drei hier implementierten Funktionen zur Berechnung der Ähnlichkeit erhalten als Übergabeparameter das oben definierte Dictionary, das die Filmbewertungen enthält und die Namen der zwei Personen, die verglichen werden sollen. \n",
    "\n",
    "Zu beachten ist, dass in beiden Funktionen für die Berechnung der Ähnlichkeit zwischen zwei Personen nur die Produkte berücksichtigt werden, welche von beiden Personen schon bewertet wurden. Es handelt sich hier also um modifizierte Ähnlichkeitsfunktionen. \n",
    "\n",
    "__Aufgabe:__\n",
    "Fragen Sie von diesem Dictionary _Toby's_ Bewertung des Films _Snakes on a Plane_ ab und geben Sie diesen Wert aus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toby's critic: 4.5\n"
     ]
    }
   ],
   "source": [
    "#Your Code\n",
    "print \"Toby's critic:\",critics['Toby']['Snakes on a Plane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial.distance as sci\n",
    "\n",
    "\n",
    "def sim_euclid(prefs,person1,person2,normed=True):\n",
    "  ''' Returns a euclidean-distance-based similarity score for \n",
    "  person1 and person2. In the distance calculation the sum is computed \n",
    "  only over those items, which are nonzero for both instances, i.e. only\n",
    "  films which are ranked by both persons are regarded.\n",
    "  If the parameter normed is True, then the euclidean distance is divided by\n",
    "  the number of non-zero elements integrated in the distance calculation. Thus\n",
    "  the effect of larger distances in the case of an increasing number of commonly ranked\n",
    "  items is avoided.\n",
    "  '''\n",
    "  # Get the list of shared_items\n",
    "  si={}\n",
    "  for item in prefs[person1]: \n",
    "    if item in prefs[person2]: si[item]=1\n",
    "  # len(si) counts the number of common ratings\n",
    "  # if they have no ratings in common, return 0\n",
    "  if len(si)==0: return 0\n",
    "\n",
    "  # Add up the squares of all the differences\n",
    "  sum_of_squares=np.sqrt(sum([pow(prefs[person1][item]-prefs[person2][item],2) \n",
    "                     for item in prefs[person1] if item in prefs[person2]]))\n",
    "  if normed:\n",
    "     sum_of_squares= 1.0/len(si)*sum_of_squares\n",
    "  return 1/(1+sum_of_squares)\n",
    "\n",
    "\n",
    "def sim_pearson(prefs,p1,p2):\n",
    "  '''\n",
    "  Returns the Pearson correlation coefficient for p1 and p2\n",
    "  '''\n",
    "    \n",
    "  # Get the list of commonly rated items\n",
    "  si={}\n",
    "  for item in prefs[p1]: \n",
    "    if item in prefs[p2]: si[item]=1\n",
    "\n",
    "  # if they are no ratings in common, return 0\n",
    "  if len(si)==0: return 0\n",
    "\n",
    "  # Sum calculations\n",
    "  n=len(si)\n",
    "  \n",
    "  # Calculate means of person 1 and 2\n",
    "  mp1=np.mean([prefs[p1][it] for it in si])\n",
    "  mp2=np.mean([prefs[p2][it] for it in si])\n",
    "  \n",
    "  # Calculate standard deviation of person 1 and 2\n",
    "  sp1=np.std([prefs[p1][it] for it in si])\n",
    "  sp2=np.std([prefs[p2][it] for it in si])\n",
    "  \n",
    "  # If all elements in one sample are identical, the standard deviation is 0. \n",
    "  # In this case there is no linear correlation between the samples\n",
    "  if sp1==0 or sp2==0:\n",
    "      return 0\n",
    "  r=1/(n*sp1*sp2)*sum([(prefs[p1][it]-mp1)*(prefs[p2][it]-mp2) for it in si])\n",
    "  return r\n",
    "\n",
    "\n",
    "def sim_RusselRao(prefs,person1,person2,normed=True):\n",
    "  ''' Returns RusselRao similaritiy between 2 users. The RusselRao similarity just counts the number\n",
    "  of common non-zero components of the two vectors and divides this number by N, where N is the length\n",
    "  of the vectors. If normed=False, the division by N is omitted.\n",
    "  '''\n",
    "  # Get the list of shared_items\n",
    "  si={}\n",
    "  commons=0\n",
    "  for item in prefs[person1]: \n",
    "    if prefs[person1][item]==1 and prefs[person2][item]==1:   \n",
    "        commons+=1\n",
    "  #print commons\n",
    "  if not normed:\n",
    "      return commons\n",
    "  else:\n",
    "      return commons*1.0/len(prefs[person1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:**\n",
    "1. Geben Sie die euklidische Ähnlichkeit und die Pearson Ähnlichkeit zwischen den Personen _Toby_ und _Lisa Rose_ aus.\n",
    "2. Diskutieren Sie die unterschiedlichen Ähnlichkeitswert\n",
    "3. Welches Ähnlichkeitsmaß erscheint Ihnen für diese Anwendung am besten geeignet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1 ###\n",
      "Euklidische Distanz (Toby,Lisa): 0.615911621789\n",
      "Pearson Distanz (Toby,Lisa): 0.991240707162\n",
      "\n",
      "\n",
      "### 2,3 ###\n",
      "sim_euclid:\n",
      "   /\\ <-> \\/       : 0.633974596216\n",
      "   /\\ <-> /\\+1     : 0.633974596216\n",
      "\n",
      "sim_pearson\n",
      "   /\\ <-> \\/       : -1.0\n",
      "   /\\ <-> /\\+1     : 1.0\n",
      "   /\\ <-> (/\\+1)*2 : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSomit gibt sich trotz der verschiedenen Formen der Kurven beim euklidischen Abstand der exakt gleiche Wert, \\nda die Summe der Abst\\xc3\\xa4nde gleich ist.\\n\\nIm gegensatz dazu liefert Pearson 1 und -1, wobei 1 eine absolute \\xc3\\x84hnlichkeit darstellt \\nund -1 keine \\xc3\\x84hnlichkeit darstellt.\\nPearson ignoriert somit Skalierung und lineare Verschiebung der Daten.\\n'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "print '### 1 ###'\n",
    "print \"Euklidische Distanz (Toby,Lisa):\", sim_euclid(critics, 'Toby', 'Lisa Rose')\n",
    "print \"Pearson Distanz (Toby,Lisa):\", sim_pearson(critics, 'Toby', 'Lisa Rose')\n",
    "print '\\n'\n",
    "\n",
    "\n",
    "#2,3\n",
    "print '### 2,3 ###'\n",
    "'''\n",
    "Die Euklidische Distanz macht hier wenig Sinn,\n",
    "da sie nur den Absoluten Wert der Unterschiede der Attribute betrachtet.\n",
    "Dies lässt sich am folgenden beispiel beobachten.\n",
    "\n",
    "Gegeben sind die Werte: [1,2,1],[2,1,2],[2,3,2]\n",
    "'''\n",
    "dic1 = { '1':1, '2':2, '3':1} # graph: /\\\n",
    "dic2 = { '1':2, '2':1, '3':2} # graph: \\/\n",
    "dic3 = { '1':2, '2':3, '3':2} # graph: /\\+1\n",
    "dic4 = { '1':4, '2':6, '3':4} # graph: (/\\+1)*2\n",
    "\n",
    "dic = {'dic1':dic1, 'dic2':dic2, 'dic3':dic3, 'dic4':dic4}\n",
    "\n",
    "#daraus ergeben sich folgende Ähnlichkeiten\n",
    "\n",
    "print 'sim_euclid:'\n",
    "print '   /\\\\ <-> \\\\/       :', sim_euclid(dic, 'dic1', 'dic2') # 0.633974596216\n",
    "print '   /\\\\ <-> /\\\\+1     :', sim_euclid(dic, 'dic1', 'dic3') # 0.633974596216\n",
    "print ''\n",
    "print 'sim_pearson' \n",
    "print '   /\\\\ <-> \\\\/       :', sim_pearson(dic, 'dic1', 'dic2') # -1.0\n",
    "print '   /\\\\ <-> /\\\\+1     :', sim_pearson(dic, 'dic1', 'dic3') # 1.0\n",
    "print '   /\\\\ <-> (/\\\\+1)*2 :', sim_pearson(dic, 'dic1', 'dic4') # 1.0\n",
    "\n",
    "'''\n",
    "Somit gibt sich trotz der verschiedenen Formen der Kurven beim euklidischen Abstand der exakt gleiche Wert, \n",
    "da die Summe der Abstände gleich ist.\n",
    "\n",
    "Im gegensatz dazu liefert Pearson 1 und -1, wobei 1 eine absolute Ähnlichkeit darstellt \n",
    "und -1 keine Ähnlichkeit darstellt.\n",
    "Pearson ignoriert somit Skalierung und lineare Verschiebung der Daten.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Aufgabe:__\n",
    "0. Schreiben Sie eine Funktion _topMatches(prefs,person,similarity)_, welche für eine beliebige in _critics_ enthaltene Person die Ähnlichkeitswerte zu allen anderen Personen berechnet und in einer geordneten Liste zurück gibt. Der Funktion soll als Übergabeparameter auch die anzuwendende Ähnlichkeitsfunktion (_sim_euclid_ oder _sim_pearson_) übergeben werden können. Berechnen Sie mit dieser Funktion für jede Person die _top matches_, zunächst unter Verwendung der euklidischen- dann unter Verwendung der Pearson-Ähnlichkeit.\n",
    "1. Geben Sie mit der implementierten Funktion die _top matches_ der Person Toby aus.\n",
    "2. Vergleichen Sie die beiden Ähnlichkeitsmaße. Welches Ähnlichkeitsmaß erscheint Ihnen für diesen Anwendungsfall sinnvoller und warum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1 ###\n",
      "\n",
      "topMatches euklidean:\n",
      "\n",
      "Jack Matthews \n",
      "##################################\n",
      "Gene Seymour      : 0.909090909091  \n",
      "Lisa Rose         : 0.720825488681  \n",
      "Mick LaSalle      : 0.666666666667  \n",
      "Claudia Puig      : 0.653453793544  \n",
      "Michael Phillips  : 0.653453793544  \n",
      "Toby              : 0.522774424948  \n",
      "\n",
      "Mick LaSalle \n",
      "##################################\n",
      "Lisa Rose         : 0.809256430169  \n",
      "Michael Phillips  : 0.716699605901  \n",
      "Gene Seymour      : 0.697830520748  \n",
      "Claudia Puig      : 0.696432229193  \n",
      "Jack Matthews     : 0.666666666667  \n",
      "Toby              : 0.666666666667  \n",
      "\n",
      "Claudia Puig \n",
      "##################################\n",
      "Michael Phillips  :  0.77599076226  \n",
      "Lisa Rose         : 0.759746926648  \n",
      "Mick LaSalle      : 0.696432229193  \n",
      "Gene Seymour      : 0.662294660325  \n",
      "Jack Matthews     : 0.653453793544  \n",
      "Toby              : 0.624638797705  \n",
      "\n",
      "Lisa Rose \n",
      "##################################\n",
      "Mick LaSalle      : 0.809256430169  \n",
      "Michael Phillips  : 0.781550104746  \n",
      "Claudia Puig      : 0.759746926648  \n",
      "Jack Matthews     : 0.720825488681  \n",
      "Gene Seymour      : 0.714462989424  \n",
      "Toby              : 0.615911621789  \n",
      "\n",
      "Toby \n",
      "##################################\n",
      "Mick LaSalle      : 0.666666666667  \n",
      "Claudia Puig      : 0.624638797705  \n",
      "Lisa Rose         : 0.615911621789  \n",
      "Michael Phillips  : 0.558481559888  \n",
      "Jack Matthews     : 0.522774424948  \n",
      "Gene Seymour      : 0.510874706924  \n",
      "\n",
      "Gene Seymour \n",
      "##################################\n",
      "Jack Matthews     : 0.909090909091  \n",
      "Lisa Rose         : 0.714462989424  \n",
      "Mick LaSalle      : 0.697830520748  \n",
      "Michael Phillips  : 0.673798637354  \n",
      "Claudia Puig      : 0.662294660325  \n",
      "Toby              : 0.510874706924  \n",
      "\n",
      "Michael Phillips \n",
      "##################################\n",
      "Lisa Rose         : 0.781550104746  \n",
      "Claudia Puig      :  0.77599076226  \n",
      "Mick LaSalle      : 0.716699605901  \n",
      "Gene Seymour      : 0.673798637354  \n",
      "Jack Matthews     : 0.653453793544  \n",
      "Toby              : 0.558481559888  \n",
      "\n",
      "topMatches pearson:\n",
      "\n",
      "Jack Matthews \n",
      "##################################\n",
      "Gene Seymour      : 0.963795681876  \n",
      "Lisa Rose         : 0.747017880834  \n",
      "Toby              :  0.66284898036  \n",
      "Mick LaSalle      : 0.211288563682  \n",
      "Michael Phillips  : 0.134839972493  \n",
      "Claudia Puig      : 0.0285714285714  \n",
      "\n",
      "Mick LaSalle \n",
      "##################################\n",
      "Toby              : 0.924473451642  \n",
      "Lisa Rose         : 0.594088525786  \n",
      "Claudia Puig      : 0.566946709514  \n",
      "Gene Seymour      : 0.411764705882  \n",
      "Jack Matthews     : 0.211288563682  \n",
      "Michael Phillips  : -0.258198889747  \n",
      "\n",
      "Claudia Puig \n",
      "##################################\n",
      "Michael Phillips  :            1.0  \n",
      "Toby              : 0.893405147442  \n",
      "Mick LaSalle      : 0.566946709514  \n",
      "Lisa Rose         : 0.566946709514  \n",
      "Gene Seymour      : 0.314970394174  \n",
      "Jack Matthews     : 0.0285714285714  \n",
      "\n",
      "Lisa Rose \n",
      "##################################\n",
      "Toby              : 0.991240707162  \n",
      "Jack Matthews     : 0.747017880834  \n",
      "Mick LaSalle      : 0.594088525786  \n",
      "Claudia Puig      : 0.566946709514  \n",
      "Michael Phillips  : 0.404519917478  \n",
      "Gene Seymour      : 0.396059017191  \n",
      "\n",
      "Toby \n",
      "##################################\n",
      "Lisa Rose         : 0.991240707162  \n",
      "Mick LaSalle      : 0.924473451642  \n",
      "Claudia Puig      : 0.893405147442  \n",
      "Jack Matthews     :  0.66284898036  \n",
      "Gene Seymour      : 0.381246425832  \n",
      "Michael Phillips  :           -1.0  \n",
      "\n",
      "Gene Seymour \n",
      "##################################\n",
      "Jack Matthews     : 0.963795681876  \n",
      "Mick LaSalle      : 0.411764705882  \n",
      "Lisa Rose         : 0.396059017191  \n",
      "Toby              : 0.381246425832  \n",
      "Claudia Puig      : 0.314970394174  \n",
      "Michael Phillips  : 0.204598301841  \n",
      "\n",
      "Michael Phillips \n",
      "##################################\n",
      "Claudia Puig      :            1.0  \n",
      "Lisa Rose         : 0.404519917478  \n",
      "Gene Seymour      : 0.204598301841  \n",
      "Jack Matthews     : 0.134839972493  \n",
      "Mick LaSalle      : -0.258198889747  \n",
      "Toby              :           -1.0  \n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import operator\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=1)\n",
    "\n",
    "### 1 ###\n",
    "print '### 1 ###\\n'\n",
    "def topMatches(prefs, person, function):\n",
    "    mapOfSimilarities = {}\n",
    "    for personName, items in prefs.items():\n",
    "        if personName != person:\n",
    "            mapOfSimilarities[personName] = function(prefs, person, personName)\n",
    "    return collections.OrderedDict(sorted(mapOfSimilarities.items(), key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "print 'topMatches euklidean:'\n",
    "for k,v in critics.items():\n",
    "    print '\\n',k, '\\n##################################'\n",
    "    for k1,v1 in topMatches(critics, k, sim_euclid).items(): print '%-16s ' % k1 ,':', '%14s ' % v1,'\\n', \n",
    "    \n",
    "    \n",
    "print '\\ntopMatches pearson:'\n",
    "for k,v in critics.items():\n",
    "    print '\\n',k, '\\n##################################'\n",
    "    for k1,v1 in topMatches(critics, k, sim_pearson).items(): print '%-16s ' % k1 ,':', '%14s ' % v1,'\\n',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 2 ###\n",
      "topMatches euklidean Toby:\n",
      "[('Mick LaSalle', 0.66666666666666663), ('Claudia Puig', 0.62463879770504627), ('Lisa Rose', 0.615911621788925), ('Michael Phillips', 0.55848155988774706), ('Jack Matthews', 0.52277442494833892), ('Gene Seymour', 0.51087470692394266)]\n",
      "topMatches pearson Toby:\n",
      "[('Lisa Rose', 0.99124070716193025), ('Mick LaSalle', 0.92447345164190509), ('Claudia Puig', 0.89340514744156441), ('Jack Matthews', 0.66284898035987028), ('Gene Seymour', 0.38124642583151169), ('Michael Phillips', -1.0)]\n"
     ]
    }
   ],
   "source": [
    "### 2 ###\n",
    "print '\\n### 2 ###'\n",
    "print 'topMatches euklidean Toby:\\n', topMatches(critics, 'Toby', sim_euclid).items()\n",
    "print 'topMatches pearson Toby:\\n', topMatches(critics, 'Toby', sim_pearson).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### 3 ###\n",
      "overlapping values:\n",
      "\n",
      "Toby\n",
      "     {'Snakes on a Plane': 4.5, 'Superman Returns': 4.0, 'You, Me and Dupree': 1.0}\n",
      "\n",
      "topmatch euklid: Mick LaSalle 0.666666666667 \n",
      "     {'Snakes on a Plane': 4.0, 'Superman Returns': 3.0, 'You, Me and Dupree': 2.0}\n",
      "\n",
      "topmatch pearson: Lisa Rose 0.991240707162 \n",
      "     {'Snakes on a Plane': 3.5, 'Superman Returns': 3.5, 'You, Me and Dupree': 2.5}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAD8CAYAAACo9anUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpFIJBrOf/OLca2nzhvuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118503a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 3 ###\n",
    "print '\\n### 3 ###'\n",
    "\n",
    "'''\n",
    "> Vergleichen Sie die beiden Ähnlichkeitsmaße. \n",
    "Welches Ähnlichkeitsmaß erscheint Ihnen für diesen Anwendungsfall sinnvoller und warum?\n",
    "\n",
    "Die Frage, die wir uns hierfür stellen müssen ist, was für Ähnlichkeiten für die Applikation wichtig sind.\n",
    "\n",
    "Die unterschiede der beiden Ähnlichkeitsfunktionen ist bereits in Aufgabe 1.3. erklärt.\n",
    "Hier nochmal eine Zusammenfassung:\n",
    "\n",
    "* Wenn der tatsächliche Unterschied der Werte der Attribute wichtig ist,\n",
    "  dann nutzen wir die euklidische Ähnlichkeitsfunktion.\n",
    "\n",
    "* Wenn wir allerdings einen Trend oder Formähnlichkeit (relative Ähnlichkeit) aller Werte suchen,\n",
    "  nutzen wir die Pearson-Ähnlichkeitsfunktion.\n",
    "\n",
    "Für unsere Anwendung nutzen wir die Pearson-Ähnlichkeitsfunktion.\n",
    "In dem Fall der Filmempfehlung, ist der euklidische Abstand nicht nützlich,\n",
    "da er nur den absoluten abstand der graphen betrachtet.\n",
    "Wichtiger ist es hier relative Charakteristika zwischen den Werten für die Ähnlichkeit zu nutzen.\n",
    "\n",
    "Im unten geplotteten Diagramm sieht man deutlich, dass Lisa Rose's Graph, Toby's Graph ähnlicher ist\n",
    "als Mick LaSelle'S. Zwar ist der absolute Abstand zwischen Mick LaSelle und Toby kleiner \n",
    "aber bei Toby und Lisa ist der Graph von links nach rechts, erst flacher dann steiler abfalled.\n",
    "'''\n",
    "\n",
    "print 'overlapping values:'\n",
    "\n",
    "toby = critics['Toby']\n",
    "print '\\nToby\\n    ', toby\n",
    "\n",
    "micksalle = {i:j for i,j in critics['Mick LaSalle'].items() if i in critics['Toby']}\n",
    "print '\\ntopmatch euklid: Mick LaSalle', topMatches(critics, 'Toby', sim_euclid).items()[0][1], '\\n    ', micksalle\n",
    "\n",
    "lisarose = {i:j for i,j in critics['Lisa Rose'].items() if i in critics['Toby']}\n",
    "print '\\ntopmatch pearson: Lisa Rose', topMatches(critics, 'Toby', sim_pearson).items()[0][1], '\\n    ', lisarose\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.plot(range(len(toby)), toby.values(), label='Toby')\n",
    "plt.plot(range(len(micksalle)), micksalle.values(), label='Mick LaSalle')\n",
    "plt.plot(range(len(lisarose)), lisarose.values(), label='Lisa Rose')\n",
    "plt.legend()\n",
    "plt.xticks(range(len(toby)), toby.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Aufgabe:__\n",
    "Schreiben Sie eine Funktion _getRecommendations(prefs,person,similarity)_, mit der die Empfehlungswerte berechnet werden können und bestimmen Sie die Empfehlungswerte für Toby. Der Funktion wird  \n",
    "\n",
    "* das Dictionary _critics_ mit den Filmbewertungen, \n",
    "* der Name der Person, für welche Empfehlungen berechnet werden sollen\n",
    "* die Methode für die Berechnung der Ähnlichkeit _sim_euclid_ oder _sim_pearson_\n",
    "\n",
    "übergeben. Die Methode soll eine geordnete Liste zurück geben. Jedes Listenelement enthält an erster Stelle den berechneten Empfehlungswert und an zweiter Stelle den Namen des Films. Die Liste soll nach Empfehlungswerten absteigend geordnet sein.\n",
    "\n",
    "Testen Sie diese Funktion indem Sie die Empfehlungen für _Toby_ berechnen und mit den Werten in der oben aufgeführten Tabelle vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_for_item(prefs, person, item, similarity):\n",
    "    korrelations = topMatches(prefs, person, similarity)\n",
    "    item_sum = 0.0 \n",
    "    for person_name, items in prefs.items():\n",
    "        if person_name != person and korrelations[person_name]> 0:\n",
    "            try:\n",
    "                item_sum = item_sum + korrelations[person_name]*items[item]\n",
    "            except KeyError:\n",
    "                item_sum = item_sum\n",
    "    return item_sum\n",
    "\n",
    "def korrelation_sum(prefs, person, movie_name, similarity):\n",
    "    korrelation_sum= 0.0\n",
    "    korrelations = topMatches(prefs, person, similarity)\n",
    "    for person_name, korrelation in korrelations.items():\n",
    "        if person_name != person and korrelations[person_name]> 0 and has_evaluated_movie(prefs, person_name, movie_name):            \n",
    "            korrelation_sum = korrelation_sum + korrelation            \n",
    "    return korrelation_sum\n",
    "\n",
    "def has_evaluated_movie(prefs, person, movie_name):\n",
    "    for person_name, movies in prefs.items():\n",
    "        if person == person_name and movie_name in movies:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_seen_movies(prefs, person):\n",
    "    ''' Returns list of known movies of a User '''\n",
    "    try: \n",
    "        return prefs[person].keys()\n",
    "    except KeyError:\n",
    "        return list()\n",
    "\n",
    "def get_all_items(prefs):\n",
    "    all_items = list()\n",
    "    for person, items in prefs.items():\n",
    "        all_items.extend(items.keys())\n",
    "    return set(all_items)\n",
    "\n",
    "def get_recommended(prefs, person, item, similarity):\n",
    "    return round(sum_for_item(prefs, person, item, similarity) / korrelation_sum(prefs, person, item, similarity), 20)\n",
    "\n",
    "def getRecommendations(prefs, person, similarity):\n",
    "    recommendations = {}\n",
    "    known_items = get_seen_movies(prefs, person)\n",
    "    all_items = get_all_items(prefs)\n",
    "    for movie_name in all_items:\n",
    "        if movie_name not in known_items:\n",
    "            recommendations[movie_name]=get_recommended(prefs, person, movie_name, similarity)\n",
    "    return sorted(recommendations.items(), key=operator.itemgetter(1), reverse=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson:  \n",
      "[('The Night Listener', 3.3477895267131013), ('Lady in the Water', 2.8325499182641622), ('Just My Luck', 2.5309807037655645)]\n"
     ]
    }
   ],
   "source": [
    "print \"Pearson: \", '\\n', getRecommendations(critics, 'Toby', sim_pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Berechnung von Empfehlungen mit User basiertem Collaborative Filtering\n",
    "Für die Produkte, die von einer Person noch nicht gekauft wurden, sollen Empfehlungen berechnet werden. Die Empfehlungen können ebenfalls Werte zwischen 1 (wird nicht empfohlen) und 5 (wird stark empfohlen) annehmen. Für die Berechnung der Empfehlung werden die Bewertungen des jeweiligen Produkts durch die anderen Personen herangezogen. Dabei werden die Bewertungen der ähnlichen Personen (d.h. hoher Pearson-Korrelationswert) stärker mit einbezogen als die Bewertungen durch Personen mit einem niedrigen Korrelationswert.\n",
    "\n",
    "__Beispiel:__\n",
    "Toby hat die Filme _The Night Listener_, _Lady in the Water_ und _Just My Luck_ noch nicht gekauft. Für diese Filme soll für Toby eine Empfehlung berechnet werden.\n",
    "In der unten aufgeführten Tabelle enthält die zweite Spalte die _Pearson-Ähnlichkeitswerte_ zwischen Toby und den anderen Personen. Die Spalten 3, 5 und 7 enthalten die Bewertungen der Filme _The Night Listener_, _Lady in the Water_ und _Just My Luck_ durch die anderen Personen. Die Spalten 4, 6 und 8 enthalten die jeweilige Filmbewertung gewichtet (mulipliziert) mit den Ähnlichkeitswerten der jeweiligen Person. Es fällt auf, dass in der Tabelle _Michael_ nicht enthalten ist. Das liegt daran, dass _Michael_ und _Toby_ einen negativen Ähnlichkeitswert aufweisen, d.h. deren Interessen sind gegenläufig. Personen mit negativem Ähnlichkeitswert sollten für Empfehlungen nicht berücksichtigt werden.\n",
    "Die Zeile _Sum_ enthält die Summe aller gewichteten Bewertungen. Aus diesem Wert allein kann die Empfehlung noch nicht abgeleitet werden, da Filme die nur von wenigen Personen bewertet wurden, eine relativ kleine Summe ergeben. Deshalb sollte _Sum_ noch durch die Anzahl der Bewertungen für diesen Film geteilt werden. Oder besser: Nicht durch die Summe der Bewertungen, sondern durch die Summe der relevanten Ähnlichkeitswerte (_KSum_). Der resultierende Empfehlungswert ist in der letzten Zeile eingetragen.\n",
    "\n",
    "\n",
    "![Abbildung Calculate Recommendation](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining/Bilder/recommenderFilmCalculation.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Toby:  \n",
      "[('The Night Listener', 3.3477895267131013), ('Lady in the Water', 2.8325499182641622), ('Just My Luck', 2.5309807037655645)]\n",
      "\n",
      "Euclid Toby:  \n",
      "[('The Night Listener', 3.4273481378103883), ('Lady in the Water', 2.795737031164006), ('Just My Luck', 2.407392750287351)]\n"
     ]
    }
   ],
   "source": [
    "print \"Pearson Toby: \", '\\n', getRecommendations(critics, 'Toby', sim_pearson)\n",
    "print ''\n",
    "print \"Euclid Toby: \", '\\n', getRecommendations(critics, 'Toby', sim_euclid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Berechnung von Empfehlungen mit Item basiertem Collaborative Filtering\n",
    "In den vorigen Aufgaben wurden Ähnlichkeiten zwischen Personen bestimmt und für Produktempfehlungen benutzt (User basiertes Collaborative Filtering). Jetzt soll die Ähnlichkeit zwischen Produkten berechnet werden und auf der Basis dieser Produktähnlichkeit Empfehlungen berechnet werden (Item basiertes Collaborative Filtering).\n",
    "\n",
    "Dabei sollen die bereits implementierten Ähnlichkeitsfunktion _sim_euclid_ und _sim_pearson_ sowie die Ähnlichkeeits-Sortierfunktion _topMatches_ unverändert eingesetzt werden.\n",
    "\n",
    "__Aufgabe:__\n",
    "\n",
    "1. Implementieren Sie eine Funktion, welche das Bewertungsdictionary _critics_derart transformiert, dass die Funktionen _sim_euclid_, _sim_pearson_ und _topMatches_ für das Item basierte CF unverändert eingesetzt werden können. Die transformierte Matrix soll unter dem Namen _transCritics_ abgespeichert werden.\n",
    "2. Schreiben Sie eine Funktion _calculateSimilarItems_, die aus der transformierten Matrix _transCritics_ ein Dictionary berechnet, welches die Ähnlichkeit zwischen allen Filmen beschreibt. Die Keys des Dictionary sind die Filmnamen. Die Values sind geordnete Listen, welche die Funktion _topMatches_ zurückgibt, wenn sie für die Filme (nicht für die User) aufgerufen wird. Dieses Dictionary wird an das aufrufende Programm zurück geben. \n",
    "3. Schreiben Sie eine Funktion _getRecommendedItems_, welche basierend auf dem im unten aufgeführten Beispiel dargestellten Verfahren unter Vorgabe der Bewertungsmatrix und der zu verwendenden Ähnlichkeitsfunktion Produktempfehlungen berechnet.\n",
    "4. Testen Sie die Funktion indem Sie die Empfehlungen für Toby berechnen und mit den Werten in der unten aufgeführten Tabelle vergleichen\n",
    "\n",
    "__Erläuterndes Beispiel:__\n",
    "\n",
    "_Toby_ hat die Filme _The Night Listener_, _Lady in the Water_ und _Just My Luck_ noch nicht gekauft. Für diese Filme soll für _Toby_ eine Empfehlung berechnet werden. Gekauft und bewertet hat _Toby_ die Filme _Snakes on a plane_, _Superman Returns_ und _You and me and Dupree_. Diese bereits vorhandenen Filme bilden die erste Spalte der unten dargestellten Matrix. In der zweiten Spalte befinden sich _Toby's_ Bewertungen dieser Filme. Die Spalten 3,5 und 7 enthalten die Ähnlichkeitswerte (mit _calculateSimilarItems_ unter Verwendung des normierten euklidischen Ähnlichkeitsmaßes berechnet) zwischen den drei von _Toby_ noch nicht gekauften Filmen und den drei von _Toby_ bewerteten Filmen. Diese Ähnlichkeitswerte werden jeweils mit _Toby's_ Bewertungen multipliziert. Das Resultat dieser Multiplikation befindet sich in den Spalten 4,6 und 8. Der finale Empfehlungswert für die von _Toby_ noch nicht gekauften Filme wird berechnet in dem in den Spalten 4,6 und 8 zunächst die Summe über die Werte dieser Spalte in den drei oberen Zeilen berechnet wird und durch die Summe über die Werte der Spalten 3,5 und 7 geteilt wird. Im Fall, dass die _Pearson-Korrelation_ zwischen den Filmen als Ähnlichkeitswert herangezogen wird, können negative Ähnlichkeitswerte auftreten. Dann soll in die Berechnung eines Empfehlungswert für Film A nur dann die Bewertung von Film B einfließen, wenn der Korrelationswert zwischen beiden $>0$ ist.  \n",
    "\n",
    "![Abbildung Calculate Itembased Recommendation](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining/Bilder/recommenderFilmItemBased.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aufgabe 1\n",
      "{'Lady in the Water': {'Lisa Rose': 2.5, 'Jack Matthews': 3.0, 'Michael Phillips': 2.5, 'Gene Seymour': 3.0, 'Mick LaSalle': 3.0}, 'Snakes on a Plane': {'Jack Matthews': 4.0, 'Mick LaSalle': 4.0, 'Claudia Puig': 3.5, 'Lisa Rose': 3.5, 'Toby': 4.5, 'Gene Seymour': 3.5, 'Michael Phillips': 3.0}, 'Just My Luck': {'Claudia Puig': 3.0, 'Lisa Rose': 3.0, 'Gene Seymour': 1.5, 'Mick LaSalle': 2.0}, 'Superman Returns': {'Jack Matthews': 5.0, 'Mick LaSalle': 3.0, 'Claudia Puig': 4.0, 'Lisa Rose': 3.5, 'Toby': 4.0, 'Gene Seymour': 5.0, 'Michael Phillips': 3.5}, 'You, Me and Dupree': {'Jack Matthews': 3.5, 'Mick LaSalle': 2.0, 'Claudia Puig': 2.5, 'Lisa Rose': 2.5, 'Toby': 1.0, 'Gene Seymour': 3.5}, 'The Night Listener': {'Jack Matthews': 3.0, 'Mick LaSalle': 3.0, 'Claudia Puig': 4.5, 'Lisa Rose': 3.0, 'Gene Seymour': 3.0, 'Michael Phillips': 4.0}} \n",
      "\n",
      "Aufgabe 2\n",
      "{'Lady in the Water': OrderedDict([('You, Me and Dupree', 0.76558762168507888), ('The Night Listener', 0.75974692664795784), ('Snakes on a Plane', 0.72771425735186723), ('Just My Luck', 0.615911621788925), ('Superman Returns', 0.61257411327720679)]), 'Snakes on a Plane': OrderedDict([('Superman Returns', 0.75789827630685158), ('The Night Listener', 0.73879612503625858), ('Lady in the Water', 0.72771425735186723), ('You, Me and Dupree', 0.58245852564983547), ('Just My Luck', 0.57841282804125316)]), 'Just My Luck': OrderedDict([('You, Me and Dupree', 0.65345379354447219), ('The Night Listener', 0.63039699812887051), ('Lady in the Water', 0.615911621788925), ('Snakes on a Plane', 0.57841282804125316), ('Superman Returns', 0.51230252551478894)]), 'Superman Returns': OrderedDict([('Snakes on a Plane', 0.75789827630685158), ('The Night Listener', 0.66978938167710644), ('Lady in the Water', 0.61257411327720679), ('You, Me and Dupree', 0.58748222906689995), ('Just My Luck', 0.51230252551478894)]), 'You, Me and Dupree': OrderedDict([('Lady in the Water', 0.76558762168507888), ('The Night Listener', 0.6758660359334131), ('Just My Luck', 0.65345379354447219), ('Superman Returns', 0.58748222906689995), ('Snakes on a Plane', 0.58245852564983547)]), 'The Night Listener': OrderedDict([('Lady in the Water', 0.75974692664795784), ('Snakes on a Plane', 0.73879612503625858), ('You, Me and Dupree', 0.6758660359334131), ('Superman Returns', 0.66978938167710644), ('Just My Luck', 0.63039699812887051)])} \n",
      "\n",
      "Aufgabe 4\n",
      "{'Lady in the Water': 3.0821369617993382, 'Just My Luck': 3.0418618690790988, 'The Night Listener': 3.2044909601608804}\n",
      "Die Werte stimmen überein\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "def get_all_person(crit):\n",
    "    return crit.keys()\n",
    "\n",
    "def get_trans_crit(crit):\n",
    "    crit_by_movie = {}\n",
    "    movies = get_all_items(crit)\n",
    "    crit_by_movie = {}\n",
    "    all_persons = crit.keys()\n",
    "    for movie in movies:\n",
    "        crit_by_movie[movie] = {}\n",
    "        for person, movies in crit.items():\n",
    "            try:\n",
    "                crit_by_movie[movie][person] = movies[movie]\n",
    "            except KeyError:\n",
    "                pass\n",
    "    return crit_by_movie\n",
    "\n",
    "trans_critics = get_trans_crit(critics)\n",
    "print \"Aufgabe 1\"\n",
    "print trans_critics, '\\n'\n",
    "\n",
    "#2-------------------------------------------------------------------------------\n",
    "def calculate_similar_items(prefs, film, similarity):\n",
    "    return topMatches(get_trans_crit(prefs), film, similarity)\n",
    "\n",
    "def get_similar_items_for_all_movies(prefs, similarity):\n",
    "    all_movies= get_all_items(prefs)\n",
    "    similar_movies = {}\n",
    "    for movie in all_movies:\n",
    "        similar_movies[movie]=calculate_similar_items(prefs, movie, similarity)\n",
    "    return similar_movies\n",
    "print \"Aufgabe 2\"\n",
    "print get_similar_items_for_all_movies(critics, sim_euclid), '\\n'\n",
    "\n",
    "#3--------------------------------------------------------------------------------\n",
    "\n",
    "def get_seen_movies_with_similarity(prefs, person, similarity):\n",
    "    seen_movies= get_seen_movies(prefs, person)\n",
    "    reduced_map = {}\n",
    "    for movie in seen_movies:\n",
    "        reduced_map[movie]=calculate_similar_items(prefs, movie, similarity)\n",
    "    return reduced_map\n",
    "\n",
    "def multily_with_rating(prefs, reduced_map, person):\n",
    "    for film, ratings in reduced_map.items():\n",
    "        factor = prefs[person][film]\n",
    "        for movie, rating in ratings.items():\n",
    "            ratings[movie] = rating * factor\n",
    "    return reduced_map\n",
    "\n",
    "def make_single_dict(reduced_multiplied_map):\n",
    "    all_movies = set()\n",
    "    for key, film_list in reduced_multiplied_map.items():\n",
    "        for film, rating in film_list.items():\n",
    "            all_movies.add(film)\n",
    "    single_dict = {}        \n",
    "    for film in all_movies:\n",
    "        single_dict[film] = 0.0\n",
    "    for key, film_list in reduced_multiplied_map.items():\n",
    "        for film, rating in film_list.items():\n",
    "            single_dict[film] = single_dict[film]+rating\n",
    "    return single_dict\n",
    "\n",
    "def divide_all_values(list_of_films, factor):\n",
    "    for film, rating in list_of_films.items():\n",
    "        list_of_films[film] = rating/factor\n",
    "    return list_of_films\n",
    "\n",
    "def normalise(single_dict, single_dict_multiplied):\n",
    "    normalised_map = {}\n",
    "    for film, rating in single_dict.items():\n",
    "        normalised_map[film] = single_dict_multiplied[film] / single_dict[film]\n",
    "    return normalised_map\n",
    "\n",
    "def sort_out_seen_films(prefs, person, film_list):\n",
    "    seen_movies = get_seen_movies(prefs, person)\n",
    "    not_seen_films = {}\n",
    "    for film, rating in film_list.items():\n",
    "        if film not in seen_movies:\n",
    "            not_seen_films[film] = film_list[film]\n",
    "    return not_seen_films\n",
    "\n",
    "def get_recommended_items(prefs, person, similarity):\n",
    "    reduced_map = get_seen_movies_with_similarity(prefs, person, similarity)\n",
    "    single_dict = sort_out_seen_films(prefs, person, make_single_dict(reduced_map))\n",
    "    multiplied_ratings = multily_with_rating(prefs ,reduced_map, person)\n",
    "    single_dict_multipied = sort_out_seen_films(prefs, person, make_single_dict(multiplied_ratings))\n",
    "    count_of_seen_movies = len(get_seen_movies(prefs, person))\n",
    "    result = single_dict_multipied\n",
    "    return normalise(single_dict, single_dict_multipied)\n",
    "\n",
    "#4---------------------------------------------------------------------\n",
    "print \"Aufgabe 4\"\n",
    "print get_recommended_items(critics, 'Toby', sim_euclid) \n",
    "print \"Die Werte stimmen überein\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##last.fm Musikempfehlungen\n",
    "Kopieren Sie die Datei _pylast.py_ vom _Resources_-Ordner im _DataMining_-Ordner des Skripteservers in das Verzeichnis dieses _IPython Notebooks_. In dieser Datei sind alle Zugriffsfunktionen auf _last.fm_ Dienste implementiert. Die notwendigen Anmelde- und Authentifizierungsdaten für den User _pythonlab_ sind ebenfalls schon in diesem Modul eingetragen.\n",
    "\n",
    "__Aufgabe:__\n",
    "\n",
    "1. Stellen Sie durch Aufruf der Funktion _network=pylast.get_lastfm_network()_ eine Verbindung zu _last.fm_ her. Beim Aufruf der Funktion wird die Anmeldung und Authentifizierung durchgeführt. Die Funktion gibt ein Objekt der Klasse _Network_ zurück. Über dieses Objekt können Methoden, wie\n",
    "\n",
    "    * ```get_artist(\"kuenstlerName\")``` (liefert Objekt der Klasse _Artist_\n",
    "    * ```get_album(\"albumName\")``` (liefert Objekt der Klasse _Album_\n",
    "    * ```get_track(\"songName\")``` (liefert Objekt der Klasse _Track_\n",
    "    * ```get_user(\"userName\")``` (liefert Objekt der Klass_Tag_\n",
    "    * usw.\n",
    "    \n",
    "      aufgerufen werden. Die Menge aller verfügbaren Klassen und deren Attribute und Methoden können dem Modul _pylast.py_ entnommen werden.\n",
    "\n",
    "1. Rufen Sie über das oben instanziierte _Network_-Objekt die Methode _get_artist(\"BandIhrerWahl\")_ auf.\n",
    "2. Rufen Sie über das oben instanziierte _Artist_-Objekt die Methode ```topfans=get_top_fans(10)``` auf. Die Methode gibt eine Liste von _User_-Objekt/Gewichtung-Paaren zurück. Die Gewichtungen von Objekten werden in diesem Versuch nicht benötigt. Legen Sie deshalb mit _group=[a.item for a in topfan]_ eine Liste an, die nur noch die User Objekte enthält. **Wichtige Anmerkung:** Seit August 2015 gibt es Probleme mit der lastFM API Methode ```get_top_fans()``` (siehe auch: [pylast issues](https://github.com/pylast/pylast/issues/155s)). Falls am Versuchstermin der Fehler noch nicht behoben ist, können Sie den unten stehenden Code benutzen. Darin wird versucht auf die API-Methode zuzugreifen. Falls das nicht möglich ist, wird eine vordefinierte Liste von Usern angewandt. Diese Liste repräsentiert die _Top Fans_ der Band _Slipknot_ im Frühjahr 2015. \n",
    "3. Implementieren Sie eine Funktion _createLastfmUserDict()_. Dieser Funktion soll, die oben angelegte Liste von _User_-Objekten _group_ übergeben werden. Für jeden User in _group_ sollen die 20 beliebtesten Bands mit der Methode ```topartists=get_top_artists()[0:20]``` bestimmt werden. Die Methode gibt eine Liste von _Artist_-Objekt/Gewichtung-Paaren zurück. Die Gewichtungen von Objekten werden in diesem Versuch nicht benötigt. Auf das _i.te_ _Artist_-Objekt selbst kann mit ```topartists[i].item``` zugegriffen werden. Die Menge aller Bands, die auf diese Weise gesammelt werden, wird im folgenden mit _AllBands_ bezeichnet. D.h. in _AllBands_ befinden sich alle Bands, die für mindestens einen User in _group_ zu den Top-20 gehören. Nun soll ein verschachteltes Dictionary mit Namen _userDict_ wie folgt angelegt werden:\n",
    "\n",
    "    * Die Keys sind die Namen der _User_-Objekte in _group_. Auf den Namen eines Objekts kann mit ```get_name()``` zugegriffen werden.\n",
    "    * Die Values sind selbst wieder Dictionaries, deren Keys die Namen der Bands in _AllBands_ sind. Achten Sie auch hier darauf, dass Sie nicht das _Artist_-Objekt selbst, sondern dessen Namen als Key verwenden. \n",
    "    * Für den User _a_ und die Band _b_ ist der Value ```userDict[a][b]= 1```, falls _b_ zu den Top-20 des Users _a_ gehört. Andernfalls ist ```userDict[a][b]= 0```. \n",
    "    \n",
    "    Das derart angelegte Dictionary soll von der Funktion zurückgegeben werden. \n",
    "4. Wählen Sie jetzt einen beliebigen User aus _group_. Bestimmen Sie zu diesem User die ähnlichsten User in _group_ durch Anwendung der im ersten Teilversuch implementierten Funktion _topMatches()_. Der Funktion wird das angelegte _userDict_ und der Name des gewählten Users übergeben. Als Ähnlichkeitsmaß soll die euklidische Metrik angewandt werden.\n",
    "5. Bestimmen Sie dann für den gewählten User Band-Empfehlungen durch Anwendung der im ersten Teilversuch implementierten Funktion _getRecommendations()_. Der Funktion wird das angelegte _userDict_ und der Name des gewählten Users übergeben. Als Ähnlichkeitsmaß soll die euklidische Metrik, danach die Russel_Rao Metrik, angewandt werden.     \n",
    "6. Diskutieren Sie das Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar (as calculated by lastFM) for artist:  Slipknot\n",
      "1.000 \t Stone Sour\n",
      "0.742 \t Korn\n",
      "0.581 \t Mudvayne\n",
      "0.485 \t System of a Down\n",
      "0.459 \t Limp Bizkit\n",
      "\n",
      "lastFM API Error for method get_top_fans\n",
      "Apply predefined group of users\n"
     ]
    }
   ],
   "source": [
    "import pylast\n",
    "nw=pylast.get_lastfm_network(api_key = \"993a5bd9d79a98a53677570368d55acd\",\n",
    "                             api_secret = \"9b8de0b57903ac007cdd8ec9003b341e\",\n",
    "                             username = \"pythonlab\")\n",
    "\n",
    "band='Slipknot'\n",
    "\n",
    "art1 = nw.get_artist(band)\n",
    "\n",
    "print \"Most similar (as calculated by lastFM) for artist: \",band\n",
    "for it in art1.get_similar(5):\n",
    "    print \"%3.3f \\t %s\"%(it.match, it.item)\n",
    "try:\n",
    "    topfan = art1.get_top_fans()\n",
    "    group = [a.item for a in topfan]\n",
    "except:\n",
    "    print \"\\nlastFM API Error for method get_top_fans\\nApply predefined group of users\"\n",
    "    usernames=['BrunoJoS','DPREBOYE','MPistol40','NemoNightfall','SkyRif','Wags1382','Znapsen','cortapsyco','emill_67','sattuviitana']\n",
    "    group=[]\n",
    "    for u in usernames:\n",
    "        u1 = nw.get_user(u)\n",
    "        group.append(u1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Team Sleep': 0, 'Flo Rida': 0, 'White Zombie': 0, 'Ke$ha': 0, 'Sabaton': 0, 'Tool': 0, 'Killswitch Engage': 0, 'Motion City Soundtrack': 0, 'Damien Rice': 1, 'Seether': 0, 'The Wonder Years': 0, 'Freestyle': 0, 'Dimmu Borgir': 0, 'Nirvana': 1, 'Trivium': 0, 'Green Day': 0, 'Electric Light Orchestra': 0, '\\xe6\\xa4\\x8d\\xe6\\x9d\\xbe\\xe4\\xbc\\xb8\\xe5\\xa4\\xab': 0, 'Breaking Benjamin': 0, 'Fall Out Boy': 0, 'Becoming the Archetype': 0, 'Three Days Grace': 0, 'Klamydia': 0, 'Queens of the Stone Age': 0, 'Iron Maiden': 0, 'Alexisonfire': 0, 'Rammstein': 0, 'Pendulum': 0, 'Pitty': 0, 'Black Label Society': 0, 'Lindemann': 0, 'Krewella': 0, 'Stam1na': 0, 'Gyllene Tider': 0, 'Radiohead': 0, 'Pentakill': 0, 'Bayside': 0, 'Nightwish': 0, 'Katy Perry': 0, 'Red Hot Chili Peppers': 0, 'Soilwork': 0, 'Magnus Uggla': 0, 'Shinedown': 0, 'Rage Against the Machine': 1, 'Oh, Sleeper': 0, 'Coheed and Cambria': 0, 'Halestorm': 0, 'A Perfect Circle': 0, 'Muse': 0, 'Soulfly': 0, '36 Crazyfists': 0, 'M.I.A.': 0, 'Limp Bizkit': 0, 'Lamb of God': 0, 'blink-182': 0, 'Metallica': 0, 'Amorphis': 0, 'AFI': 0, 'P.D.P.': 0, 'Dmitri Shostakovich': 0, 'Arctic Monkeys': 1, 'Mogwai': 1, 'Disturbed': 0, 'New Found Glory': 0, 'Sick Puppies': 0, 'Machine Head': 0, 'Lacuna Coil': 0, 'Tenacious D': 0, 'Boston': 0, 'Energy': 0, 'Queen': 0, 'Bring Me the Horizon': 0, 'The Band': 1, 'Pink Floyd': 0, 'Powerwolf': 0, 'deadmau5': 0, 'Sum 41': 0, 'Epic Rap Battles Of History': 0, 'Rob Zombie': 0, 'Papa Roach': 0, 'DIR EN GREY': 1, '30 Seconds to Mars': 0, 'Avenged Sevenfold': 0, 'Panic! at the Disco': 0, 'The Dear Hunter': 0, 'All Time Low': 0, 'Hozier': 1, 'Die Antwoord': 1, 'Korn': 0, 'Ween': 0, 'Four Year Strong': 0, 'Arch Enemy': 0, 'The Killers': 0, 'Cat Power': 1, 'Wintersun': 0, 'Demon Hunter': 0, 'Children of Bodom': 0, 'Sonata Arctica': 0, 'Parkway Drive': 0, 'Daughter': 1, 'Gallows': 0, 'Scar Symmetry': 0, 'Foo Fighters': 0, 'The White Stripes': 1, 'Slipknot': 1, 'Theory of a Deadman': 0, 'Saosin': 0, 'Ben Howard': 0, 'Wu-Tang Clan': 1, 'Pantera': 0, 'Leevi and the Leavings': 0, 'Warpaint': 1, 'Black Veil Brides': 0, 'My Chemical Romance': 0, 'Hans Zimmer': 0, 'Dark Tranquillity': 0, 'Madonna': 0, 'Stone Sour': 0, 'Evanescence': 0, 'Atoms for Peace': 1, 'Amon Amarth': 0, 'Thom Yorke': 0, 'Coldplay': 0, 'Dr. Dre': 1, 'Dope': 0, 'Marina & the Diamonds': 0, 'Five Finger Death Punch': 0, 'Calvin Harris': 0, 'Nine Inch Nails': 0, 'N.W.A': 1, 'Cradle of Filth': 0, 'Memphis May Fire': 0, 'Beach House': 1, 'Deftones': 0, 'Bullet for My Valentine': 0, 'System of a Down': 0, 'Linkin Park': 0, 'James Blake': 1, 'Misfits': 0, 'Cruel Hand': 0, 'Godsmack': 0, 'Billy Talent': 0, 'Mustasch': 0, 'In Flames': 0, 'Howard Shore': 0, 'DragonForce': 0, 'Circa Survive': 0, 'Mumford & Sons': 0, 'Volbeat': 0, 'Evergreen Terrace': 0}\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "'''\n",
    "* Die Keys sind die Namen der User-Objekte in group. Auf den Namen eines Objekts kann mit get_name() \n",
    "zugegriffen werden.\n",
    "\n",
    "* Die Values sind selbst wieder Dictionaries, deren Keys die Namen der Bands in AllBands sind. \n",
    "Achten Sie auch hier darauf, dass Sie nicht das Artist-Objekt selbst, sondern dessen Namen als Key verwenden.\n",
    "\n",
    "* Für den User a und die Band b ist der Value userDict[a][b]= 1, falls b zu den Top-20 des Users a gehört. \n",
    "Andernfalls ist userDict[a][b]= 0.\n",
    "\n",
    "#dict username: dict allbands : 0/1 \n",
    "'''\n",
    "\n",
    "def getAllArtists(users,countPerUser):\n",
    "    alltopartists = [user.get_top_artists()[0:20] for user in users]\n",
    "    # flatten list of all artists\n",
    "    allArtists = list(set([user[0] for userbands in alltopartists for user in userbands]))\n",
    "    return allArtists\n",
    "\n",
    "allArtists = getAllArtists(group,20)\n",
    "userNameslist = [user.get_name() for user in group]\n",
    "\n",
    "def topArtistsToDict(allArtists,users_top_artists):\n",
    "    usersTopArtistsList = [artist[0] for artist in users_top_artists]\n",
    "    usersTopArtistsDict = {}\n",
    "    for artist in allArtists:\n",
    "        if artist in usersTopArtistsList:\n",
    "            usersTopArtistsDict[artist.get_name().encode('utf-8')] = 1\n",
    "        else:\n",
    "            usersTopArtistsDict[artist.get_name().encode('utf-8')] = 0\n",
    "    return usersTopArtistsDict\n",
    "    \n",
    "def createUserArtistDict(users, count):\n",
    "    allArtists = getAllArtists(users,count)\n",
    "    return {user.get_name(): topArtistsToDict(allArtists,user.get_top_artists()[0:20]) for user in users}\n",
    "\n",
    "userArtistDict = createUserArtistDict(group,20)\n",
    "print userArtistDict['DPREBOYE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: DPREBOYE – euclidean similarity:\n",
      "\n",
      "  | MPistol40     -> 0.961538461538\n",
      "  | BrunoJoS      -> 0.961538461538\n",
      "  | SkyRif        -> 0.961538461538\n",
      "  | emill_67      -> 0.961538461538\n",
      "  | cortapsyco    -> 0.960526128553\n",
      "  | Wags1382      -> 0.960526128553\n",
      "  | sattuviitana  -> 0.960526128553\n",
      "  | Znapsen       -> 0.960526128553\n",
      "  | NemoNightfall -> 0.960526128553\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "user = 'DPREBOYE'\n",
    "print 'user:',user,'– euclidean similarity:\\n'\n",
    "for k,v in topMatches(userArtistDict, user, sim_euclid).items():\n",
    "    print '  |','%-13s' % (k,),'->', v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index                      euclidean similarity  | russelRao similarity                        \n",
      "#############################################################################################\n",
      "  1             System of a Down  0.666705683054 | 0.692307692308 System of a Down \n",
      "---------------------------------------------------------------------------------------------\n",
      "  2                         Korn  0.555646593793 | 0.615384615385 Korn             \n",
      "---------------------------------------------------------------------------------------------\n",
      "  3      Five Finger Death Punch  0.444353406207 | 0.461538461538 Red Hot Chili Peppers\n",
      "---------------------------------------------------------------------------------------------\n",
      "  4        Red Hot Chili Peppers  0.333528415272 | 0.384615384615 Papa Roach       \n",
      "---------------------------------------------------------------------------------------------\n",
      "  5                   Papa Roach  0.333411366109 | 0.384615384615 Stone Sour       \n",
      "---------------------------------------------------------------------------------------------\n",
      "  6                   Stone Sour  0.333411366109 | 0.384615384615 Five Finger Death Punch\n",
      "---------------------------------------------------------------------------------------------\n",
      "  7                  Linkin Park  0.333411366109 | 0.384615384615 Linkin Park      \n",
      "---------------------------------------------------------------------------------------------\n",
      "  8                    Rammstein  0.333294316946 | 0.307692307692 Rammstein        \n",
      "---------------------------------------------------------------------------------------------\n",
      "  9                    Metallica  0.333294316946 | 0.307692307692 Muse             \n",
      "---------------------------------------------------------------------------------------------\n",
      " 10                         Muse  0.222352276848 | 0.307692307692 Metallica        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 11                 Foo Fighters  0.222352276848 | 0.307692307692 Foo Fighters     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 12                      Sabaton  0.222235227685 | 0.230769230769 Sabaton          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 13             Three Days Grace  0.222235227685 | 0.230769230769 Three Days Grace \n",
      "---------------------------------------------------------------------------------------------\n",
      " 14                  Limp Bizkit  0.222235227685 | 0.230769230769 Limp Bizkit      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 15                  Lamb of God  0.222235227685 | 0.230769230769 Lamb of God      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 16                   Pink Floyd  0.222235227685 | 0.230769230769 Pink Floyd       \n",
      "---------------------------------------------------------------------------------------------\n",
      " 17           30 Seconds to Mars  0.222235227685 | 0.230769230769 30 Seconds to Mars\n",
      "---------------------------------------------------------------------------------------------\n",
      " 18                     Pendulum  0.222235227685 | 0.230769230769 Pendulum         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 19                    In Flames  0.222235227685 | 0.230769230769 In Flames        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 20           Coheed and Cambria  0.222118178522 | 0.153846153846 Team Sleep       \n",
      "---------------------------------------------------------------------------------------------\n",
      " 21            Avenged Sevenfold  0.222118178522 | 0.153846153846 Seether          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 22                      Pantera  0.222118178522 | 0.153846153846 Green Day        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 23                   Team Sleep  0.111176138424 | 0.153846153846 Electric Light Orchestra\n",
      "---------------------------------------------------------------------------------------------\n",
      " 24                      Seether  0.111176138424 | 0.153846153846 Queens of the Stone Age\n",
      "---------------------------------------------------------------------------------------------\n",
      " 25                    Green Day  0.111176138424 | 0.153846153846 Iron Maiden      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 26     Electric Light Orchestra  0.111176138424 | 0.153846153846 Arch Enemy       \n",
      "---------------------------------------------------------------------------------------------\n",
      " 27      Queens of the Stone Age  0.111176138424 | 0.153846153846 Pitty            \n",
      "---------------------------------------------------------------------------------------------\n",
      " 28                  Iron Maiden  0.111176138424 | 0.153846153846 Radiohead        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 29                   Arch Enemy  0.111176138424 | 0.153846153846 Pentakill        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 30                        Pitty  0.111176138424 | 0.153846153846 Soilwork         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 31                    Radiohead  0.111176138424 | 0.153846153846 Shinedown        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 32                    Pentakill  0.111176138424 | 0.153846153846 Coheed and Cambria\n",
      "---------------------------------------------------------------------------------------------\n",
      " 33                     Soilwork  0.111176138424 | 0.153846153846 Tool             \n",
      "---------------------------------------------------------------------------------------------\n",
      " 34                    Shinedown  0.111176138424 | 0.153846153846 Soulfly          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 35                         Tool  0.111176138424 | 0.153846153846 36 Crazyfists    \n",
      "---------------------------------------------------------------------------------------------\n",
      " 36                      Soulfly  0.111176138424 | 0.153846153846 M.I.A.           \n",
      "---------------------------------------------------------------------------------------------\n",
      " 37                36 Crazyfists  0.111176138424 | 0.153846153846 Dmitri Shostakovich\n",
      "---------------------------------------------------------------------------------------------\n",
      " 38                       M.I.A.  0.111176138424 | 0.153846153846 Disturbed        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 39          Dmitri Shostakovich  0.111176138424 | 0.153846153846 Tenacious D      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 40                    Disturbed  0.111176138424 | 0.153846153846 Boston           \n",
      "---------------------------------------------------------------------------------------------\n",
      " 41                  Tenacious D  0.111176138424 | 0.153846153846 Powerwolf        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 42                       Boston  0.111176138424 | 0.153846153846 deadmau5         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 43                    Powerwolf  0.111176138424 | 0.153846153846 Sum 41           \n",
      "---------------------------------------------------------------------------------------------\n",
      " 44                     deadmau5  0.111176138424 | 0.153846153846 Epic Rap Battles Of History\n",
      "---------------------------------------------------------------------------------------------\n",
      " 45                       Sum 41  0.111176138424 | 0.153846153846 Rob Zombie       \n",
      "---------------------------------------------------------------------------------------------\n",
      " 46  Epic Rap Battles Of History  0.111176138424 | 0.153846153846 Avenged Sevenfold\n",
      "---------------------------------------------------------------------------------------------\n",
      " 47                   Rob Zombie  0.111176138424 | 0.153846153846 Ween             \n",
      "---------------------------------------------------------------------------------------------\n",
      " 48                         Ween  0.111176138424 | 0.153846153846 The Killers      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 49                  The Killers  0.111176138424 | 0.153846153846 Wintersun        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 50                    Wintersun  0.111176138424 | 0.153846153846 Scar Symmetry    \n",
      "---------------------------------------------------------------------------------------------\n",
      " 51                Scar Symmetry  0.111176138424 | 0.153846153846 Theory of a Deadman\n",
      "---------------------------------------------------------------------------------------------\n",
      " 52          Theory of a Deadman  0.111176138424 | 0.153846153846 Pantera          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 53             A Perfect Circle  0.111176138424 | 0.153846153846 A Perfect Circle \n",
      "---------------------------------------------------------------------------------------------\n",
      " 54                  Hans Zimmer  0.111176138424 | 0.153846153846 Hans Zimmer      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 55            Dark Tranquillity  0.111176138424 | 0.153846153846 Dark Tranquillity\n",
      "---------------------------------------------------------------------------------------------\n",
      " 56                      Madonna  0.111176138424 | 0.153846153846 Madonna          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 57                  Evanescence  0.111176138424 | 0.153846153846 Evanescence      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 58                  Amon Amarth  0.111176138424 | 0.153846153846 Amon Amarth      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 59                   Thom Yorke  0.111176138424 | 0.153846153846 Thom Yorke       \n",
      "---------------------------------------------------------------------------------------------\n",
      " 60                     Coldplay  0.111176138424 | 0.153846153846 Coldplay         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 61              Nine Inch Nails  0.111176138424 | 0.153846153846 Nine Inch Nails  \n",
      "---------------------------------------------------------------------------------------------\n",
      " 62                     Deftones  0.111176138424 | 0.153846153846 Deftones         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 63                 Howard Shore  0.111176138424 | 0.153846153846 Howard Shore     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 64                  DragonForce  0.111176138424 | 0.153846153846 DragonForce      \n",
      "---------------------------------------------------------------------------------------------\n",
      " 65        Marina & the Diamonds  0.111059089261 | 0.0769230769231 Marina & the Diamonds\n",
      "---------------------------------------------------------------------------------------------\n",
      " 66                     Flo Rida  0.111059089261 | 0.0769230769231 Flo Rida         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 67                 White Zombie  0.111059089261 | 0.0769230769231 White Zombie     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 68                        Ke$ha  0.111059089261 | 0.0769230769231 Ke$ha            \n",
      "---------------------------------------------------------------------------------------------\n",
      " 69            Killswitch Engage  0.111059089261 | 0.0769230769231 Killswitch Engage\n",
      "---------------------------------------------------------------------------------------------\n",
      " 70       Motion City Soundtrack  0.111059089261 | 0.0769230769231 Motion City Soundtrack\n",
      "---------------------------------------------------------------------------------------------\n",
      " 71             The Wonder Years  0.111059089261 | 0.0769230769231 The Wonder Years \n",
      "---------------------------------------------------------------------------------------------\n",
      " 72                    Halestorm  0.111059089261 | 0.0769230769231 Halestorm        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 73                    Freestyle  0.111059089261 | 0.0769230769231 Freestyle        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 74                 Dimmu Borgir  0.111059089261 | 0.0769230769231 Dimmu Borgir     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 75                      Trivium  0.111059089261 | 0.0769230769231 Trivium          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 76                 植松伸夫  0.111059089261 | 0.0769230769231 植松伸夫     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 77            Breaking Benjamin  0.111059089261 | 0.0769230769231 Breaking Benjamin\n",
      "---------------------------------------------------------------------------------------------\n",
      " 78                 Fall Out Boy  0.111059089261 | 0.0769230769231 Fall Out Boy     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 79       Becoming the Archetype  0.111059089261 | 0.0769230769231 Becoming the Archetype\n",
      "---------------------------------------------------------------------------------------------\n",
      " 80                     Klamydia  0.111059089261 | 0.0769230769231 Klamydia         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 81                 Alexisonfire  0.111059089261 | 0.0769230769231 Alexisonfire     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 82          Black Label Society  0.111059089261 | 0.0769230769231 Black Label Society\n",
      "---------------------------------------------------------------------------------------------\n",
      " 83                    Lindemann  0.111059089261 | 0.0769230769231 Lindemann        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 84                     Krewella  0.111059089261 | 0.0769230769231 Krewella         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 85                      Stam1na  0.111059089261 | 0.0769230769231 Stam1na          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 86                Gyllene Tider  0.111059089261 | 0.0769230769231 Gyllene Tider    \n",
      "---------------------------------------------------------------------------------------------\n",
      " 87                      Bayside  0.111059089261 | 0.0769230769231 Bayside          \n",
      "---------------------------------------------------------------------------------------------\n",
      " 88                    Nightwish  0.111059089261 | 0.0769230769231 Nightwish        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 89                   Katy Perry  0.111059089261 | 0.0769230769231 Katy Perry       \n",
      "---------------------------------------------------------------------------------------------\n",
      " 90                 Magnus Uggla  0.111059089261 | 0.0769230769231 Magnus Uggla     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 91          My Chemical Romance  0.111059089261 | 0.0769230769231 My Chemical Romance\n",
      "---------------------------------------------------------------------------------------------\n",
      " 92                    blink-182  0.111059089261 | 0.0769230769231 blink-182        \n",
      "---------------------------------------------------------------------------------------------\n",
      " 93                     Amorphis  0.111059089261 | 0.0769230769231 Amorphis         \n",
      "---------------------------------------------------------------------------------------------\n",
      " 94                          AFI  0.111059089261 | 0.0769230769231 AFI              \n",
      "---------------------------------------------------------------------------------------------\n",
      " 95                       P.D.P.  0.111059089261 | 0.0769230769231 P.D.P.           \n",
      "---------------------------------------------------------------------------------------------\n",
      " 96              New Found Glory  0.111059089261 | 0.0769230769231 New Found Glory  \n",
      "---------------------------------------------------------------------------------------------\n",
      " 97                 Sick Puppies  0.111059089261 | 0.0769230769231 Sick Puppies     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 98                 Machine Head  0.111059089261 | 0.0769230769231 Machine Head     \n",
      "---------------------------------------------------------------------------------------------\n",
      " 99                  Lacuna Coil  0.111059089261 | 0.0769230769231 Lacuna Coil      \n",
      "---------------------------------------------------------------------------------------------\n",
      "100                       Energy  0.111059089261 | 0.0769230769231 Energy           \n",
      "---------------------------------------------------------------------------------------------\n",
      "101                        Queen  0.111059089261 | 0.0769230769231 Queen            \n",
      "---------------------------------------------------------------------------------------------\n",
      "102         Bring Me the Horizon  0.111059089261 | 0.0769230769231 Bring Me the Horizon\n",
      "---------------------------------------------------------------------------------------------\n",
      "103          Panic! at the Disco  0.111059089261 | 0.0769230769231 Panic! at the Disco\n",
      "---------------------------------------------------------------------------------------------\n",
      "104              The Dear Hunter  0.111059089261 | 0.0769230769231 The Dear Hunter  \n",
      "---------------------------------------------------------------------------------------------\n",
      "105                 All Time Low  0.111059089261 | 0.0769230769231 All Time Low     \n",
      "---------------------------------------------------------------------------------------------\n",
      "106             Four Year Strong  0.111059089261 | 0.0769230769231 Four Year Strong \n",
      "---------------------------------------------------------------------------------------------\n",
      "107                 Demon Hunter  0.111059089261 | 0.0769230769231 Demon Hunter     \n",
      "---------------------------------------------------------------------------------------------\n",
      "108                   Ben Howard  0.111059089261 | 0.0769230769231 Ben Howard       \n",
      "---------------------------------------------------------------------------------------------\n",
      "109               Sonata Arctica  0.111059089261 | 0.0769230769231 Sonata Arctica   \n",
      "---------------------------------------------------------------------------------------------\n",
      "110                Parkway Drive  0.111059089261 | 0.0769230769231 Parkway Drive    \n",
      "---------------------------------------------------------------------------------------------\n",
      "111                      Gallows  0.111059089261 | 0.0769230769231 Gallows          \n",
      "---------------------------------------------------------------------------------------------\n",
      "112                       Saosin  0.111059089261 | 0.0769230769231 Saosin           \n",
      "---------------------------------------------------------------------------------------------\n",
      "113            Children of Bodom  0.111059089261 | 0.0769230769231 Children of Bodom\n",
      "---------------------------------------------------------------------------------------------\n",
      "114       Leevi and the Leavings  0.111059089261 | 0.0769230769231 Leevi and the Leavings\n",
      "---------------------------------------------------------------------------------------------\n",
      "115            Black Veil Brides  0.111059089261 | 0.0769230769231 Black Veil Brides\n",
      "---------------------------------------------------------------------------------------------\n",
      "116                         Dope  0.111059089261 | 0.0769230769231 Dope             \n",
      "---------------------------------------------------------------------------------------------\n",
      "117                Calvin Harris  0.111059089261 | 0.0769230769231 Calvin Harris    \n",
      "---------------------------------------------------------------------------------------------\n",
      "118              Cradle of Filth  0.111059089261 | 0.0769230769231 Cradle of Filth  \n",
      "---------------------------------------------------------------------------------------------\n",
      "119             Memphis May Fire  0.111059089261 | 0.0769230769231 Memphis May Fire \n",
      "---------------------------------------------------------------------------------------------\n",
      "120      Bullet for My Valentine  0.111059089261 | 0.0769230769231 Bullet for My Valentine\n",
      "---------------------------------------------------------------------------------------------\n",
      "121                  Oh, Sleeper  0.111059089261 | 0.0769230769231 Oh, Sleeper      \n",
      "---------------------------------------------------------------------------------------------\n",
      "122                      Misfits  0.111059089261 | 0.0769230769231 Misfits          \n",
      "---------------------------------------------------------------------------------------------\n",
      "123                   Cruel Hand  0.111059089261 | 0.0769230769231 Cruel Hand       \n",
      "---------------------------------------------------------------------------------------------\n",
      "124                     Godsmack  0.111059089261 | 0.0769230769231 Godsmack         \n",
      "---------------------------------------------------------------------------------------------\n",
      "125                 Billy Talent  0.111059089261 | 0.0769230769231 Billy Talent     \n",
      "---------------------------------------------------------------------------------------------\n",
      "126                     Mustasch  0.111059089261 | 0.0769230769231 Mustasch         \n",
      "---------------------------------------------------------------------------------------------\n",
      "127                Circa Survive  0.111059089261 | 0.0769230769231 Circa Survive    \n",
      "---------------------------------------------------------------------------------------------\n",
      "128               Mumford & Sons  0.111059089261 | 0.0769230769231 Mumford & Sons   \n",
      "---------------------------------------------------------------------------------------------\n",
      "129                      Volbeat  0.111059089261 | 0.0769230769231 Volbeat          \n",
      "---------------------------------------------------------------------------------------------\n",
      "130            Evergreen Terrace  0.111059089261 | 0.0769230769231 Evergreen Terrace\n",
      "---------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "def get_known_bands(prefs, person):\n",
    "    ''' Returns list of known bands for a User '''\n",
    "    try: \n",
    "        return {k:v for (k,v) in prefs[person].items() if v != 0}.keys()\n",
    "    except KeyError:\n",
    "        return list()\n",
    "\n",
    "# wir müssen die getRecommendations funktion dazu erst verallgemeinern \n",
    "# da die getRecommendations funktion auf movies zugeschnitten ist \n",
    "    \n",
    "def getRecommendationsX(prefs, known_items_function, person, similarity):\n",
    "    recommendations = {}\n",
    "    known_items = known_items_function(prefs, person, )\n",
    "    all_items = get_all_items(prefs)\n",
    "    for item in all_items:\n",
    "        if item not in known_items:\n",
    "            recommendations[item]=get_recommended(prefs, person, item, similarity)\n",
    "    return sorted(recommendations.items(), key=operator.itemgetter(1), reverse=True)   \n",
    "\n",
    "user = 'DPREBOYE'\n",
    "\n",
    "euclidean_recom = getRecommendationsX(userArtistDict, get_known_bands, user, sim_euclid)\n",
    "russelRao_recom = getRecommendationsX(userArtistDict, get_known_bands, user, sim_RusselRao)\n",
    "\n",
    "print 'index', '%41s ' % 'euclidean similarity', '|' , '%-43s ' % 'russelRao similarity'\n",
    "print '#############################################################################################'\n",
    "for i,v in enumerate(zip(euclidean_recom,russelRao_recom)): \n",
    "    print '%3s ' % (i+1) , '%27s ' % (v[0][0],), '%-10s' % (v[0][1],),'|','%-14s' % (v[1][1],), '%-17s' % (v[1][0],)\n",
    "    print '---------------------------------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Diskussion der Ergebnisse\n",
    "Russel Rao und die euklidische Ähnlichkeit ergeben sehr ähnliche Vorschläge.\n",
    "\n",
    "Der kleine Unterschied der Vorschläge zwischen euklid und russel rao lässt sich mit folgendem begründen.\n",
    "Russell Rao nutzt Anzahl der Werte die für beide Vektoren 1 sind (1 und 1) und Teilt durch die Anzahl aller Werte.\n",
    "Der euklidische Abstand betrachtet die abstände aller Werte was bei binären Daten dazu führt, \n",
    "dass nur unterschiedliche Werte ins gewicht fallen (0 und 1 , 1 und 0), 1-1 und 0-0 ändern nichts an der Ähnlichkeit.\n",
    "\n",
    "Beispiel\n",
    "X = 1,0,1,1,0  Y = 1,0,1,0,1 \n",
    "Russel Rao = 2/5 \n",
    "Euklid = sqrt((1-1)^2 + (0-0)^2 + (1-1)^2 + (1-0)^2 + (0-1)^2)) = sqrt((1-0)^2 + (0-1)^2))\n",
    "\n",
    "\n",
    "Die Empfehlungen für beide Ähnlichkeitsfunktionen sind schlüssig. \n",
    "Es ergeben sich Vorschläge die man zu Slipknot erwarten würde.\n",
    "\n",
    "Wenn man unsere Vorschläge mit den von lastFM vergleicht.\n",
    "Sieht man dass die von lastFM berechneten, scheinbar skaliert werden, da der Top Match einen Wert von 1.0 hat.\n",
    "Es werden wahrscheinlich mehr Userdaten für die empfehlungen benutzt.\n",
    "Mudvayne z.B. ist gar nicht in unserem Datenset enthalten.\n",
    "\n",
    "Die Top 5 (ausgenommen Mudvayne) sind bei uns in den Top 14 Vorschlägen enthalten.\n",
    "\n",
    "getRecommendationsX()\n",
    "  1   System of a Down  0.666705683054 | 0.692307692308 System of a Down \n",
    "  2               Korn  0.555646593793 | 0.615384615385 Korn             \n",
    "  5         Papa Roach  0.333411366109 | 0.384615384615 Stone Sour       \n",
    "  6         Stone Sour  0.333411366109 | 0.384615384615 Five Finger Death Punch\n",
    " 14        Limp Bizkit  0.222235227685 | 0.230769230769 Limp Bizkit\n",
    "\n",
    "lastFM\n",
    "1.000 \t Stone Sour\n",
    "0.742 \t Korn\n",
    "0.581 \t Mudvayne\n",
    "0.485 \t System of a Down\n",
    "0.459 \t Limp Bizkit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "664px",
   "left": "0px",
   "right": "1209.67px",
   "top": "125.333px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
