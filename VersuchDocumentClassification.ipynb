{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Document Classification\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 06.11.2015\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Dokumentklassifikation: Klassifikation von Dokumenten, insbesondere Emails und RSS Feed\n",
    "* Naive Bayes Classifier: Weit verbreitete Klassifikationsmethode, welche unter bestimmten Randbedingungen sehr gut skaliert.\n",
    "\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "### Parametrische Klassifikation und Naive Bayes Methode\n",
    "Klassifikatoren müssen zu einer gegebenen Eingabe $\\underline{x}$ die zugehörige Klasse $C_i$ bestimmen. Mithilfe der Wahrscheinlichkeitstheorie kann diese Aufgabe wie folgt beschrieben werden: Bestimme für alle möglichen Klassen $C_i$ die bedingte Wahrscheinlichkeit $P(C_i | \\underline{x})$, also die Wahrscheinlichkeit, dass die gegebene Eingabe $\\underline{x}$ in Klasse $C_i$ fällt. Wähle dann die Klasse aus, für welche diese Wahrscheinlichkeit maximal ist.\n",
    "\n",
    "Die Entscheidungsregeln von Klassifikatoren können mit Methoden des \"\"überwachten Lernens\"\" aus Trainingsdaten ermittelt werden. Im Fall des **parametrischen Lernens** kann aus den Trainingsdaten die sogenannte **Likelihood-Funktion** $p(\\underline{x} \\mid C_i)$ bestimmt werden. _Anmerkung:_ Allgemein werden mit $p(...)$ kontinuierliche Wahrscheinlichkeitsfunktionen und mit $P(...)$ diskrete Wahrscheinlichkeitswerte bezeichnet. \n",
    "\n",
    "Mithilfe der **Bayes-Formel**\n",
    "$$\n",
    "P(C_i \\mid \\underline{x}) = \\frac{p(\\underline{x} \\mid C_i) \\cdot P(C_i)}{p(\\underline{x})}\n",
    "$$\n",
    "\n",
    "kann aus der Likelihood die **a-posteriori-Wahrscheinlichkeit $P(C_i \\mid \\underline{x})$** berechnet werden. Darin wird $P(C_i)$ die **a-priori-Wahrscheinlichkeit** und $p(\\underline{x})$ die **Evidenz** genannt. Die a-priori-Wahrscheinlichkeit kann ebenfalls aus den Trainingsdaten ermittelt werden. Die Evidenz ist für die Klassifikationsentscheidung nicht relevant, da sie für alle Klassen $C_i$ gleich groß ist.\n",
    "\n",
    "Die Berechnung der Likelihood-Funktion $p(\\underline{x} \\mid C_i)$ ist dann sehr aufwendig, wenn $\\underline{x}=(x_1,x_2,\\ldots,x_Z)$ ein Vektor von voneinander abhängigen Variablen $x_i$ ist. Bei der **Naive Bayes Classification** wird jedoch von der vereinfachenden Annahme ausgegangen, dass die Eingabevariabeln $x_i$ voneinander unabhängig sind. Dann vereinfacht sich die bedingte Verbundwahrscheinlichkeits-Funktion $p(x_1,x_2,\\ldots,x_Z \\mid C_i)$ zu:\n",
    "\n",
    "$$\n",
    "p(x_1,x_2,\\ldots,x_Z \\mid C_i)=\\prod\\limits_{j=1}^Z p(x_j | C_i)\n",
    "$$\n",
    "\n",
    "### Anwendung der Naive Bayes Methode in der Dokumentklassifikation\n",
    "Auf der rechten Seite der vorigen Gleichung stehen nur noch von den jeweils anderen Variablen unabhängige bedingte Wahrscheinlichkeiten. Im Fall der Dokumentklassifikation sind die einzelnen Worte die Variablen, d.h. ein Ausdruck der Form $P(x_j | C_i)$ gibt an mit welcher Wahrscheinlichkeit ein Wort $x_j=w$ in einem Dokument der Klasse $C_i$ vorkommt. \n",
    "Die Menge aller Variablen $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ ist dann die Menge aller Wörter im Dokument. Damit gibt die linke Seite in der oben gegebenen Gleichung die _Wahrscheinlichkeit, dass die Wörter $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ in einem Dokument der Klasse $C_i$ vorkommen_ an.\n",
    "\n",
    "Für jedes Wort _w_ wird aus den Trainingsdaten die Wahrscheinlichkeit $P(w|G)$, mit der das Wort in Dokumenten der Kategorie _Good_ und die Wahrscheinlichkeit $P(w|B)$ mit der das Wort in Dokumenten der Kategorie _Bad_ auftaucht ermittelt. Trainingsdokumente werden in der Form\n",
    "\n",
    "$$\n",
    "tD=(String,Category)\n",
    "$$\n",
    "eingegeben. \n",
    "\n",
    "Wenn \n",
    "\n",
    "* mit der Variable $fc(w,cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ in denen das Wort $w$ enthalten ist\n",
    "* mit der Variable $cc(cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ \n",
    "\n",
    "gezählt wird, dann ist \n",
    "\n",
    "$$\n",
    "P(w|G)=\\frac{fc(w,G)}{cc(G)} \\quad \\quad P(w|B)=\\frac{fc(w,B)}{cc(B)}.\n",
    "$$\n",
    "\n",
    "Wird nun nach der Eingabe von $L$ Trainingsdokumenten ein neu zu klassifizierendes Dokument $D$ eingegeben und sei $W(D)$ die Menge aller Wörter in $D$, dann berechnen sich unter der Annahme, dass die Worte in $W(D)$ voneinander unabhängig sind (naive Bayes Annahme) die a-posteriori Wahrscheinlichkeiten zu:\n",
    "\n",
    "$$\n",
    "P(G|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | G) \\right) \\cdot P(G)}{p(D)}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | B) \\right) \\cdot P(B)}{p(D)}.\n",
    "$$\n",
    "\n",
    "Die hierfür notwendigen a-priori-Wahrscheinlichkeiten berechnen sich zu \n",
    "\n",
    "$$\n",
    "P(G)=\\frac{cc(G)}{L}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B)=\\frac{cc(B)}{L}\n",
    "$$\n",
    "\n",
    "Die Evidenz $p(D)$ beeinflusst die Entscheidung nicht und kann deshalb ignoriert werden.\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "\n",
    "1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training für die spätere Klassifikation abgespeichert werden?\n",
    "2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?\n",
    "3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tatsächlich gegeben?\n",
    "4. Betrachten Sie die Formeln für die Berechnung von $P(G|D)$ und $P(B|D)$. Welches Problem stellt sich ein, wenn in der Menge $W(D)$ ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie $G$ vorkommt und ein anderes Wort aus $W(D)$ nicht in den Trainingsdaten der Kategorie $B$ enthalten ist? Wie könnte dieses Problem gelöst werden? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1 Wie wird Bayes trainiert?\n",
    "Der Bayes Classifier wird mit Hilfe von Trainingstexten trainiert. Ein Trainingstext ist ein Text dessen Klasse bereits bekannt ist. Von jedem Text wird dann die Häufigkeit der einzelnen Wörter gezählt und nach Klassen abgespeichert.\n",
    "\n",
    "#### 2 Wie wird ein Dokument eingeteilt?\n",
    "1. Das Dokument wird in eine Liste umgewandelt. Die enthaltenen Wörter werden in eine Liste gespeichert.\n",
    "1. Danach wird für jedes einzelne Wort die Wahrscheinlichkeit der Wörter in der einzelnen Klasse berechnet.\n",
    "1. Anschließend werden all diese Wahrscheinlichkeiten, pro Klasse, miteinander multipliziert.\n",
    "1. Nun wird geschaut welche der einzelnen Kategorien, die höchste Trefferquote hat. (Wahrscheinlichkeit)\n",
    "1. Anschließend bekommt der ankommende Text die Klassifikation mit der höchsten Wahrscheinlichkeit.\n",
    "\n",
    "#### 3 Annahme beim naiven Bayer?\n",
    "Beim naiven Bayes wird davon ausgegangen das alle Wörter in einem Text unabhängig voneinander sind. \n",
    "##### 3.1 Naive\n",
    "Das heißt es wird nur die Wahrscheinlichkeit des Vorkommens *eines* Wortes unter der Bedingung einer bestimmten Klassifikation berechnet. \n",
    "###### 3.2 Nicht naive\n",
    "Beim nicht naive Bayes würde die Wahrscheinlichkeit des Vorkommens *aller* Wörter im zu untersuchenden Text unter Annahme einer Klassifikation berechnet. Da alle Wörter in der Zielmenge (Klasse) vorkommen die auch im zu klassifizierenden Text vorkommen, ist jedoch sehr unwahrscheinlich und daher für Texte nicht brauchbar. Zusätzlich würde die Berechnungszeit bei diesem Ansatz erheblich.\n",
    "##### 3.3 abhängig oder unabhänging?\n",
    "Die Annahme das die Wörter in einem Text unabhängig voneinander sind ist, schlichtweg falsch. Da jedoch der klassische Bayes nicht auf dieses Problem anwendbar ist und der naive Bayes zusätzlich ein sehr gutes, schnelles Ergebnis liefert, wird er trotzdem angewendet. Mathematisch ist diese Annahme jedoch nicht vertretbar.\n",
    "\n",
    "#### 4 Das Problem wenn das Wort nicht in den Trainingsdaten Vorhanden ist\n",
    "Die Wahrscheinlichkeit ob ein Wort zu einer Klasse gehört wird folgendermaßen berechnet:\n",
    "$$\n",
    "P(Klassifikation|Wort) = \\frac{Worthäufigkeit In Klassifikation} {Worthäufigkeit Über Alle Klassifikationen}\n",
    "$$\n",
    "\n",
    "Dies wird nun für alle Wörter im zu klassifizierenden Text gemacht. Die Ergebnisse der einzelne Zahlen werden dann wieder miteinander multipliziert.\n",
    "*Beispiel:* Eingabetext: {\"Hallo\", \"Du\"} Klasse: Egoistisch [(Hallo, 5), (Du,0)]\n",
    "$$\n",
    "P(Du|Egoistisch) = \\frac{0}{20} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(Hallo|Egoistisch) = \\frac{10}{50} = \\frac{1}{5}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(Hallo Du|Egoistisch) = \\frac{1}{5} * 0 = 0\n",
    "$$\n",
    "\n",
    "Ist also ein Wort im Eingabetext vorhanden,jedoch nicht in der Klasse ist deren Wahrscheinlichkeit 0. Diese wird anschließend mit den anderen Wahrscheinlichkeiten multipliziert. Was dazu führt dass, die Wahrscheinlichkeit '0' wird, egal wie gut der Rest des Eingabetextes auf die Klassifikation passt.\n",
    "\n",
    "*Lösung:*\n",
    "Eine Möglichkeit ist es einfach alle 0-Wahrscheinlichkeiten durch die sogenannte Pass-Wahrscheinlichkeit zu ersetzten:\n",
    "\n",
    "\n",
    "P<sub>ass,i</sub> = $ \\frac{1}{K} $ , mit [K]: Anzahl der Klassen.\n",
    "\n",
    "Somit wird eine Wahrscheinlichkeit eingesetzt, die in etwa der mittleren Wahrscheinlichkeit entspricht. Das hat zu Folge dass, das Ergebnis nur minimal verfälscht wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Feature Extraction/ -Selection\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie eine Funktion _getwords(doc)_, der ein beliebiges Dokument in Form einer String-Variablen übergeben wird. In der Funktion soll der String in seine Wörter zerlegt und jedes Wort in _lowercase_ transformiert werden. Wörter, die weniger als eine untere Grenze von Zeichen (z.B. 3) oder mehr als eine obere Grenze von Zeichen (z.B. 20) enthalten, sollen ignoriert werden. Die Funktion soll ein dictionary zurückgeben, dessen _Keys_ die Wörter sind. Die _Values_ sollen für jedes Wort zunächst auf $1$ gesetzt werden.\n",
    "\n",
    "**Tipp:** Benutzen Sie für die Zerlegung des Strings und für die Darstellung aller Wörter mit ausschließlich kleinen Buchstaben die Funktionen _split(), strip('sep')_ und _lower()_ der Klasse _String_.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwords(doc):\n",
    "    \"create lowercase word dict with keys between len(range(4,20))\"\n",
    "    word_dict = {}    \n",
    "    word_dict = {x.lower() : 1 for x in doc.split() if len(x) in range(4,20)}\n",
    "    return word_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie den Naive Bayes Classifier für die Dokumentklassifikation. Es bietet sich an die Funktionalität des Klassifikators und das vom Klassifikator gelernte Wissen in einer Instanz einer Klasse _Classifier_ zu kapseln. In diesem Fall kann wie folgt vorgegangen werden:\n",
    "\n",
    "* Im Konstruktor der Klasse wird je ein Dictionary für die Instanzvariablen _fc_ und _cc_ (siehe oben) initialisiert. Dabei ist _fc_ ein verschachteltes Dictionary. Seine Keys sind die bisher gelernten Worte, die Values sind wiederum Dictionaries, deren Keys die Kategorien _Good_ und _Bad_ sind und deren Values zählen wie häufig das Wort bisher in Dokumenten der jeweiligen Kategorie auftrat. Das Dictionary _cc_ hat als Keys die Kategorien _Good_ und _Bad_. Die Values zählen wie häufig Dokumente der jeweiligen Kategorien bisher auftraten.\n",
    "* Im Konstruktor wird ferner der Instanzvariablen _getfeatures_ die Funktion _getwords()_ übergeben. Die Funktion _getwords()_ wurde bereits zuvor ausserhalb der Klasse definiert. Sinn dieses Vorgehens ist, dass andere Varianten um Merkmale aus Dokumenten zu extrahieren denkbar sind. Diese Varianten könnten dann ähnlich wie die _getwords()_-Funktion ausserhalb der Klasse definiert und beim Anlegen eines _Classifier_-Objekts der Instanzvariablen _getfeatures_ übergeben werden.  \n",
    "* Der Methode _incf(self,f,cat)_ wird ein Wort _f_ und die zugehörige Kategorie _cat_ des Dokuments in welchem es auftrat übergeben. In der Methode wird der _fc_-Zähler angepasst.\n",
    "* Der Methode _incc(self,cat)_ wird die Kategorie _cat_ des gerade eingelesenen Dokuments übergeben. In der Methode wird der _cc_-Zähler angepasst.\n",
    "* Die Methode _fcount(self,f,cat)_ gibt die Häufigkeit des Worts _f_ in den Dokumenten der Kategorie _cat_ zurück.\n",
    "* Die Methode _catcount(self,cat)_ gibt die Anzahl der Dokumente in der Kategorie _cat_ zurück.\n",
    "* Die Methode _totalcount(self)_ gibt die Anzahl aller Dokumente zurück.\n",
    "* Der Methode _train(self,item,cat)_ wird ein neues Trainingselement, bestehend aus der Betreffzeile (_item_) und der entsprechenden Kategorisierung (_cat_) übergeben. Der String _item_ wird mit der Instanzmethode _getfeatures_ (Diese referenziert _getwords()_) in Worte zerlegt. Für jedes einzelne Wort wird dann _incf(self,f,cat)_ aufgerufen. Ausserdem wird für das neue Trainingsdokument die Methode _incc(self,cat)_ aufgerufen.\n",
    "* Die Methode _fprob(self,f,cat)_ berechnet die bedingte Wahrscheinlichkeit $P(f | cat)$ des Wortes _f_ in der Kategorie _cat_ entsprechend der oben angegebenen Formeln, indem sie den aktuellen Stand des Zählers _fc(f,cat)_ durch den aktuellen Stand des Zählers _cc(cat)_ teilt.   \n",
    "* Die Methode _fprob(self,f,cat)_ liefert evtl. ungewollt extreme Ergebnisse, wenn noch wenig Wörter im Klassifizierer verbucht sind. Kommt z.B. ein Wort erst einmal in den Trainingsdaten vor, so wird seine Auftrittswahrscheinlichkeit in der Kategorie in welcher es nicht vorkommt gleich 0 sein. Um extreme Wahrscheinlichkeitswerte im Fall noch selten vorkommender Werte zu vermeiden, soll zusätzlich zur Methode _fprob(self,f,cat)_ die Methode _weightedprob(self,f,cat)_ implementiert und angewandt werden. Der von ihr zurückgegebene Wahrscheinlichkeitswert könnte z.B. wie folgt berechnet werden:$$wprob=\\frac{initprob+count \\cdot fprob(self,f,cat)}{1+count},$$ wobei $initprob$ ein initialer Wahrscheinlichkeitswert (z.B. 0.5) ist, welcher zurückgegeben werden soll, wenn das Wort noch nicht in den Trainingsdaten aufgetaucht ist. Die Variable $count$ zählt wie oft das Wort $f$ bisher in den Trainingsdaten auftrat. Wie zu erkennen ist, nimmt der Einfluss der initialen Wahrscheinlichkeit ab, je häufiger das Wort in den Trainingsdaten auftrat.\n",
    "* Nach dem Training soll ein beliebiges neues Dokument (Text-String) eingegeben werden können. Für dieses soll mit der Methode _prob(self,item,cat)_ die a-posteriori-Wahrscheinlichkeit $P(cat|item)$ (Aufgrund der Vernachlässigung der Evidenz handelt es sich hierbei genaugenommen um das Produkt aus a-posteriori-Wahrscheinlichkeit und Evidenz), mit der das Dokument _item_ in die Kategorie _cat_ fällt berechnet werden. Innerhalb der Methode _prob(self,item,cat)_ soll zunächst die Methode _weightedprob(self,f,cat)_ für alle Wörter $f$ im Dokument _item_ aufgerufen werden. Die jeweiligen Rückgabewerte von _weightedprob(self,f,cat)_ werden multipliziert. Das Produkt der Rückgabewerte von _weightedprob(self,f,cat)_ über alle Wörter $f$ im Dokument muss schließlich noch mit der a-priori Wahrscheinlichkeit $P(G)$ bzw. $P(B)$ entsprechend der oben aufgeführten Formeln multipliziert werden. Das Resultat des Produkts wird an das aufrufende Programm zurück gegeben, die Evidenz wird also vernachlässigt (wie oben begründet).\n",
    "\n",
    "\n",
    "\n",
    "Ein Dokument _item_ wird schließlich der Kategorie _cat_ zugeteilt, für welche die Funktion _prob(self,item,cat)_ den höheren Wert zurück gibt. Da die Rückgabewerte in der Regel sehr klein sind, werden in der Regel folgende Werte angezeigt. Wenn mit $g$ der Rückgabewert von _prob(self,item,cat=G)_ und mit $b$ der Rückgabewert von _prob(self,item,cat=B)_ bezeichnet wird dann ist die Wahrscheinlichkeit, dass $item$ in die Kategorie $G$ fällt, gleich:\n",
    "$$\n",
    "\\frac{g}{g+b}\n",
    "$$\n",
    "und die Wahrscheinlichkeit, dass $item$ in die Kategorie $B$ fällt, gleich:\n",
    "$$\n",
    "\\frac{b}{g+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Die überarbeitete Klasse #### \n",
    "### noch nicht fertig ! ###\n",
    "class Classy:\n",
    "    \n",
    "    def __init__(self, labels, doc_list, feature_extr_fn):\n",
    "        self.labels = labels\n",
    "        self.fc = {'nobody':{'Good':0, 'Bad': 0}, 'owns':{'Bad': 0, 'Good': 0}}#create_fc()\n",
    "        self.cc = self.create_cc()\n",
    "        self.getfeatures = feature_extr_fn\n",
    "        self.doc_list = doc_list\n",
    "        \n",
    "    # noch zu machen #\n",
    "    #def create_fc():\n",
    "    \n",
    "    # noch zu machen #\n",
    "    def create_cc(self):\n",
    "        unique = self.labels.unique()\n",
    "        cc = {j: self.labels.loc[self.labels==unique[i]].size for i,j in enumerate(unique)}\n",
    "        return cc\n",
    "    \n",
    "    def incf(self, f, cat):\n",
    "        'zählt fc hoch'\n",
    "        # check ob das gesuchte Wort teil der Doc_List-Wortmenge ist\n",
    "        for x in doc_list[1].values:\n",
    "            if f in x:\n",
    "                # sobald die Cat mit dem Label übereinstimmt, zähle hoch\n",
    "                if cat.lower()==self.labels[0].lower():\n",
    "                    self.fc[f][cat]+=1\n",
    "                elif cat.lower()==self.labels[1].lower():\n",
    "                    self.fc[f][cat]+=1\n",
    "                    \n",
    "    def incc(self, cat):\n",
    "        'zählt cc hoch, wenn Dokument einer Kategorie gelesen wird'\n",
    "        # Wenn cat in labels zu finden ist\n",
    "        if cat in self.labels:\n",
    "            # welches label soll hochgezählt werden\n",
    "            if cat==self.labels[0]:\n",
    "                self.cc[self.labels[0]]+=1\n",
    "            elif cat==self.labels[1]:\n",
    "                self.cc[self.labels[1]]+=1\n",
    "                \n",
    "    def fcount(self,f,cat):\n",
    "        'gibt Häufigkeit des Word f einer bestimmten Cat zurück'\n",
    "        return self.fc[f][cat]  \n",
    "    \n",
    "    def catcount(self,cat):\n",
    "        'gibt Häufigkeit einer Cat aus'\n",
    "        return self.cc[cat]\n",
    "    \n",
    "    def totalcount(self):\n",
    "        'gibt Anzahl aller Dokumente aus'\n",
    "        return len(self.doc_list)\n",
    "    \n",
    "    def train(self, item, cat):\n",
    "        'für jedes wort wird incf() aufgerufen, für das neue trainingsdokument wird incc() aufgerufen'\n",
    "       \n",
    "        # Item der Documentenliste Hinzufügen?????????\n",
    "        '''eigentlich muss hier das Item der gelernten worte (Doc_List) hinzugefügt werden, da sonst \n",
    "        fehler geschmissen werden.\n",
    "        \n",
    "        Nachgelesen!: die wahrscheinlichkeiten müssen berechnet werden um zu ermitteln in welche\n",
    "        kategorie es fällt.\n",
    "        '''\n",
    "        for word in self.getfeatures(item):\n",
    "            self.incf(word, cat)\n",
    "        self.incc(cat)\n",
    "\n",
    "    # noch zu machen #    \n",
    "    #def fprob(self,f,cat):\n",
    "    \n",
    "    # noch zu machen #\n",
    "    #def weightedprob(self,f,cat):\n",
    "    #weighted = (0.5 + (count * fprob(self, f cat))) / (1 + count)\n",
    "\n",
    "\n",
    "    \n",
    "##### testdaten #####   \n",
    "doc_list = pd.DataFrame([('Good', 'nobody owns the water'), ('Good', 'the quick rabbit jumps fences'),\n",
    "                         ('Good', 'make quick money at the online casino'), \n",
    "                         ('Good', 'next meeting is at night'), ('Bad', 'buy pharmaceuticals now'), \n",
    "                         ('Bad', 'the quick brown fox jumps'), \n",
    "                         ('Bad', 'meeting with your superstar'), ('Bad', 'money like water')])  \n",
    "labels = doc_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Classy instance has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-68e046fee7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# funktionalitäten testen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-6e64fc2b23d8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, labels, doc_list, feature_extr_fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_extr_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'nobody'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Good'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bad'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'owns'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Bad'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Good'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m#create_fc()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extr_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-6e64fc2b23d8>\u001b[0m in \u001b[0;36mcreate_cc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# noch zu machen #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Classy instance has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "# funktionalitäten testen \n",
    "c = Classy(labels, doc_list, getwords)\n",
    "\n",
    "    \n",
    "print c.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## veraltete Klasse ############\n",
    "# Kann sein das man noch etwas verwenden kann aus dieser Version \n",
    "\n",
    "class Classifier:\n",
    "    'classifier class for naive bayes classification'\n",
    "   \n",
    "    def __init__(self, labels, doc_list, feature_extr_fn):\n",
    "        self.labels = labels\n",
    "        self.fc = create_fc(extract_words(doc_list), self.labels)\n",
    "        self.cc = create_cc(self.labels) # instance variable unique to each instance\n",
    "        self.getfeatures = feature_extr_fn\n",
    "   \n",
    "    def extract_words(doc_list):\n",
    "        'set aus Wörtern aller Dokumente. Doc_list ist Pandaframe.'\n",
    "        sentence_list = [value for value in doc_list[1]]\n",
    "        train_word_set = set([item for word_list in sentence_list for item in word_list.split()])\n",
    "        return train_word_set \n",
    "    \n",
    "    def create_fc(train_word_set, labels):\n",
    "        train_word_set = extract_words(doc_list)    \n",
    "        fc = {}\n",
    "        for word in train_word_set:\n",
    "            fc.update({word: {labels[0]: 0, labels[1]: 0}})\n",
    "            for cat in doc_list[doc_list[1].str.contains(word.lower())][0].values:\n",
    "                if cat is labels[0]:\n",
    "                    fc[word][labels[0]]+=1\n",
    "                elif cat is labels[1]:\n",
    "                    fc[word][labels[1]]+=1  \n",
    "        return fc\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "**Aufgabe:**\n",
    "Instanzieren Sie ein Objekt der Klasse _Classifier_ und übergeben Sie der _train()_ Methode dieser Klasse mindestens 8 kategorisierte Dokumente (Betreffzeilen als Stringvariablen zusammen mit der Kategorie Good oder Bad). Definieren Sie dann ein beliebig neues Dokument und berechnen Sie für dieses die Kategorie, in welches es mit größter Wahrscheinlichkeit fällt. Benutzen Sie für den Test das in \n",
    "[NLP Vorlesung Document Classification](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/NaturalLanguageProcessing/WS1415/03TextClassification.pdf)\n",
    "ausführlich beschriebene Beispiel zu implementieren. Berechnen Sie die Klassifikatorausgabe des Satzes _the money jumps_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von RSS Newsfeeds\n",
    "Mit dem unten gegebenen Skript werden Nachrichten verschiedener Newsserver geladen und als String abgespeichert.\n",
    "\n",
    "**Aufgaben:**\n",
    "1. Trainieren Sie Ihren Naive Bayes Classifier mit allen Nachrichten der in den Listen _trainTech_ und _trainNonTech_ definierten Servern. Weisen Sie für das Training allen Nachrichten aus _trainTech_ die Kategorie _Tech_ und allen Nachrichten aus _trainNonTech_ die Kategorie _NonTech_ zu.\n",
    "2. Nach dem Training sollen alle Nachrichten aus der Liste _test_ vom Naive Bayes Classifier automatisch klassifiziert werden. Gehen Sie davon aus, dass alle Nachrichten von [http://rss.golem.de/rss.php?r=sw&feed=RSS0.91](http://rss.golem.de/rss.php?r=sw&feed=RSS0.91) tatsächlich von der Kategorie _Tech_ sind und alle Nachrichten von den beiden anderen Servern in der Liste _test_ von der Kategorie _NonTech_ sind. Bestimmen Sie die _Konfusionsmatrix_ und die _Accuracy_ sowie für beide Klassen _Precision, Recall_ und _F1-Score_. Diese Qualitätsmetriken sind z.B. in [NLP Vorlesung Document Classification](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/NaturalLanguageProcessing/WS1415/03TextClassification.pdf) definiert.\n",
    "3. Diskutieren Sie das Ergebnis\n",
    "4. Wie könnte die Klassifikationsgüte durch Modifikation der _getwords()_-Methode verbessert werden? Implementieren Sie diesen Ansatz und vergleichen Sie das Ergebnis mit dem des ersten Ansatzes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "\n",
    "def stripHTML(h):\n",
    "  p=''\n",
    "  s=0\n",
    "  for c in h:\n",
    "    if c=='<': s=1\n",
    "    elif c=='>':\n",
    "      s=0\n",
    "      p+=' '\n",
    "    elif s==0:\n",
    "      p+=c\n",
    "  return p\n",
    "\n",
    "\n",
    "trainTech=['http://rss.chip.de/c/573/f/7439/index.rss',\n",
    "           #'http://feeds.feedburner.com/netzwelt',\n",
    "           'http://rss1.t-online.de/c/11/53/06/84/11530684.xml',\n",
    "           'http://www.computerbild.de/rssfeed_2261.xml?node=13',\n",
    "           'http://www.heise.de/newsticker/heise-top-atom.xml']\n",
    "\n",
    "trainNonTech=['http://newsfeed.zeit.de/index',\n",
    "              'http://newsfeed.zeit.de/wirtschaft/index',\n",
    "              'http://www.welt.de/politik/?service=Rss',\n",
    "              'http://www.spiegel.de/schlagzeilen/tops/index.rss',\n",
    "              'http://www.sueddeutsche.de/app/service/rss/alles/rss.xml',\n",
    "              'http://www.faz.net/rss/aktuell/'\n",
    "              ]\n",
    "test=[\"http://rss.golem.de/rss.php?r=sw&feed=RSS0.91\",\n",
    "          'http://newsfeed.zeit.de/politik/index',  \n",
    "          'http://www.welt.de/?service=Rss'\n",
    "           ]\n",
    "\n",
    "countnews={}\n",
    "countnews['tech']=0\n",
    "countnews['nontech']=0\n",
    "countnews['test']=0\n",
    "print \"--------------------News from trainTech------------------------\"\n",
    "for feed in trainTech:\n",
    "    print \"*\"*30\n",
    "    print feed\n",
    "    f=feedparser.parse(feed)\n",
    "    for e in f.entries:\n",
    "      print '\\n---------------------------'\n",
    "      fulltext=stripHTML(e.title+' '+e.description)\n",
    "      print fulltext\n",
    "      countnews['tech']+=1\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "\n",
    "print \"--------------------News from trainNonTech------------------------\"\n",
    "for feed in trainNonTech:\n",
    "    print \"*\"*30\n",
    "    print feed\n",
    "    f=feedparser.parse(feed)\n",
    "    for e in f.entries:\n",
    "      print '\\n---------------------------'\n",
    "      fulltext=stripHTML(e.title+' '+e.description)\n",
    "      print fulltext\n",
    "      countnews['nontech']+=1\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "\n",
    "print \"--------------------News from test------------------------\"\n",
    "for feed in test:\n",
    "    print \"*\"*30\n",
    "    print feed\n",
    "    f=feedparser.parse(feed)\n",
    "    for e in f.entries:\n",
    "      print '\\n---------------------------'\n",
    "      fulltext=stripHTML(e.title+' '+e.description)\n",
    "      print fulltext\n",
    "      countnews['test']+=1\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "\n",
    "print 'Number of used trainings samples in categorie tech',countnews['tech']\n",
    "print 'Number of used trainings samples in categorie notech',countnews['nontech']\n",
    "print 'Number of used test samples',countnews['test']\n",
    "print '--'*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
