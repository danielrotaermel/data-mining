{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Document Classification\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 06.11.2015\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)\n",
    "\n",
    "# Einführung\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Dokumentklassifikation: Klassifikation von Dokumenten, insbesondere Emails und RSS Feed\n",
    "* Naive Bayes Classifier: Weit verbreitete Klassifikationsmethode, welche unter bestimmten Randbedingungen sehr gut skaliert.\n",
    "\n",
    "\n",
    "## Theorie zur Vorbereitung\n",
    "### Parametrische Klassifikation und Naive Bayes Methode\n",
    "Klassifikatoren müssen zu einer gegebenen Eingabe $\\underline{x}$ die zugehörige Klasse $C_i$ bestimmen. Mithilfe der Wahrscheinlichkeitstheorie kann diese Aufgabe wie folgt beschrieben werden: Bestimme für alle möglichen Klassen $C_i$ die bedingte Wahrscheinlichkeit $P(C_i | \\underline{x})$, also die Wahrscheinlichkeit, dass die gegebene Eingabe $\\underline{x}$ in Klasse $C_i$ fällt. Wähle dann die Klasse aus, für welche diese Wahrscheinlichkeit maximal ist.\n",
    "\n",
    "Die Entscheidungsregeln von Klassifikatoren können mit Methoden des \"\"überwachten Lernens\"\" aus Trainingsdaten ermittelt werden. Im Fall des **parametrischen Lernens** kann aus den Trainingsdaten die sogenannte **Likelihood-Funktion** $p(\\underline{x} \\mid C_i)$ bestimmt werden. _Anmerkung:_ Allgemein werden mit $p(...)$ kontinuierliche Wahrscheinlichkeitsfunktionen und mit $P(...)$ diskrete Wahrscheinlichkeitswerte bezeichnet. \n",
    "\n",
    "Mithilfe der **Bayes-Formel**\n",
    "$$\n",
    "P(C_i \\mid \\underline{x}) = \\frac{p(\\underline{x} \\mid C_i) \\cdot P(C_i)}{p(\\underline{x})}\n",
    "$$\n",
    "\n",
    "kann aus der Likelihood die **a-posteriori-Wahrscheinlichkeit $P(C_i \\mid \\underline{x})$** berechnet werden. Darin wird $P(C_i)$ die **a-priori-Wahrscheinlichkeit** und $p(\\underline{x})$ die **Evidenz** genannt. Die a-priori-Wahrscheinlichkeit kann ebenfalls aus den Trainingsdaten ermittelt werden. Die Evidenz ist für die Klassifikationsentscheidung nicht relevant, da sie für alle Klassen $C_i$ gleich groß ist.\n",
    "\n",
    "Die Berechnung der Likelihood-Funktion $p(\\underline{x} \\mid C_i)$ ist dann sehr aufwendig, wenn $\\underline{x}=(x_1,x_2,\\ldots,x_Z)$ ein Vektor von voneinander abhängigen Variablen $x_i$ ist. Bei der **Naive Bayes Classification** wird jedoch von der vereinfachenden Annahme ausgegangen, dass die Eingabevariabeln $x_i$ voneinander unabhängig sind. Dann vereinfacht sich die bedingte Verbundwahrscheinlichkeits-Funktion $p(x_1,x_2,\\ldots,x_Z \\mid C_i)$ zu:\n",
    "\n",
    "$$\n",
    "p(x_1,x_2,\\ldots,x_Z \\mid C_i)=\\prod\\limits_{j=1}^Z p(x_j | C_i)\n",
    "$$\n",
    "\n",
    "### Anwendung der Naive Bayes Methode in der Dokumentklassifikation\n",
    "Auf der rechten Seite der vorigen Gleichung stehen nur noch von den jeweils anderen Variablen unabhängige bedingte Wahrscheinlichkeiten. Im Fall der Dokumentklassifikation sind die einzelnen Worte die Variablen, d.h. ein Ausdruck der Form $P(x_j | C_i)$ gibt an mit welcher Wahrscheinlichkeit ein Wort $x_j=w$ in einem Dokument der Klasse $C_i$ vorkommt. \n",
    "Die Menge aller Variablen $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ ist dann die Menge aller Wörter im Dokument. Damit gibt die linke Seite in der oben gegebenen Gleichung die _Wahrscheinlichkeit, dass die Wörter $\\left\\{x_1,x_2,\\ldots,x_Z \\right\\}$ in einem Dokument der Klasse $C_i$ vorkommen_ an.\n",
    "\n",
    "Für jedes Wort _w_ wird aus den Trainingsdaten die Wahrscheinlichkeit $P(w|G)$, mit der das Wort in Dokumenten der Kategorie _Good_ und die Wahrscheinlichkeit $P(w|B)$ mit der das Wort in Dokumenten der Kategorie _Bad_ auftaucht ermittelt. Trainingsdokumente werden in der Form\n",
    "\n",
    "$$\n",
    "tD=(String,Category)\n",
    "$$\n",
    "eingegeben. \n",
    "\n",
    "Wenn \n",
    "\n",
    "* mit der Variable $fc(w,cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ in denen das Wort $w$ enthalten ist\n",
    "* mit der Variable $cc(cat)$ die Anzahl der Trainingsdokumente in Kategorie $cat$ \n",
    "\n",
    "gezählt wird, dann ist \n",
    "\n",
    "$$\n",
    "P(w|G)=\\frac{fc(w,G)}{cc(G)} \\quad \\quad P(w|B)=\\frac{fc(w,B)}{cc(B)}.\n",
    "$$\n",
    "\n",
    "Wird nun nach der Eingabe von $L$ Trainingsdokumenten ein neu zu klassifizierendes Dokument $D$ eingegeben und sei $W(D)$ die Menge aller Wörter in $D$, dann berechnen sich unter der Annahme, dass die Worte in $W(D)$ voneinander unabhängig sind (naive Bayes Annahme) die a-posteriori Wahrscheinlichkeiten zu:\n",
    "\n",
    "$$\n",
    "P(G|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | G) \\right) \\cdot P(G)}{p(D)}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B|D)=\\frac{\\left( \\prod\\limits_{w \\in W(D)} P(w | B) \\right) \\cdot P(B)}{p(D)}.\n",
    "$$\n",
    "\n",
    "Die hierfür notwendigen a-priori-Wahrscheinlichkeiten berechnen sich zu \n",
    "\n",
    "$$\n",
    "P(G)=\\frac{cc(G)}{L}\n",
    "$$\n",
    "und\n",
    "$$\n",
    "P(B)=\\frac{cc(B)}{L}\n",
    "$$\n",
    "\n",
    "Die Evidenz $p(D)$ beeinflusst die Entscheidung nicht und kann deshalb ignoriert werden.\n",
    "\n",
    "\n",
    "## Vor dem Versuch zu klärende Fragen\n",
    "\n",
    "\n",
    "1. Wie wird ein Naive Bayes Classifier trainiert? Was muss beim Training für die spätere Klassifikation abgespeichert werden?\n",
    "2. Wie teilt ein Naiver Bayes Classifier ein neues Dokument ein?\n",
    "3. Welche naive Annahme liegt dem Bayes Classifier zugrunde? Ist diese Annahme im Fall der Dokumentklassifikation tatsächlich gegeben?\n",
    "4. Betrachten Sie die Formeln für die Berechnung von $P(G|D)$ und $P(B|D)$. Welches Problem stellt sich ein, wenn in der Menge $W(D)$ ein Wort vorkommt, das nicht in den Trainingsdaten der Kategorie $G$ vorkommt und ein anderes Wort aus $W(D)$ nicht in den Trainingsdaten der Kategorie $B$ enthalten ist? Wie könnte dieses Problem gelöst werden? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1 Wie wird Bayes trainiert?\n",
    "Der Bayes Classifier wird mit Hilfe von Trainingstexten trainiert. Ein Trainingstext ist ein Text dessen Klasse bereits bekannt ist. Von jedem Text wird dann die Häufigkeit der einzelnen Wörter gezählt und nach Klassen abgespeichert.\n",
    "\n",
    "#### 2 Wie wird ein Dokument eingeteilt?\n",
    "1. Das Dokument wird in eine Liste umgewandelt. Die enthaltenen Wörter werden in eine Liste gespeichert.\n",
    "1. Danach wird für jedes einzelne Wort die Wahrscheinlichkeit der Wörter in der einzelnen Klasse berechnet.\n",
    "1. Anschließend werden all diese Wahrscheinlichkeiten, pro Klasse, miteinander multipliziert.\n",
    "1. Nun wird geschaut welche der einzelnen Kategorien, die höchste Trefferquote hat. (Wahrscheinlichkeit)\n",
    "1. Anschließend bekommt der ankommende Text die Klassifikation mit der höchsten Wahrscheinlichkeit.\n",
    "\n",
    "#### 3 Annahme beim naiven Bayes?\n",
    "Beim naiven Bayes wird davon ausgegangen das alle Wörter in einem Text unabhängig voneinander sind. \n",
    "##### 3.1 Naive\n",
    "Das heißt es wird nur die Wahrscheinlichkeit des Vorkommens *eines* Wortes unter der Bedingung einer bestimmten Klassifikation berechnet. \n",
    "###### 3.2 Bayes (Nicht naiv)\n",
    "Beim nicht naiven Bayes würde die Wahrscheinlichkeit des Vorkommens *aller* Wörter im zu untersuchenden Text unter Annahme einer Klassifikation berechnet. Da alle Wörter in der Zielmenge (Klasse) vorkommen die auch im zu klassifizierenden Text vorkommen, ist jedoch sehr unwahrscheinlich und daher für Texte nicht brauchbar. Zusätzlich würde die Berechnungszeit bei diesem Ansatz erheblich.\n",
    "##### 3.3 abhängig oder unabhänging?\n",
    "Die Annahme das die Wörter in einem Text unabhängig voneinander sind ist, schlichtweg falsch. Da jedoch der klassische Bayes nicht auf dieses Problem anwendbar ist und der naive Bayes zusätzlich ein sehr gutes, schnelles Ergebnis liefert, wird er trotzdem angewendet. Mathematisch ist diese Annahme jedoch nicht vertretbar.\n",
    "\n",
    "#### 4 Das Problem wenn das Wort nicht in den Trainingsdaten Vorhanden ist\n",
    "Die Wahrscheinlichkeit ob ein Wort zu einer Klasse gehört wird folgendermaßen berechnet:\n",
    "$$\n",
    "P(Klassifikation|Wort) = \\frac{Worthäufigkeit In Klassifikation} {Worthäufigkeit Über Alle Klassifikationen}\n",
    "$$\n",
    "\n",
    "Dies wird nun für alle Wörter im zu klassifizierenden Text gemacht. Die Ergebnisse der einzelne Zahlen werden dann wieder miteinander multipliziert.\n",
    "*Beispiel:* Eingabetext: {\"Hallo\", \"Du\"} Klasse: Egoistisch [(Hallo, 5), (Du,0)]\n",
    "$$\n",
    "P(Du|Egoistisch) = \\frac{0}{20} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(Hallo|Egoistisch) = \\frac{10}{50} = \\frac{1}{5}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(Hallo Du|Egoistisch) = \\frac{1}{5} * 0 = 0\n",
    "$$\n",
    "\n",
    "Ist also ein Wort im Eingabetext vorhanden,jedoch nicht in der Klasse ist deren Wahrscheinlichkeit 0. Diese wird anschließend mit den anderen Wahrscheinlichkeiten multipliziert. Was dazu führt dass, die Wahrscheinlichkeit '0' wird, egal wie gut der Rest des Eingabetextes auf die Klassifikation passt.\n",
    "\n",
    "*Lösung:*\n",
    "Eine Möglichkeit ist es einfach alle 0-Wahrscheinlichkeiten durch die sogenannte Pass-Wahrscheinlichkeit zu ersetzten:\n",
    "\n",
    "\n",
    "P<sub>ass,i</sub> = $ \\frac{1}{K} $ , mit [K]: Anzahl der Klassen.\n",
    "\n",
    "Somit wird eine Wahrscheinlichkeit eingesetzt, die in etwa der mittleren Wahrscheinlichkeit entspricht. Das hat zu Folge dass, das Ergebnis nur minimal verfälscht wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Feature Extraction/ -Selection\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie eine Funktion _getwords(doc)_, der ein beliebiges Dokument in Form einer String-Variablen übergeben wird. In der Funktion soll der String in seine Wörter zerlegt und jedes Wort in _lowercase_ transformiert werden. Wörter, die weniger als eine untere Grenze von Zeichen (z.B. 3) oder mehr als eine obere Grenze von Zeichen (z.B. 20) enthalten, sollen ignoriert werden. Die Funktion soll ein dictionary zurückgeben, dessen _Keys_ die Wörter sind. Die _Values_ sollen für jedes Wort zunächst auf $1$ gesetzt werden.\n",
    "\n",
    "**Tipp:** Benutzen Sie für die Zerlegung des Strings und für die Darstellung aller Wörter mit ausschließlich kleinen Buchstaben die Funktionen _split(), strip('sep')_ und _lower()_ der Klasse _String_.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from collections import defaultdict\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hallo': 1, 'test': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getwords(doc):\n",
    "    \"create lowercase word dict with keys between len(range(4,20))\"\n",
    "    word_dict = {}    \n",
    "    word_dict = {x.lower() : 1 for x in doc.split() if len(x) in range(4,20)}\n",
    "    return word_dict\n",
    "\n",
    "getwords(\"Hallo Hallo das ist ein Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier\n",
    "\n",
    "**Aufgabe:**\n",
    "Implementieren Sie den Naive Bayes Classifier für die Dokumentklassifikation. Es bietet sich an die Funktionalität des Klassifikators und das vom Klassifikator gelernte Wissen in einer Instanz einer Klasse _Classifier_ zu kapseln. In diesem Fall kann wie folgt vorgegangen werden:\n",
    "\n",
    "* Im Konstruktor der Klasse wird je ein Dictionary für die Instanzvariablen _fc_ und _cc_ (siehe oben) initialisiert. Dabei ist _fc_ ein verschachteltes Dictionary. Seine Keys sind die bisher gelernten Worte, die Values sind wiederum Dictionaries, deren Keys die Kategorien _Good_ und _Bad_ sind und deren Values zählen wie häufig das Wort bisher in Dokumenten der jeweiligen Kategorie auftrat. Das Dictionary _cc_ hat als Keys die Kategorien _Good_ und _Bad_. Die Values zählen wie häufig Dokumente der jeweiligen Kategorien bisher auftraten.\n",
    "* Im Konstruktor wird ferner der Instanzvariablen _getfeatures_ die Funktion _getwords()_ übergeben. Die Funktion _getwords()_ wurde bereits zuvor ausserhalb der Klasse definiert. Sinn dieses Vorgehens ist, dass andere Varianten um Merkmale aus Dokumenten zu extrahieren denkbar sind. Diese Varianten könnten dann ähnlich wie die _getwords()_-Funktion ausserhalb der Klasse definiert und beim Anlegen eines _Classifier_-Objekts der Instanzvariablen _getfeatures_ übergeben werden.  \n",
    "* Der Methode _incf(self,f,cat)_ wird ein Wort _f_ und die zugehörige Kategorie _cat_ des Dokuments in welchem es auftrat übergeben. In der Methode wird der _fc_-Zähler angepasst.\n",
    "* Der Methode _incc(self,cat)_ wird die Kategorie _cat_ des gerade eingelesenen Dokuments übergeben. In der Methode wird der _cc_-Zähler angepasst.\n",
    "* Die Methode _fcount(self,f,cat)_ gibt die Häufigkeit des Worts _f_ in den Dokumenten der Kategorie _cat_ zurück.\n",
    "* Die Methode _catcount(self,cat)_ gibt die Anzahl der Dokumente in der Kategorie _cat_ zurück.\n",
    "* Die Methode _totalcount(self)_ gibt die Anzahl aller Dokumente zurück.\n",
    "* Der Methode _train(self,item,cat)_ wird ein neues Trainingselement, bestehend aus der Betreffzeile (_item_) und der entsprechenden Kategorisierung (_cat_) übergeben. Der String _item_ wird mit der Instanzmethode _getfeatures_ (Diese referenziert _getwords()_) in Worte zerlegt. Für jedes einzelne Wort wird dann _incf(self,f,cat)_ aufgerufen. Ausserdem wird für das neue Trainingsdokument die Methode _incc(self,cat)_ aufgerufen.\n",
    "* Die Methode _fprob(self,f,cat)_ berechnet die bedingte Wahrscheinlichkeit $P(f | cat)$ des Wortes _f_ in der Kategorie _cat_ entsprechend der oben angegebenen Formeln, indem sie den aktuellen Stand des Zählers _fc(f,cat)_ durch den aktuellen Stand des Zählers _cc(cat)_ teilt.   \n",
    "* Die Methode _fprob(self,f,cat)_ liefert evtl. ungewollt extreme Ergebnisse, wenn noch wenig Wörter im Klassifizierer verbucht sind. Kommt z.B. ein Wort erst einmal in den Trainingsdaten vor, so wird seine Auftrittswahrscheinlichkeit in der Kategorie in welcher es nicht vorkommt gleich 0 sein. Um extreme Wahrscheinlichkeitswerte im Fall noch selten vorkommender Werte zu vermeiden, soll zusätzlich zur Methode _fprob(self,f,cat)_ die Methode _weightedprob(self,f,cat)_ implementiert und angewandt werden. Der von ihr zurückgegebene Wahrscheinlichkeitswert könnte z.B. wie folgt berechnet werden:$$wprob=\\frac{initprob+count \\cdot fprob(self,f,cat)}{1+count},$$ wobei $initprob$ ein initialer Wahrscheinlichkeitswert (z.B. 0.5) ist, welcher zurückgegeben werden soll, wenn das Wort noch nicht in den Trainingsdaten aufgetaucht ist. Die Variable $count$ zählt wie oft das Wort $f$ bisher in den Trainingsdaten auftrat. Wie zu erkennen ist, nimmt der Einfluss der initialen Wahrscheinlichkeit ab, je häufiger das Wort in den Trainingsdaten auftrat.\n",
    "* Nach dem Training soll ein beliebiges neues Dokument (Text-String) eingegeben werden können. Für dieses soll mit der Methode _prob(self,item,cat)_ die a-posteriori-Wahrscheinlichkeit $P(cat|item)$ (Aufgrund der Vernachlässigung der Evidenz handelt es sich hierbei genaugenommen um das Produkt aus a-posteriori-Wahrscheinlichkeit und Evidenz), mit der das Dokument _item_ in die Kategorie _cat_ fällt berechnet werden. Innerhalb der Methode _prob(self,item,cat)_ soll zunächst die Methode _weightedprob(self,f,cat)_ für alle Wörter $f$ im Dokument _item_ aufgerufen werden. Die jeweiligen Rückgabewerte von _weightedprob(self,f,cat)_ werden multipliziert. Das Produkt der Rückgabewerte von _weightedprob(self,f,cat)_ über alle Wörter $f$ im Dokument muss schließlich noch mit der a-priori Wahrscheinlichkeit $P(G)$ bzw. $P(B)$ entsprechend der oben aufgeführten Formeln multipliziert werden. Das Resultat des Produkts wird an das aufrufende Programm zurück gegeben, die Evidenz wird also vernachlässigt (wie oben begründet).\n",
    "\n",
    "\n",
    "\n",
    "Ein Dokument _item_ wird schließlich der Kategorie _cat_ zugeteilt, für welche die Funktion _prob(self,item,cat)_ den höheren Wert zurück gibt. Da die Rückgabewerte in der Regel sehr klein sind, werden in der Regel folgende Werte angezeigt. Wenn mit $g$ der Rückgabewert von _prob(self,item,cat=G)_ und mit $b$ der Rückgabewert von _prob(self,item,cat=B)_ bezeichnet wird dann ist die Wahrscheinlichkeit, dass $item$ in die Kategorie $G$ fällt, gleich:\n",
    "$$\n",
    "\\frac{g}{g+b}\n",
    "$$\n",
    "und die Wahrscheinlichkeit, dass $item$ in die Kategorie $B$ fällt, gleich:\n",
    "$$\n",
    "\\frac{b}{g+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classy:\n",
    "    \n",
    "    def __init__(self, getfeatures):\n",
    "        self.fc = defaultdict(lambda : defaultdict(int))\n",
    "        self.cc = defaultdict(int)\n",
    "        self.getfeatures = getfeatures\n",
    "    \n",
    "    def classify(self, item):\n",
    "        '''classifies item – returns the category to which the item most likely belongs'''\n",
    "        probs = self.allprobs(item)\n",
    "        return max(probs, key=probs.get)\n",
    "    \n",
    "    def allprobs(self, item):\n",
    "        '''calculates propabilities for all possible categories'''\n",
    "        return {cat: self.prob(item, cat) for cat in self.cc}\n",
    "    \n",
    "    def prob(self, item, cat):\n",
    "        '''a-posteriori-Wahrscheinlichkeit P(cat|item)'''\n",
    "        wprobsprod = reduce(mul, [self.weightedprob(f,cat) for f in self.getfeatures(item)])\n",
    "        return wprobsprod * self.cc[cat]/self.totalcount()\n",
    "    \n",
    "    def incc(self, cat):\n",
    "        'zählt cc (categoryCount) hoch'\n",
    "        self.cc[cat] += 1\n",
    "    \n",
    "    def incf(self, f, cat):\n",
    "        'zählt fc (featureCount) hoch'\n",
    "        self.fc[f][cat] += 1\n",
    "        \n",
    "    def fcount(self,f, cat=None):\n",
    "        if cat is None:\n",
    "            'gibt Häufigkeit des Word f zurück'\n",
    "            return sum(self.fc[f].values())  \n",
    "        else:\n",
    "            'gibt Häufigkeit des Word f einer bestimmten Cat zurück'\n",
    "            return self.fc[f][cat]\n",
    "               \n",
    "    def catcount(self,cat):\n",
    "        'gibt Häufigkeit einer category aus'\n",
    "        return self.cc[cat]\n",
    "    \n",
    "    def totalcount(self):\n",
    "        'gibt Anzahl aller documents aus'\n",
    "        return sum(self.cc.values())\n",
    "    \n",
    "    def train(self, item, cat):\n",
    "        'für item wird incc aufgerufen'\n",
    "        self.incc(cat)\n",
    "        \n",
    "        'features extrahieren'\n",
    "        features = self.getfeatures(item)\n",
    "        \n",
    "        'für jedes feature wird incf() aufgerufen'\n",
    "        for f in features:\n",
    "            self.incf(f,cat)\n",
    "   \n",
    "    def fprob(self,f,cat):\n",
    "        '''Die Methode fprob(self,f,cat) berechnet die bedingte Wahrscheinlichkeit  P(f|cat)\n",
    "        des Wortes f in der Kategorie cat entsprechend der oben angegebenen Formeln, indem sie \n",
    "        den aktuellen Stand des Zählers fc(f,cat) durch den aktuellen Stand des Zählers cc(cat) teilt.'''\n",
    "        return self.fcount(f,cat)/float(self.catcount(cat))\n",
    "        \n",
    "    def weightedprob(self,f,cat):\n",
    "        '''weighted = (0.5 + (count * fprob(self, f cat))) / (1 + count)'''\n",
    "        initprob = 0.5\n",
    "        count = self.fcount(f)\n",
    "        fprob = self.fprob(f,cat)\n",
    "        return (initprob + count * fprob)/(1 + count)\n",
    "\n",
    "##### testdaten #####   \n",
    "doc_list = pd.DataFrame([('Good', 'nobody owns the water'), ('Good', 'the quick rabbit jumps fences'),\n",
    "                         ('Good', 'make quick money at the online casino'), \n",
    "                         ('Good', 'next meeting is at night'), ('Bad', 'buy pharmaceuticals now'), \n",
    "                         ('Bad', 'the quick brown fox jumps'), \n",
    "                         ('Bad', 'meeting with your superstar'), ('Bad', 'money like water')])  \n",
    "labels = doc_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cc:\n",
      "{'Bad': 4, 'Good': 4}\n",
      "\n",
      "fc:\n",
      "{'brown': {'Bad': 1}, 'nobody': {'Good': 1}, 'money': {'Bad': 1, 'Good': 1}, 'like': {'Bad': 1}, 'meeting': {'Bad': 1, 'Good': 1}, 'jumps': {'Bad': 1, 'Good': 1}, 'casino': {'Good': 1}, 'make': {'Good': 1}, 'next': {'Good': 1}, 'water': {'Bad': 1, 'Good': 1}, 'pharmaceuticals': {'Bad': 1}, 'online': {'Good': 1}, 'rabbit': {'Good': 1}, 'night': {'Good': 1}, 'quick': {'Bad': 1, 'Good': 2}, 'superstar': {'Bad': 1}, 'fences': {'Good': 1}, 'with': {'Bad': 1}, 'your': {'Bad': 1}, 'owns': {'Good': 1}}\n",
      "\n",
      "fccount brown Bad: 1\n",
      "\n",
      "totalcount: 8\n",
      "\n",
      "fprob( Good | quick ) =  0.5\n",
      "\n",
      "fprob( Bad | quick ) =  0.25\n",
      "--------------------------------------------------------------------------------\n",
      "0.3125\n",
      "0.5\n",
      "buy pharmaceuticals now\n",
      "0.125\n",
      "Bad\n",
      "{'Bad': 0.1875, 'Good': 0.125}\n"
     ]
    }
   ],
   "source": [
    "def to_dict(d):\n",
    "    '''helper class – converts defaultdict to regular dict'''\n",
    "    if isinstance(d, defaultdict):\n",
    "        d = {k: to_dict(v) for k, v in d.iteritems()}\n",
    "    return d\n",
    "\n",
    "c = Classy(getwords)\n",
    "\n",
    "for index, row in doc_list.iterrows():\n",
    "    #print type(row), row[0], row[1]\n",
    "    cat = row[0]\n",
    "    item = row[1]\n",
    "    c.train(item, cat)\n",
    "\n",
    "print '\\ncc:\\n',to_dict(c.cc)\n",
    "print '\\nfc:\\n',to_dict(c.fc)\n",
    "\n",
    "print '\\nfccount brown Bad:',c.fcount('brown', 'Bad')\n",
    "print '\\ntotalcount:',c.totalcount()\n",
    "\n",
    "f = 'quick'\n",
    "good = 'Good'\n",
    "bad = 'Bad'\n",
    "\n",
    "print '\\nfprob(', good, '|', f, ') = ', c.fprob(f,good)\n",
    "print '\\nfprob(', bad, '|', f, ') = ', c.fprob(f,bad)\n",
    "\n",
    "print '-'*80\n",
    "\n",
    "print c.weightedprob(f,bad)\n",
    "print c.weightedprob(f,good)\n",
    "\n",
    "doc = doc_list.iloc[4][1]\n",
    "print doc\n",
    "print c.prob(doc ,good)\n",
    "print c.classify(doc)\n",
    "print c.allprobs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# möglicherweise können wir das training optional im constructor abarbeiten, wenn daten und mitgegeben werden\n",
    "#c = Classy(labels, doc_list, getwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "**Aufgabe:**\n",
    "Instanzieren Sie ein Objekt der Klasse _Classifier_ und übergeben Sie der _train()_ Methode dieser Klasse mindestens 8 kategorisierte Dokumente (Betreffzeilen als Stringvariablen zusammen mit der Kategorie Good oder Bad). Definieren Sie dann ein beliebig neues Dokument und berechnen Sie für dieses die Kategorie, in welches es mit größter Wahrscheinlichkeit fällt. Benutzen Sie für den Test das in \n",
    "[NLP Vorlesung Document Classification](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/NaturalLanguageProcessing/WS1415/03TextClassification.pdf)\n",
    "ausführlich beschriebene Beispiel zu implementieren. Berechnen Sie die Klassifikatorausgabe des Satzes _the money jumps_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klassifikation von RSS Newsfeeds\n",
    "Mit dem unten gegebenen Skript werden Nachrichten verschiedener Newsserver geladen und als String abgespeichert.\n",
    "\n",
    "* Das Skript haben wir erweitert sodass es uns einen Dataframe für Test und Training erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------News from trainTech------------------------\n",
      "******************************\n",
      "http://www.chip.de/rss/rss_tests.xml\n",
      "******************************\n",
      "http://rss1.t-online.de/c/11/53/06/84/11530684.xml\n",
      "******************************\n",
      "http://www.computerbild.de/rssfeed_2261.xml?node=13\n",
      "******************************\n",
      "http://www.heise.de/newsticker/heise-top-atom.xml\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "--------------------News from trainNonTech------------------------\n",
      "******************************\n",
      "http://newsfeed.zeit.de/index\n",
      "******************************\n",
      "http://newsfeed.zeit.de/wirtschaft/index\n",
      "******************************\n",
      "http://www.welt.de/politik/?service=Rss\n",
      "******************************\n",
      "http://www.spiegel.de/schlagzeilen/tops/index.rss\n",
      "******************************\n",
      "http://www.sueddeutsche.de/app/service/rss/alles/rss.xml\n",
      "******************************\n",
      "http://www.faz.net/rss/aktuell/\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "--------------------News from test------------------------\n",
      "******************************\n",
      "http://rss.golem.de/rss.php?r=sw&feed=RSS0.91\n",
      "******************************\n",
      "http://newsfeed.zeit.de/politik/index\n",
      "******************************\n",
      "http://www.welt.de/?service=Rss\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "Number of used trainings samples in categorie tech 115\n",
      "Number of used trainings samples in categorie nontech 121\n",
      "Number of used test samples 85\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "rssfeeds = pd.DataFrame(columns=['label','text','source'])\n",
    "testRssfeeds = pd.DataFrame(columns=['label','text','source'])\n",
    "\n",
    "def stripHTML(h):\n",
    "  p=''\n",
    "  s=0\n",
    "  for c in h:\n",
    "    if c=='<': s=1\n",
    "    elif c=='>':\n",
    "      s=0\n",
    "      p+=' '\n",
    "    elif s==0:\n",
    "      p+=c\n",
    "  return p\n",
    "\n",
    "\n",
    "trainTech=['http://www.chip.de/rss/rss_tests.xml',\n",
    "           #'http://feeds.feedburner.com/netzwelt',\n",
    "           'http://rss1.t-online.de/c/11/53/06/84/11530684.xml',\n",
    "           'http://www.computerbild.de/rssfeed_2261.xml?node=13',\n",
    "           'http://www.heise.de/newsticker/heise-top-atom.xml']\n",
    "\n",
    "trainNonTech=['http://newsfeed.zeit.de/index',\n",
    "              'http://newsfeed.zeit.de/wirtschaft/index',\n",
    "              'http://www.welt.de/politik/?service=Rss',\n",
    "              'http://www.spiegel.de/schlagzeilen/tops/index.rss',\n",
    "              'http://www.sueddeutsche.de/app/service/rss/alles/rss.xml',\n",
    "              'http://www.faz.net/rss/aktuell/'\n",
    "              ]\n",
    "test=[\"http://rss.golem.de/rss.php?r=sw&feed=RSS0.91\",\n",
    "          'http://newsfeed.zeit.de/politik/index',  \n",
    "          'http://www.welt.de/?service=Rss'\n",
    "           ]\n",
    "\n",
    "countnews={}\n",
    "countnews['tech']=0\n",
    "countnews['nontech']=0\n",
    "countnews['test']=0\n",
    "print \"--------------------News from trainTech------------------------\"\n",
    "for feed in trainTech:\n",
    "    print \"*\"*30\n",
    "    print feed\n",
    "    f=feedparser.parse(feed)\n",
    "    for e in f.entries:\n",
    "      #print '\\n---------------------------'\n",
    "      if 'summary' in e.keys() and 'title' in e.keys():\n",
    "        fulltext=stripHTML(e.title+' '+e.description)\n",
    "        rssfeeds = rssfeeds.append(pd.DataFrame({'label': 'tech','text': fulltext, 'source': feed}, index=[0]), ignore_index=True)\n",
    "        countnews['tech']+=1\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "\n",
    "print \"--------------------News from trainNonTech------------------------\"\n",
    "for feed in trainNonTech:\n",
    "    print \"*\"*30\n",
    "    print feed\n",
    "    f=feedparser.parse(feed)\n",
    "    for e in f.entries:\n",
    "      #print '\\n---------------------------'\n",
    "      if 'summary' in e.keys() and 'title' in e.keys():\n",
    "        fulltext=stripHTML(e.title+' '+e.description)\n",
    "        rssfeeds = rssfeeds.append(pd.DataFrame({'label': 'nontech','text': fulltext, 'source': feed}, index=[0]), ignore_index=True)      \n",
    "        countnews['nontech']+=1\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "\n",
    "\n",
    "print \"--------------------News from test------------------------\"\n",
    "for feed in test:\n",
    "    print \"*\"*30\n",
    "    print feed\n",
    "    f=feedparser.parse(feed)\n",
    "    for e in f.entries:\n",
    "      #print '\\n---------------------------'\n",
    "      if 'summary' in e.keys() and 'title' in e.keys():    \n",
    "        fulltext=stripHTML(e.title+' '+e.description)\n",
    "        testRssfeeds = testRssfeeds.append(pd.DataFrame({'text': fulltext, 'source': feed}, index=[0]), ignore_index=True)            \n",
    "        countnews['test']+=1\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "print \"----------------------------------------------------------------\"\n",
    "\n",
    "print 'Number of used trainings samples in categorie tech',countnews['tech']\n",
    "print 'Number of used trainings samples in categorie nontech',countnews['nontech']\n",
    "print 'Number of used test samples',countnews['test']\n",
    "print '--'*30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ausgabe der Dokumente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rssfeeds:\n",
      "       label                                             source  \\\n",
      "173  nontech            http://www.welt.de/politik/?service=Rss   \n",
      "82      tech  http://www.heise.de/newsticker/heise-top-atom.xml   \n",
      "30      tech  http://rss1.t-online.de/c/11/53/06/84/11530684...   \n",
      "205  nontech  http://www.sueddeutsche.de/app/service/rss/all...   \n",
      "44      tech  http://www.computerbild.de/rssfeed_2261.xml?no...   \n",
      "152  nontech            http://www.welt.de/politik/?service=Rss   \n",
      "14      tech  http://rss1.t-online.de/c/11/53/06/84/11530684...   \n",
      "87      tech  http://www.heise.de/newsticker/heise-top-atom.xml   \n",
      "183  nontech  http://www.spiegel.de/schlagzeilen/tops/index.rss   \n",
      "212  nontech  http://www.sueddeutsche.de/app/service/rss/all...   \n",
      "\n",
      "                                                  text  \n",
      "173  Leere Flüchtlingsunterkünfte kosten die Kommun...  \n",
      "82   Europäisches Leistungsschutzrecht: EU-Kommissi...  \n",
      "30   „FIFA 18“ über eine Million Mal verkauft Der B...  \n",
      "205  Vom schmalen Grat der Meinungsfreiheit  Unser ...  \n",
      "44   Game of Thrones – Staffel 8: Finale verschiebt...  \n",
      "152  „Brigitte Macron ist wie besessen von einer ei...  \n",
      "14   Französische Justiz ermittelt gegen Druckerher...  \n",
      "87   Windows 10: Insider-Preview mit Ausblick auf v...  \n",
      "183  \"Fire and Fury\"-Autor Wolff im Radio: \"Das wir...  \n",
      "212  Im Allgäu liegt ein Ursprung der Menschenrecht...  \n",
      "\n",
      " testRssfeeds:\n",
      "   label                                         source  \\\n",
      "72   NaN                http://www.welt.de/?service=Rss   \n",
      "9    NaN  http://rss.golem.de/rss.php?r=sw&feed=RSS0.91   \n",
      "29   NaN  http://rss.golem.de/rss.php?r=sw&feed=RSS0.91   \n",
      "58   NaN                http://www.welt.de/?service=Rss   \n",
      "77   NaN                http://www.welt.de/?service=Rss   \n",
      "33   NaN  http://rss.golem.de/rss.php?r=sw&feed=RSS0.91   \n",
      "24   NaN  http://rss.golem.de/rss.php?r=sw&feed=RSS0.91   \n",
      "43   NaN          http://newsfeed.zeit.de/politik/index   \n",
      "18   NaN  http://rss.golem.de/rss.php?r=sw&feed=RSS0.91   \n",
      "65   NaN                http://www.welt.de/?service=Rss   \n",
      "\n",
      "                                                 text  \n",
      "72  Ajax Amsterdam soll Herzfehler verheimlicht ha...  \n",
      "9   Open Source: Die Community gewinnt - fast imme...  \n",
      "29  Nouveau: Nvidia baut neues Grafikspeicher-API ...  \n",
      "58  Vierter Ausbrecher bei Taschendiebstahl wieder...  \n",
      "77  Die schmutzigen Tricks der falschen Vermieter ...  \n",
      "33  Streaming-Device: Amazon bringt Browser auf Fi...  \n",
      "24  Myloc/Webtropia: Offene VNC-Ports ermöglichten...  \n",
      "43  Iran: Sonderkommission prüft Schicksal inhafti...  \n",
      "18  DWD-Wetter-App: 170.000 Kunden haben für die W...  \n",
      "65  „So lädt man die Leute geradezu zum Rassismus ...  \n"
     ]
    }
   ],
   "source": [
    "print 'rssfeeds:\\n', rssfeeds.sample(10)\n",
    "print '\\n testRssfeeds:\\n', testRssfeeds.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgaben:**  \n",
    "1.  \n",
    "Trainieren Sie Ihren Naive Bayes Classifier mit allen Nachrichten der in den Listen _trainTech_ und _trainNonTech_ definierten Servern. Weisen Sie für das Training allen Nachrichten aus _trainTech_ die Kategorie _Tech_ und allen Nachrichten aus _trainNonTech_ die Kategorie _NonTech_ zu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rssC = Classy(getwords)\n",
    "\n",
    "for index, row in rssfeeds.iterrows():\n",
    "    #print type(row), row[0], row[1]\n",
    "    cat = row[0]\n",
    "    item = row[2]\n",
    "    rssC.train(item, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * Test der Klassifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digitalisierung tech : 0.123940677966\n",
      "Digitalisierung nontech : 0.128177966102\n",
      "\n",
      "Industrie nontech : 0.130296610169\n",
      "Industrie tech : 0.121822033898\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "TestDoc:\n",
      "Android 8.0: Oreo-Update für Oneplus Five wird wieder verteilt Oneplus verteilt für das Smartphone Five wieder das Update auf Android 8.0 alias Oreo. Zwischenzeitlich war die Verteilung unterbrochen worden, weil zu viele Fehler entdeckt wurden. Auf manchen Geräten lässt sich das Update aber immer noch nicht ohne Weiteres aufspielen. ( Oneplus Five ,  Applikationen )  \n",
      "\n",
      "result: tech -> {'tech': 5.8668294964869796e-21, 'nontech': 3.412458284901765e-21}\n"
     ]
    }
   ],
   "source": [
    "tech = 'tech'\n",
    "nontech = 'nontech'\n",
    "\n",
    "print 'Digitalisierung',  tech, ':', rssC.prob('Digitalisierung',tech)\n",
    "print 'Digitalisierung',  nontech, ':', rssC.prob('Digitalisierung',nontech)\n",
    "\n",
    "print '\\nIndustrie', nontech, ':', rssC.prob('Industrie',nontech)\n",
    "print 'Industrie', tech, ':', rssC.prob('Industrie',tech)\n",
    "\n",
    "print '-'*80\n",
    "\n",
    "testdoc = testRssfeeds.iloc[0][2] # nontech\n",
    "\n",
    "print '\\nTestDoc:\\n', testdoc\n",
    "print '\\nresult:', rssC.classify(testdoc), '->', rssC.allprobs(testdoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"2\">\n",
    "<li>Nach dem Training sollen alle Nachrichten aus der Liste _test_ vom Naive Bayes Classifier automatisch\n",
    "klassifiziert werden. Gehen Sie davon aus, dass alle Nachrichten von [http://rss.golem.de/rss.php?r=sw&feed=RSS0.91](http://rss.golem.de/rss.php?r=sw&feed=RSS0.91) tatsächlich von der Kategorie _Tech_ sind und alle Nachrichten von den beiden anderen Servern in der Liste _test_ von der Kategorie _NonTech_ sind. Bestimmen Sie die _Konfusionsmatrix_ und die _Accuracy_ sowie für beide Klassen _Precision, Recall_ und _F1-Score_. Diese Qualitätsmetriken sind z.B. in [NLP Vorlesung Document Classification](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/NaturalLanguageProcessing/WS1415/03TextClassification.pdf) definiert.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified Documents: {'tech': 115, 'nontech': 121}\n"
     ]
    }
   ],
   "source": [
    "testRssfeedsCopy = testRssfeeds.copy()\n",
    "\n",
    "# set tech where source is http://rss.golem.de/rss.php?r=sw&feed=RSS0.91\n",
    "testRssfeedsCopy.loc[testRssfeeds.source=='http://rss.golem.de/rss.php?r=sw&feed=RSS0.91','label'] = 'tech'\n",
    "# set nontech where source is not http://rss.golem.de/rss.php?r=sw&feed=RSS0.91\n",
    "testRssfeedsCopy.loc[testRssfeeds.source!='http://rss.golem.de/rss.php?r=sw&feed=RSS0.91','label'] = 'nontech'\n",
    "\n",
    "#classify test documents\n",
    "for index, row in testRssfeeds.iterrows():\n",
    "    testRssfeeds['label'][index] = rssC.classify(row['text'])\n",
    "print '\\nClassified Documents:', to_dict(rssC.cc)\n",
    "\n",
    "#print testRssfeeds.head(10)\n",
    "#print originatedTestRssfeeds.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Confusion matrix, without normalization\n",
      "[[13  0  0]\n",
      " [ 0 10  6]\n",
      " [ 0  0  9]]\n",
      "Normalized confusion matrix\n",
      "[[ 1.    0.    0.  ]\n",
      " [ 0.    0.62  0.38]\n",
      " [ 0.    0.    1.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAEmCAYAAAA0k8gFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1066be810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEmCAYAAADfpHMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0e7d9850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"3\">\n",
    "<li>Diskutieren Sie das Ergebnis</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol start=\"4\">\n",
    "<li>Wie könnte die Klassifikationsgüte durch Modifikation der _getwords()_-Methode verbessert werden? Implementieren Sie diesen Ansatz und vergleichen Sie das Ergebnis mit dem des ersten Ansatzes.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dani test code\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib \n",
    "    \n",
    "    \n",
    "def create_fc(labels,data):\n",
    "    \n",
    "    combined = pd.concat([labels,data], axis=1)\n",
    "    \n",
    "    fc = {}\n",
    "    \n",
    "    unique_labels = labels.unique()\n",
    "    empty_labels_dict =  {ulabel: 0 for ulabel in unique_labels}\n",
    "                    \n",
    "    # loop over combined data\n",
    "    for i,row in combined.iterrows():\n",
    "        label, words =  row[row.index[0]], row[row.index[1]].lower().split()\n",
    "        \n",
    "        for word in words:\n",
    "            if word not in fc:\n",
    "                fc[word] = empty_labels_dict.copy()\n",
    "            if word in fc:\n",
    "                fc[word][label] += 1\n",
    "    \n",
    "    return fc    \n",
    "    \n",
    "def create_cc(labels):\n",
    "    unique_labels = labels.unique()\n",
    "    return {j: labels.loc[labels==unique_labels[i]].size for i,j in enumerate(unique_labels)}\n",
    "    \n",
    "\n",
    "print create_fc(rssfeeds['label'],rssfeeds['text'])\n",
    "\n",
    "print create_cc(rssfeeds['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbenutzter code\n",
    "def create_fc(self):\n",
    "        'erzeugt ein Dict über alle Wörter(Keys) und zeigt wie oft ein Wort in einer Klasse vorkommt'\n",
    "        combined = pd.concat([self.labels,self.doc_list[1]], axis=1)\n",
    "        fc = {}\n",
    "    \n",
    "        # erzeuge leeres labels dict\n",
    "        unique_labels = self.labels.unique()\n",
    "        empty_labels_dict =  {ulabel: 0 for ulabel in unique_labels}\n",
    "\n",
    "        # loop über kombinierte daten \n",
    "        for i,row in combined.iterrows():\n",
    "            # erzeuge label pro row (wordliste)\n",
    "            label, words =  row[row.index[0]], row[row.index[1]].lower().split()\n",
    "            for word in words:\n",
    "                # falls word nicht in fc, erzeuge es und einen leeres labels dict\n",
    "                if word not in fc:\n",
    "                    fc[word] = empty_labels_dict.copy()\n",
    "                # falls word in fc zähle counter hoch\n",
    "                if word in fc:\n",
    "                    fc[word][label] += 1\n",
    "        return fc\n",
    "    \n",
    "    def create_cc(self):\n",
    "        'erzeugt Dict und zählt ein Label hoch, wenn ein Dokument einem Label zugewiesen wurde'\n",
    "        unique = self.labels.unique()\n",
    "        cc = {j: self.labels.loc[self.labels==unique[i]].size for i,j in enumerate(unique)}\n",
    "        return cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
