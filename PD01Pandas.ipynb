{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pandas for real-world data\n",
    "In the previous notebook Numpy arrays have been introduced. Numpy arrays provide an efficient data structure for clean, numerical data. However, in practise the quality of data is often more challenging. There can be missing data and lots of different data types. Moreover, accessing data only by integer indices may be cumbersome. More meaningful indices would be desirable.\n",
    "**Pandas** is a newer python package, which builds on top of numpy arrays and extends it with many features, which provide a much more efficient managing of practical data. Pandas provides\n",
    "\n",
    "* methods to cope with missing data and different data types, \n",
    "* methods to label columns and rows for a comfortable data access\n",
    "* functions, which are familiar to users of database- and spreadsheet frameworks, such as complex queries, filters, joins, pivots, ...\n",
    "* methods for comfortable data visualisation (on top of Matplotlib)\n",
    "\n",
    "The fundamental data structures of Pandas are _Series_ and _Dataframes_. Both of them apply a third important structure, the _Index_. The basics of these datastructures are introduced in this notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Pandas and check version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Pandas Series\n",
    "Pandas Series can be considered to be 1-dimensional numpy arrays with an explicitly configurable index.\n",
    "### Construction of Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series object:    \n",
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n",
      "Values of series object:  [10 20 30 40]\n",
      "Type of series values:    <type 'numpy.ndarray'>\n",
      "Index of series object:   Int64Index([0, 1, 2, 3], dtype='int64')\n",
      "Type of series index:     <class 'pandas.core.index.Int64Index'>\n"
     ]
    }
   ],
   "source": [
    "S1=pd.Series(data=[10,20,30,40])\n",
    "print \"Pandas Series object:    \\n\",S1\n",
    "print \"Values of series object: \",S1.values\n",
    "print \"Type of series values:   \",type(S1.values)\n",
    "print \"Index of series object:  \",S1.index\n",
    "print \"Type of series index:    \",type(S1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Series object:    \n",
      "2014    19.5\n",
      "2015    20.3\n",
      "2016    18.7\n",
      "2017    17.0\n",
      "dtype: float64\n",
      "Values of series object:  [ 19.5  20.3  18.7  17. ]\n",
      "Type of series values:    <type 'numpy.ndarray'>\n",
      "Index of series object:   Index([u'2014', u'2015', u'2016', u'2017'], dtype='object')\n",
      "Type of series index:     <class 'pandas.core.index.Index'>\n"
     ]
    }
   ],
   "source": [
    "pd.Series()\n",
    "S2=pd.Series(index=[\"2014\",\"2015\",\"2016\",\"2017\"],data=[19.5,20.3,18.7,17.0])\n",
    "print \"Pandas Series object:    \\n\",S2\n",
    "print \"Values of series object: \",S2.values\n",
    "print \"Type of series values:   \",type(S2.values)\n",
    "print \"Index of series object:  \",S2.index\n",
    "print \"Type of series index:    \",type(S2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas series can be directly generated from Python dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'September': 16012, 'July': 15511, 'June': 14789, 'August': 15517}\n"
     ]
    }
   ],
   "source": [
    "RegisteredUsersDict={\"June\":14789,\"July\":15511,\"August\":15517,\"September\":16012}\n",
    "print RegisteredUsersDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "August       15517\n",
      "July         15511\n",
      "June         14789\n",
      "September    16012\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "RegisteredUsersSeries=pd.Series(RegisteredUsersDict)\n",
    "print RegisteredUsersSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Pandas Series data\n",
    "Accessing single elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20.3\n"
     ]
    }
   ],
   "source": [
    "print S1[1]\n",
    "print S2[\"2015\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data structure with an explicitly defined index is already available in Python: the _dictionary_. However, pandas series provide more capabilities, e.g. for the query of slices over a key-range, such as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice of S1:\n",
      "1    20\n",
      "2    30\n",
      "dtype: int64\n",
      "\n",
      "Slice of S2:\n",
      "2015    20.3\n",
      "2016    18.7\n",
      "2017    17.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print \"Slice of S1:\\n\",S1[1:3] \n",
    "print \"\\nSlice of S2:\\n\",S2[\"2015\":\"2017\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the index has been defined explicitly, it is always possible to asscess by integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015    20.3\n",
      "2016    18.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print S2[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possibilty to access elements by the explicitly defined index and the implicit integer index may yield confusions, in particular if the explicitly defined index also contains integers. Therefore it is recommended to access elements by _.loc[]_ and _.iloc[]._ The former provides access by explicitly defined index and the latter by the implicit integer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015    20.3\n",
       "2016    18.7\n",
       "2017    17.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.loc[\"2015\":\"2017\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015    20.3\n",
       "2016    18.7\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014    19.5\n",
      "2016    18.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print S2[(S2<20) & (S2>18)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new element to series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: \n",
      "2014    19.5\n",
      "2015    20.3\n",
      "2016    18.7\n",
      "2017    17.0\n",
      "dtype: float64\n",
      "\n",
      "After: \n",
      "2014    19.5\n",
      "2015    20.3\n",
      "2016    18.7\n",
      "2017    17.0\n",
      "2018    17.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print \"Before: \\n\",S2\n",
    "S2[\"2018\"]=17.7\n",
    "print \"\\nAfter: \\n\",S2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Pandas Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Series can be considered to be 2-dimensional numpy arrays with an explicitly configurable index.\n",
    "\n",
    "### Construction of Pandas Dataframes\n",
    "Create dataframe from nested Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataframe object:    \n",
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "\n",
      "Values of dataframe object: \n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Type of dataframe values:    <type 'numpy.ndarray'>\n",
      "Index of dataframe object:   Int64Index([0, 1], dtype='int64')\n",
      "Type of dataframe index:     <class 'pandas.core.index.Int64Index'>\n",
      "Columns of dataframe object: Int64Index([0, 1, 2], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "DF1=pd.DataFrame(data=[[1,2,3],[4,5,6]])\n",
    "print \"Pandas dataframe object:    \\n\",DF1\n",
    "print \"\\nValues of dataframe object: \\n\",DF1.values\n",
    "print \"\\nType of dataframe values:   \",type(DF1.values)\n",
    "print \"Index of dataframe object:  \",DF1.index\n",
    "print \"Type of dataframe index:    \",type(DF1.index)\n",
    "print \"Columns of dataframe object:\",DF1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe with explicitly defined index and labeled column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataframe object:    \n",
      "       gender  age\n",
      "peter    male   23\n",
      "paul     male   31\n",
      "mary   female   25\n",
      "\n",
      "Values of dataframe object: \n",
      "[['male' 23L]\n",
      " ['male' 31L]\n",
      " ['female' 25L]]\n",
      "\n",
      "Type of dataframe values:    <type 'numpy.ndarray'>\n",
      "Index of dataframe object:   Index([u'peter', u'paul', u'mary'], dtype='object')\n",
      "Type of dataframe index:     <class 'pandas.core.index.Index'>\n",
      "Columns of dataframe object: Index([u'gender', u'age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "DF2=pd.DataFrame(index=[\"peter\",\"paul\",\"mary\"],columns=[\"gender\",\"age\"],data=[[\"male\",23],[\"male\",31],[\"female\",25]])\n",
    "print \"Pandas dataframe object:    \\n\",DF2\n",
    "print \"\\nValues of dataframe object: \\n\",DF2.values\n",
    "print \"\\nType of dataframe values:   \",type(DF2.values)\n",
    "print \"Index of dataframe object:  \",DF2.index\n",
    "print \"Type of dataframe index:    \",type(DF2.index)\n",
    "print \"Columns of dataframe object:\",DF2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe from Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas dataframe object:    \n",
      "   0  1  2  3  4  5  6\n",
      "0  2  5  5  8  1  0  9\n",
      "1  4  8  5  4  5  6  3\n",
      "2  8  7  3  6  0  7  6\n",
      "\n",
      "Values of dataframe object: \n",
      "[[2 5 5 8 1 0 9]\n",
      " [4 8 5 4 5 6 3]\n",
      " [8 7 3 6 0 7 6]]\n",
      "\n",
      "Type of dataframe values:    <type 'numpy.ndarray'>\n",
      "Index of dataframe object:   Int64Index([0, 1, 2], dtype='int64')\n",
      "Type of dataframe index:     <class 'pandas.core.index.Int64Index'>\n",
      "Columns of dataframe object: Int64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr= np.random.randint(0,10,(3,7))\n",
    "DF3=pd.DataFrame(arr)\n",
    "print \"Pandas dataframe object:    \\n\",DF3\n",
    "print \"\\nValues of dataframe object: \\n\",DF3.values\n",
    "print \"\\nType of dataframe values:   \",type(DF3.values)\n",
    "print \"Index of dataframe object:  \",DF3.index\n",
    "print \"Type of dataframe index:    \",type(DF3.index)\n",
    "print \"Columns of dataframe object:\",DF3.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename index and columns of dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A  B  C  D  E  F  G\n",
      "user1  2  5  5  8  1  0  9\n",
      "user2  4  8  5  4  5  6  3\n",
      "user3  8  7  3  6  0  7  6\n"
     ]
    }
   ],
   "source": [
    "DF3.columns=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"]\n",
    "DF3.index= [\"user1\",\"user2\",\"user3\"]\n",
    "print DF3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert new column into existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gender  age       home\n",
      "peter    male   23   new york\n",
      "paul     male   31  san diego\n",
      "mary   female   25     Boston\n"
     ]
    }
   ],
   "source": [
    "hometown=['new york','san diego','Boston']\n",
    "DF2[\"home\"]=hometown\n",
    "print DF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section the Pandas series _RegisteredUsersSeries_ has been defined. From such a series object dataframes can be constructed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Users\n",
      "August     15517\n",
      "July       15511\n",
      "June       14789\n",
      "September  16012\n"
     ]
    }
   ],
   "source": [
    "RegisteredUsersDF=pd.DataFrame(RegisteredUsersSeries,columns=[\"Users\"])\n",
    "print RegisteredUsersDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe from list of dictionaries. Note that even though not all dictionaries have the same keys the dataframe can be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 13, 'name': 'ben'}, {'age': 15, 'name': 'lucia'}, {'age': 11, 'name': 'lynn'}, {'name': 'eve'}]\n"
     ]
    }
   ],
   "source": [
    "personDict=[{\"name\":\"ben\",\"age\":13},{\"name\":\"lucia\",\"age\":15},{\"name\":\"lynn\",\"age\":11},{\"name\":\"eve\"}]\n",
    "print personDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age   name\n",
      "0   13    ben\n",
      "1   15  lucia\n",
      "2   11   lynn\n",
      "3  NaN    eve\n"
     ]
    }
   ],
   "source": [
    "personDF=pd.DataFrame(personDict)\n",
    "print personDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Accessing Pandas Dataframe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single column of a dataframe can be accessed by specifying the name of the column such as e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peter     new york\n",
      "paul     san diego\n",
      "mary        Boston\n",
      "Name: home, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print DF2[\"home\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peter     new york\n",
      "paul     san diego\n",
      "mary        Boston\n",
      "Name: home, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print DF2.home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, __a single row can not be accessed in this way__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF2[\"peter\"] or DF2[0] raises an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A possibility to access a single row would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  age      home\n",
      "peter   male   23  new york\n"
     ]
    }
   ],
   "source": [
    "print DF2[\"peter\":\"peter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  age      home\n",
      "peter   male   23  new york\n"
     ]
    }
   ],
   "source": [
    "print DF2[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already mentioned in the context of Pandas Series objects, this type of indexing is confusing and it is recommended to apply _.loc[]_ and _.iloc[]_ instead.\n",
    "\n",
    "Access of single row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender        male\n",
      "age             23\n",
      "home      new york\n",
      "Name: peter, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print DF2.loc[\"peter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender        male\n",
      "age             23\n",
      "home      new york\n",
      "Name: peter, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print DF2.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access element in dedicated row and column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york\n"
     ]
    }
   ],
   "source": [
    "print DF2.loc[\"peter\",\"home\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york\n"
     ]
    }
   ],
   "source": [
    "print DF2.iloc[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access dedicated subframe of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age      home\n",
      "peter   23  new york\n",
      "mary    25    Boston\n"
     ]
    }
   ],
   "source": [
    "print DF2.loc[[\"peter\",\"mary\"],[\"age\",\"home\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age      home\n",
      "peter   23  new york\n",
      "mary    25    Boston\n"
     ]
    }
   ],
   "source": [
    "print DF2.iloc[[0,2],[1,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Ranges in Pandas\n",
    "Data is often associated to date- and time-stamps. In particular time-series data consists of a series of uni- or multi-variate data instances, where each instance is labeled with an unique date-time-stamp. In Pandas date-time ranges can be created by the _date_range()_ method as shown below. The first parameter defines the start of the date-time range, the _periods_-parameter defines the number of instances and the _freq_-parameter defines the duration between successive date-time-stamps.\n",
    "\n",
    "Date-time range with a frequency of 2-days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-10-03', '2016-10-05', '2016-10-07', '2016-10-09',\n",
      "               '2016-10-11', '2016-10-13'],\n",
      "              dtype='datetime64[ns]', freq='2D')\n"
     ]
    }
   ],
   "source": [
    "dates1 = pd.date_range('20161003', periods=6,freq=\"2D\")\n",
    "print dates1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date-time range with a frequency of 45 minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-10-03 10:45:00', '2016-10-03 11:30:00',\n",
      "               '2016-10-03 12:15:00', '2016-10-03 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq='45T')\n"
     ]
    }
   ],
   "source": [
    "dates2 = pd.date_range('20161003104500', periods=4,freq=\"45Min\")\n",
    "print dates2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements of a date-time range are _timestamps_. Single _timestamps_-objects can be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-12-23 09:15:00\n",
      "2017-01-09 10:30:00\n"
     ]
    }
   ],
   "source": [
    "dec23=pd.Timestamp(pd.datetime(2016,12,23,9,15,0))\n",
    "jan9=pd.Timestamp(pd.datetime(2017,1,9,10,30,0))\n",
    "print dec23\n",
    "print jan9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations like adding a time-delta to a given timestamp or calculating the number of days can be performed like e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.tslib.Timestamp'>\n",
      "2016-11-14 00:00:00\n",
      "6 days 00:00:00\n",
      "17 days 01:15:00\n",
      "23 days 01:15:00\n"
     ]
    }
   ],
   "source": [
    "print type(dates1[1])\n",
    "print dates1[1]+20\n",
    "datediff1=dates1[4]-dates1[1]\n",
    "print datediff1\n",
    "datediff2=jan9-dec23\n",
    "print datediff2\n",
    "print datediff1 + datediff2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas date-time-ranges are often applied as index for series or dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-03    10\n",
      "2016-10-05    11\n",
      "2016-10-07    12\n",
      "2016-10-09    13\n",
      "2016-10-11    14\n",
      "2016-10-13    15\n",
      "Freq: 2D, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "TS1=pd.Series(index=dates1,data=np.arange(10,16))\n",
    "print TS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-29    0\n",
      "2016-10-01    1\n",
      "2016-10-03    2\n",
      "2016-10-05    3\n",
      "2016-10-07    4\n",
      "Freq: 2D, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "dates2 = pd.date_range('20160929', periods=5,freq=\"2D\")\n",
    "TS2=pd.Series(index=dates2,data=np.arange(5))\n",
    "print TS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      C1   C2   C3\n",
      "2016-10-03 00:00:00  168  177  113\n",
      "2016-10-03 10:30:00  118  117  181\n",
      "2016-10-03 21:00:00  196  126  188\n",
      "2016-10-04 07:30:00  191  157  107\n",
      "2016-10-04 18:00:00  199  139  107\n"
     ]
    }
   ],
   "source": [
    "dates3 = pd.date_range('20161003', periods=5,freq=\"10H30MIN\")\n",
    "TDF1=pd.DataFrame(index=dates3,data=np.random.randint(100,200,(5,3)),columns=[\"C1\",\"C2\",\"C3\"])\n",
    "print TDF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      C3   C4   C5\n",
      "2016-10-03 11:00:00  149  140  100\n",
      "2016-10-03 11:00:10  115  148  179\n",
      "2016-10-03 11:00:20  164  189  171\n",
      "2016-10-03 11:00:30  148  155  180\n",
      "2016-10-03 11:00:40  155  195  178\n",
      "2016-10-03 11:00:50  187  155  163\n",
      "2016-10-03 11:01:00  187  125  123\n",
      "2016-10-03 11:01:10  126  106  154\n",
      "2016-10-03 11:01:20  193  118  161\n",
      "2016-10-03 11:01:30  143  100  183\n"
     ]
    }
   ],
   "source": [
    "dates4 = pd.date_range('20161003110000', periods=10,freq=\"10S\")\n",
    "TDF2=pd.DataFrame(index=dates4,data=np.random.randint(100,200,(10,3)),columns=[\"C3\",\"C4\",\"C5\"])\n",
    "print TDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Series and Dataframes\n",
    "Series and dataframes can be combined by the methods _combine()_ and _combine_first()_. Application of _combine_first()_ is demonstrated below. If 2 series _S1_, and _S2_ are combined by _S1.combine_first(S2)_ the result is a new Series-object whose index is the union of the index elements in _S1_ and _S2_. For each element in the new index the corresponding value is\n",
    "* the value of _S1_ at this index-element, if _S1_ contains this index-element.\n",
    "* the value of _S2_ at this index-element, if _S1_ does not contain this index-element\n",
    "\n",
    "If 2 dataframes _DF1_, and _DF2_ are combined by _DF1.combine_first(DF2)_ the result is a new Dataframe-object whose index is the union of the index elements in _DF1_ and _DF2_ and whose columns are the union of the columns in _DF1_ and _DF2_. For each element in the resulting dataframe the value is\n",
    "* the value of _DF1_ at this index/column-element, if _DF1_ contains this index/column-element.\n",
    "* the value of _DF2_ at this index/column-element, if _DF1_ does not contain this index/column-element, but _DF2_ contains it\n",
    "* _NAN_ if neither _DF1_ nor _DF2_ contains this index/column-element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time Series TS1=\n",
      "2016-10-03    10\n",
      "2016-10-05    11\n",
      "2016-10-07    12\n",
      "2016-10-09    13\n",
      "2016-10-11    14\n",
      "2016-10-13    15\n",
      "Freq: 2D, dtype: int32\n",
      "\n",
      "Time Series TS2=\n",
      "2016-09-29    0\n",
      "2016-10-01    1\n",
      "2016-10-03    2\n",
      "2016-10-05    3\n",
      "2016-10-07    4\n",
      "Freq: 2D, dtype: int32\n",
      "\n",
      "Combination of TS1 and TS2 is TS3=\n",
      "2016-09-29     0\n",
      "2016-10-01     1\n",
      "2016-10-03    10\n",
      "2016-10-05    11\n",
      "2016-10-07    12\n",
      "2016-10-09    13\n",
      "2016-10-11    14\n",
      "2016-10-13    15\n",
      "Freq: 2D, dtype: float64\n",
      "------------------------------\n",
      "\n",
      "Dataframe TDF1=\n",
      "                      C1   C2   C3\n",
      "2016-10-03 00:00:00  168  177  113\n",
      "2016-10-03 10:30:00  118  117  181\n",
      "2016-10-03 21:00:00  196  126  188\n",
      "2016-10-04 07:30:00  191  157  107\n",
      "2016-10-04 18:00:00  199  139  107\n",
      "\n",
      "Dataframe TDF2=\n",
      "                      C3   C4   C5\n",
      "2016-10-03 11:00:00  149  140  100\n",
      "2016-10-03 11:00:10  115  148  179\n",
      "2016-10-03 11:00:20  164  189  171\n",
      "2016-10-03 11:00:30  148  155  180\n",
      "2016-10-03 11:00:40  155  195  178\n",
      "2016-10-03 11:00:50  187  155  163\n",
      "2016-10-03 11:01:00  187  125  123\n",
      "2016-10-03 11:01:10  126  106  154\n",
      "2016-10-03 11:01:20  193  118  161\n",
      "2016-10-03 11:01:30  143  100  183\n",
      "\n",
      "Combination of TDF1 and TDF2 is TSDF1=\n",
      "                      C1   C2   C3   C4   C5\n",
      "2016-10-03 00:00:00  168  177  113  NaN  NaN\n",
      "2016-10-03 10:30:00  118  117  181  NaN  NaN\n",
      "2016-10-03 11:00:00  NaN  NaN  149  140  100\n",
      "2016-10-03 11:00:10  NaN  NaN  115  148  179\n",
      "2016-10-03 11:00:20  NaN  NaN  164  189  171\n",
      "2016-10-03 11:00:30  NaN  NaN  148  155  180\n",
      "2016-10-03 11:00:40  NaN  NaN  155  195  178\n",
      "2016-10-03 11:00:50  NaN  NaN  187  155  163\n",
      "2016-10-03 11:01:00  NaN  NaN  187  125  123\n",
      "2016-10-03 11:01:10  NaN  NaN  126  106  154\n",
      "2016-10-03 11:01:20  NaN  NaN  193  118  161\n",
      "2016-10-03 11:01:30  NaN  NaN  143  100  183\n",
      "2016-10-03 21:00:00  196  126  188  NaN  NaN\n",
      "2016-10-04 07:30:00  191  157  107  NaN  NaN\n",
      "2016-10-04 18:00:00  199  139  107  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "print \"\\nTime Series TS1=\\n\",TS1\n",
    "print \"\\nTime Series TS2=\\n\",TS2\n",
    "TS3=TS1.combine_first(TS2)\n",
    "print \"\\nCombination of TS1 and TS2 is TS3=\\n\",TS3\n",
    "print \"-\"*30\n",
    "print \"\\nDataframe TDF1=\\n\",TDF1\n",
    "print \"\\nDataframe TDF2=\\n\",TDF2\n",
    "TSDF1=TDF2.combine_first(TDF1)\n",
    "print \"\\nCombination of TDF1 and TDF2 is TSDF1=\\n\",TSDF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling of Missing Data\n",
    "One of the main features of _Pandas_ is it's capability to manage missing data. As shown in the example above, Series- and Dataframe-elements without assigned data are represented by _NaN_, which is actually Numpy's _numpy.nan_ value. A boolean mask, which identifies all dataframe-elements with missing data (NaN-values) can be calculated as follows. It contains _True_ at all _NaN_-positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        C1     C2     C3     C4     C5\n",
      "2016-10-03 00:00:00  False  False  False   True   True\n",
      "2016-10-03 10:30:00  False  False  False   True   True\n",
      "2016-10-03 11:00:00   True   True  False  False  False\n",
      "2016-10-03 11:00:10   True   True  False  False  False\n",
      "2016-10-03 11:00:20   True   True  False  False  False\n",
      "2016-10-03 11:00:30   True   True  False  False  False\n",
      "2016-10-03 11:00:40   True   True  False  False  False\n",
      "2016-10-03 11:00:50   True   True  False  False  False\n",
      "2016-10-03 11:01:00   True   True  False  False  False\n",
      "2016-10-03 11:01:10   True   True  False  False  False\n",
      "2016-10-03 11:01:20   True   True  False  False  False\n",
      "2016-10-03 11:01:30   True   True  False  False  False\n",
      "2016-10-03 21:00:00  False  False  False   True   True\n",
      "2016-10-04 07:30:00  False  False  False   True   True\n",
      "2016-10-04 18:00:00  False  False  False   True   True\n"
     ]
    }
   ],
   "source": [
    "print TSDF1.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In combination with _all()_ and _any()_ the _isnull()_-method can also be applied to check whether all columns or all rows or any column or any row contain missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all elements in a column of TSDF1 NaN?\n",
      "C1    False\n",
      "C2    False\n",
      "C3    False\n",
      "C4    False\n",
      "C5    False\n",
      "dtype: bool\n",
      "\n",
      "Is any element in a column of TSDF1 NaN?\n",
      "C1     True\n",
      "C2     True\n",
      "C3    False\n",
      "C4     True\n",
      "C5     True\n",
      "dtype: bool\n",
      "\n",
      "Are all elements in a row of TSDF1 NaN?\n",
      "2016-10-03 00:00:00    False\n",
      "2016-10-03 10:30:00    False\n",
      "2016-10-03 11:00:00    False\n",
      "2016-10-03 11:00:10    False\n",
      "2016-10-03 11:00:20    False\n",
      "2016-10-03 11:00:30    False\n",
      "2016-10-03 11:00:40    False\n",
      "2016-10-03 11:00:50    False\n",
      "2016-10-03 11:01:00    False\n",
      "2016-10-03 11:01:10    False\n",
      "2016-10-03 11:01:20    False\n",
      "2016-10-03 11:01:30    False\n",
      "2016-10-03 21:00:00    False\n",
      "2016-10-04 07:30:00    False\n",
      "2016-10-04 18:00:00    False\n",
      "dtype: bool\n",
      "\n",
      "Is any element in a row of TSDF1 NaN?\n",
      "2016-10-03 00:00:00    True\n",
      "2016-10-03 10:30:00    True\n",
      "2016-10-03 11:00:00    True\n",
      "2016-10-03 11:00:10    True\n",
      "2016-10-03 11:00:20    True\n",
      "2016-10-03 11:00:30    True\n",
      "2016-10-03 11:00:40    True\n",
      "2016-10-03 11:00:50    True\n",
      "2016-10-03 11:01:00    True\n",
      "2016-10-03 11:01:10    True\n",
      "2016-10-03 11:01:20    True\n",
      "2016-10-03 11:01:30    True\n",
      "2016-10-03 21:00:00    True\n",
      "2016-10-04 07:30:00    True\n",
      "2016-10-04 18:00:00    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print \"Are all elements in a column of TSDF1 NaN?\\n\",TSDF1.isnull().all(axis=0)\n",
    "print \"\\nIs any element in a column of TSDF1 NaN?\\n\",TSDF1.isnull().any(axis=0)\n",
    "print \"\\nAre all elements in a row of TSDF1 NaN?\\n\",TSDF1.isnull().all(axis=1)\n",
    "print \"\\nIs any element in a row of TSDF1 NaN?\\n\",TSDF1.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _dropna()_-method can be applied to drop all columns or rows, in which at least one or in which all elements are NaN. The following use of _dropna()_ drops all columns, which contain at least one _NaN_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      C3\n",
      "2016-10-03 00:00:00  113\n",
      "2016-10-03 10:30:00  181\n",
      "2016-10-03 11:00:00  149\n",
      "2016-10-03 11:00:10  115\n",
      "2016-10-03 11:00:20  164\n",
      "2016-10-03 11:00:30  148\n",
      "2016-10-03 11:00:40  155\n",
      "2016-10-03 11:00:50  187\n",
      "2016-10-03 11:01:00  187\n",
      "2016-10-03 11:01:10  126\n",
      "2016-10-03 11:01:20  193\n",
      "2016-10-03 11:01:30  143\n",
      "2016-10-03 21:00:00  188\n",
      "2016-10-04 07:30:00  107\n",
      "2016-10-04 18:00:00  107\n"
     ]
    }
   ],
   "source": [
    "TSDF2=TSDF1.copy()\n",
    "print TSDF2.dropna(axis=1,how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NaN_-values can be replaced by any other value using the _fillna()_ method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      C1   C2   C3   C4   C5\n",
      "2016-10-03 00:00:00  168  177  113    0    0\n",
      "2016-10-03 10:30:00  118  117  181    0    0\n",
      "2016-10-03 11:00:00    0    0  149  140  100\n",
      "2016-10-03 11:00:10    0    0  115  148  179\n",
      "2016-10-03 11:00:20    0    0  164  189  171\n",
      "2016-10-03 11:00:30    0    0  148  155  180\n",
      "2016-10-03 11:00:40    0    0  155  195  178\n",
      "2016-10-03 11:00:50    0    0  187  155  163\n",
      "2016-10-03 11:01:00    0    0  187  125  123\n",
      "2016-10-03 11:01:10    0    0  126  106  154\n",
      "2016-10-03 11:01:20    0    0  193  118  161\n",
      "2016-10-03 11:01:30    0    0  143  100  183\n",
      "2016-10-03 21:00:00  196  126  188    0    0\n",
      "2016-10-04 07:30:00  191  157  107    0    0\n",
      "2016-10-04 18:00:00  199  139  107    0    0\n"
     ]
    }
   ],
   "source": [
    "TSDF3=TSDF1.fillna(value=0.0)\n",
    "print TSDF3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split, Concatenate and Join\n",
    "Pandas dataframes can be splitted into parts using the common slicing approach as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part 0\n",
      "                      C1   C2   C3  C4  C5\n",
      "2016-10-03 00:00:00  168  177  113   0   0\n",
      "2016-10-03 10:30:00  118  117  181   0   0\n",
      "\n",
      "Part 1\n",
      "                     C1  C2   C3   C4   C5\n",
      "2016-10-03 11:00:00   0   0  149  140  100\n",
      "2016-10-03 11:00:10   0   0  115  148  179\n",
      "2016-10-03 11:00:20   0   0  164  189  171\n",
      "2016-10-03 11:00:30   0   0  148  155  180\n",
      "2016-10-03 11:00:40   0   0  155  195  178\n",
      "2016-10-03 11:00:50   0   0  187  155  163\n",
      "2016-10-03 11:01:00   0   0  187  125  123\n",
      "2016-10-03 11:01:10   0   0  126  106  154\n",
      "2016-10-03 11:01:20   0   0  193  118  161\n",
      "2016-10-03 11:01:30   0   0  143  100  183\n",
      "\n",
      "Part 2\n",
      "                      C1   C2   C3  C4  C5\n",
      "2016-10-03 21:00:00  196  126  188   0   0\n",
      "2016-10-04 07:30:00  191  157  107   0   0\n",
      "2016-10-04 18:00:00  199  139  107   0   0\n"
     ]
    }
   ],
   "source": [
    "parts=[TSDF3[:2],TSDF3[2:12],TSDF3[12:]]\n",
    "for i,p in enumerate(parts):\n",
    "    print \"\\nPart %1d\\n\"%i,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several dataframes can be concatenated. For this the parts must be assigned to a python list, which is passed to the Pandas method _concat()_. Vertical concatenation is realised by setting the parameter _axis=0_. For horizontal concatenation this parameter must be _1_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      C1   C2   C3   C4   C5\n",
      "2016-10-03 00:00:00  168  177  113    0    0\n",
      "2016-10-03 10:30:00  118  117  181    0    0\n",
      "2016-10-03 11:00:00    0    0  149  140  100\n",
      "2016-10-03 11:00:10    0    0  115  148  179\n",
      "2016-10-03 11:00:20    0    0  164  189  171\n",
      "2016-10-03 11:00:30    0    0  148  155  180\n",
      "2016-10-03 11:00:40    0    0  155  195  178\n",
      "2016-10-03 11:00:50    0    0  187  155  163\n",
      "2016-10-03 11:01:00    0    0  187  125  123\n",
      "2016-10-03 11:01:10    0    0  126  106  154\n",
      "2016-10-03 11:01:20    0    0  193  118  161\n",
      "2016-10-03 11:01:30    0    0  143  100  183\n",
      "2016-10-03 21:00:00  196  126  188    0    0\n",
      "2016-10-04 07:30:00  191  157  107    0    0\n",
      "2016-10-04 18:00:00  199  139  107    0    0\n"
     ]
    }
   ],
   "source": [
    "All=pd.concat(parts,axis=0)\n",
    "print All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL-stile joins can be performed on pandas dataframes by applying the _merge()_-method. The _on_-parameter of the _merge()_-method takes a list, whose elements are the keys on which the join shall be performed. The keys must be column names, which exist in both dataframes. The _how_-parameter of the _merge()_-method is used to specify the type of join. The type of join defines how to create the new dataframe in the case that some key-combinations do not exist in both dataframes:\n",
    "* _inner_: The joined dataframe contains only rows, whose key-combinations exist in both dataframes\n",
    "* _outer_: The joined dataframe contains all rows, whose key-combinations exist either in the left, the right or in both dataframes\n",
    "* _left_: The joined dataframe contains all rows, whose key-combinations exist in the left dataframe\n",
    "* _right_: The joined dataframe contains all rows, whose key-combinations exist in the right dataframe\n",
    "\n",
    "Examples of all join-types are demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age familyname firstname gender\n",
      "0   21       aman     peter      m\n",
      "1   18       bman      paul      m\n",
      "2   23       cman      mary      f\n",
      "  familyname firstname      home  phone\n",
      "0       aman     peter  new york   1234\n",
      "1       bman      paul    boston   4789\n",
      "2       dman      mary   florida   9856\n"
     ]
    }
   ],
   "source": [
    "group1=pd.DataFrame({\"firstname\":[\"peter\",\"paul\",\"mary\"],\"familyname\":[\"aman\",\"bman\",\"cman\"],\"age\":[21,18,23],\"gender\":[\"m\",\"m\",\"f\"]})\n",
    "print group1\n",
    "group2=pd.DataFrame({\"firstname\":[\"peter\",\"paul\",\"mary\"],\"familyname\":[\"aman\",\"bman\",\"dman\"],\"home\":[\"new york\",\"boston\",\"florida\"],\"phone\":[1234,4789,9856]})\n",
    "print group2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age familyname firstname gender      home  phone\n",
      "0   21       aman     peter      m  new york   1234\n",
      "1   18       bman      paul      m    boston   4789\n"
     ]
    }
   ],
   "source": [
    "groupInner=pd.merge(group1, group2, on=['firstname','familyname'],how=\"inner\")\n",
    "print groupInner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age familyname firstname gender      home  phone\n",
      "0   21       aman     peter      m  new york   1234\n",
      "1   18       bman      paul      m    boston   4789\n",
      "2   23       cman      mary      f       NaN    NaN\n",
      "3  NaN       dman      mary    NaN   florida   9856\n"
     ]
    }
   ],
   "source": [
    "groupOuter=pd.merge(group1, group2, on=['firstname','familyname'],how=\"outer\")\n",
    "print groupOuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age familyname firstname gender      home  phone\n",
      "0   21       aman     peter      m  new york   1234\n",
      "1   18       bman      paul      m    boston   4789\n",
      "2   23       cman      mary      f       NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "groupLeft=pd.merge(group1, group2, on=['firstname','familyname'],how=\"left\")\n",
    "print groupLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age familyname firstname gender      home  phone\n",
      "0   21       aman     peter      m  new york   1234\n",
      "1   18       bman      paul      m    boston   4789\n",
      "2  NaN       dman      mary    NaN   florida   9856\n"
     ]
    }
   ],
   "source": [
    "groupRight=pd.merge(group1, group2, on=['firstname','familyname'],how=\"right\")\n",
    "print groupRight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Operations on Pandas Series and Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "    0   1   2\n",
      "0   3   6   9\n",
      "1  12  15  18\n",
      "    0   1   2\n",
      "0   4   8  12\n",
      "1  16  20  24\n"
     ]
    }
   ],
   "source": [
    "print DF1\n",
    "DF2=3*DF1\n",
    "print DF2\n",
    "print DF1.add(DF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy operations on Pandas Series and Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  4  5  6\n"
     ]
    }
   ],
   "source": [
    "print DF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "\n",
      "log2 of series values:\n",
      "0    3.321928\n",
      "1    4.321928\n",
      "2    4.906891\n",
      "3    5.321928\n",
      "dtype: float64\n",
      "\n",
      "log2 of dataframe values:\n",
      "   0         1         2\n",
      "0  0  1.000000  1.584963\n",
      "1  2  2.321928  2.584963\n",
      "----------------------------------------\n",
      "\n",
      "Sinus of series values:\n",
      "0   -0.544021\n",
      "1    0.912945\n",
      "2   -0.988032\n",
      "3    0.745113\n",
      "dtype: float64\n",
      "\n",
      "Sinus of dataframe values:\n",
      "          0         1         2\n",
      "0  0.841471  0.909297  0.141120\n",
      "1 -0.756802 -0.958924 -0.279415\n",
      "----------------------------------------\n",
      "\n",
      "Second power of series values:\n",
      "0     100\n",
      "1     400\n",
      "2     900\n",
      "3    1600\n",
      "dtype: int64\n",
      "\n",
      "Second power of dataframe values:\n",
      "    0   1   2\n",
      "0   1   4   9\n",
      "1  16  25  36\n"
     ]
    }
   ],
   "source": [
    "print \"-\"*40\n",
    "print \"\\nlog2 of series values:\\n\",np.log2(S1)\n",
    "print \"\\nlog2 of dataframe values:\\n\",np.log2(DF1)\n",
    "\n",
    "print \"-\"*40\n",
    "print \"\\nSinus of series values:\\n\",np.sin(S1)\n",
    "print \"\\nSinus of dataframe values:\\n\",np.sin(DF1)\n",
    "\n",
    "print \"-\"*40\n",
    "print \"\\nSecond power of series values:\\n\",np.power(S1,2)\n",
    "print \"\\nSecond power of dataframe values:\\n\",np.power(DF1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which series value are in the specified range:\n",
      "2016-09-29    False\n",
      "2016-10-01    False\n",
      "2016-10-03    False\n",
      "2016-10-05     True\n",
      "2016-10-07     True\n",
      "Freq: 2D, dtype: bool\n",
      "\n",
      "Maximum value in series:\n",
      "4\n",
      "\n",
      "Index of maximum value\n",
      "2016-10-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print \"Which series value are in the specified range:\\n\",TS2.between(3,8)\n",
    "print \"\\nMaximum value in series:\\n\",TS2.max()\n",
    "print \"\\nIndex of maximum value\\n\",TS2.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Read from and Write to Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CSV File IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age familyname firstname gender      home  phone\n",
      "0   21       aman     peter      m  new york   1234\n",
      "1   18       bman      paul      m    boston   4789\n",
      "2  NaN       dman      mary    NaN   florida   9856\n"
     ]
    }
   ],
   "source": [
    "print groupRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupRight.to_csv(\"groupRight.csv\",sep=\",\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "newgroupRight=pd.read_csv(\"groupRight.csv\",sep=\",\",encoding=\"utf-8\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age familyname firstname gender      home  phone\n",
      "0   21       aman     peter      m  new york   1234\n",
      "1   18       bman      paul      m    boston   4789\n",
      "2  NaN       dman      mary    NaN   florida   9856\n"
     ]
    }
   ],
   "source": [
    "print newgroupRight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Write Data to SQLite\n",
    "In order to write to and read from databases a *sqlalchemy*-engine must be created, which provides the connection to the database:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine # database connection\n",
    "disk_engine = create_engine('sqlite:///dmTutorial.db')\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code-snippet data is read into a Pandas data frame and stored from the dataframe to the database. Note, that it is not necessary to import the entire .csv file into the dataframe. Instead the user can define the size of chunks, which are imported into the dataframe. Importing and processing data in chunks is recommended for very large amounts of data. In the example below the file is very small. Chunk-by-chunk processing is not necessary in this case. The example shall just demonstrate how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of table is:  groupRight\n"
     ]
    }
   ],
   "source": [
    "csvfilename=\"groupRight.csv\"\n",
    "tablename=csvfilename[:-4]\n",
    "print \"Name of table is: \",tablename\n",
    "chunksize = 2\n",
    "index_start = 1\n",
    "for df in pd.read_csv(csvfilename, chunksize=chunksize, iterator=True, encoding='utf-8'):\n",
    "    df.index += index_start\n",
    "    df.to_sql(tablename, disk_engine, if_exists='append')\n",
    "    index_start = df.index[-1] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Data from SQLite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>familyname</th>\n",
       "      <th>firstname</th>\n",
       "      <th>gender</th>\n",
       "      <th>home</th>\n",
       "      <th>phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>aman</td>\n",
       "      <td>peter</td>\n",
       "      <td>m</td>\n",
       "      <td>new york</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>bman</td>\n",
       "      <td>paul</td>\n",
       "      <td>m</td>\n",
       "      <td>boston</td>\n",
       "      <td>4789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dman</td>\n",
       "      <td>mary</td>\n",
       "      <td>None</td>\n",
       "      <td>florida</td>\n",
       "      <td>9856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  age familyname firstname gender      home  phone\n",
       "0      1           0   21       aman     peter      m  new york   1234\n",
       "1      2           1   18       bman      paul      m    boston   4789\n",
       "2      3           2  NaN       dman      mary   None   florida   9856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_sql_query('SELECT * FROM groupRight', disk_engine)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>firstname</th>\n",
       "      <th>familyname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>peter</td>\n",
       "      <td>aman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age firstname familyname\n",
       "0   21     peter       aman"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfq = pd.read_sql_query('SELECT age,firstname,familyname FROM groupRight WHERE age >20', disk_engine)\n",
    "display(dfq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "564px",
   "left": "0px",
   "right": "1138px",
   "top": "106px",
   "width": "270px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
