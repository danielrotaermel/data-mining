{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Versuch Mobile User Analysis and Gender-Age-Group Prediction\n",
    "* Autor: Prof. Dr. Johannes Maucher\n",
    "* Datum: 04.10.2016\n",
    "\n",
    "[Übersicht Ipython Notebooks im Data Mining Praktikum](Data Mining Praktikum.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung\n",
    "\n",
    "## Kurzbeschreibung:\n",
    "\n",
    "In diesem Versuch werden die im Rahmen eines Kaggle-Contest [von _TalkingData_ bereitgestellten Daten](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) analysiert. Die Daten enthalten für eine große Menge chinesischer User, Angaben zur Marke und Modell des Smartphones und zu den installierten und aktiven Apps. Ziel ist es aus den zur Verfügung stehenden Trainingsdaten ein Modell zu erlernen, das die Klassifikation der User in die jeweilige Gender-Age-Gruppe erlaubt. Für die Lösung dieser Aufgabe müssen sämtliche Schritte der Data Mining Prozesskette implementiert werden:\n",
    "\n",
    "1. Datenbeschaffung und Zugriff\n",
    "2. Datenauswahl: Welche der vorhandenen Daten sind für die gegebene Aufgabe tatsächlich relevant\n",
    "3. Datenbereinigung: Wie wird mit fehlenden und fehlerhaften Daten umgegangen?\n",
    "4. Datentransformation: Wie können aus den vorhandenen Daten informative Mermale gewonnen werden?\n",
    "5. Modellbildung: Unüberwachtes oder überwachtes erlernen eines Modells; Clustering-, Klassifikations- oder Regressionsmodell.\n",
    "6. Evaluation, Visualisierung und Interpretation der Daten/Ergebnisse\n",
    "\n",
    "## Lernziele:\n",
    "In diesem Versuch sollen Kenntnisse in folgenden Themen vermittelt werden:\n",
    "\n",
    "* Zugriff auf Daten in .csv Files\n",
    "* Zugriff auf Daten in SQLite Files\n",
    "* Statistische Analyse und Visualisierung von Daten\n",
    "* Implementierung der oben genannten Data Mining Prozessschritte, insbesondere:\n",
    "\n",
    "    * Feature-Engineering: Berechnung von für die gegebene Aufgabe relevanter Daten aus Rohdaten\n",
    "    * Clustering (unüberwachtes Lernen) \n",
    "    * Klassifikation/Prädiktion (überwachtes Lernen) mit verschiedenen Machine Learning Verfahren\n",
    "    * Evaluation von Klassifikationsverfahren\n",
    "\n",
    "## Aufgaben zur Vorbereitung\n",
    "\n",
    "1. Laden Sie die Daten entweder vom Skripteserver oder direkt von [Kaggle](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) herunter und versuchen Sie die Daten anhand dieser [Beschreibung](https://www.kaggle.com/c/talkingdata-mobile-user-demographics/data) zu verstehen.\n",
    "2. In diesem Versuch soll die Gender-Age-Group von Smartphone-Usern vorhergesagt werden. Überlegen Sie sich welche der vorhandenen Daten für diese Vorhersage relevant sein könnten.\n",
    "3. Für die Vorhersage kann ein beliebiger Klassifikationsalgorithmus aus dem Bereich des überwachten Lernens eingesetzt werden. Das Prinzip des überwachten Lernens und das entsprechende Testen des gelernten Modells ist in der unten aufgeführten Abbildung dargestellt. Machen Sie sich mit diesem Prinzip vertraut.\n",
    "\n",
    "4. Für das überwachte Lernen sind gelabelte Daten (Soll-Ausgabe) notwendig. In diesem Versuch ist die Ausgabe die Gender-Age-Group der User. Im File *gender\\_age\\_train.csv* ist für 74645 User (devices) die zugehörigen Gender-Age-Group angegeben. Die Menge aller gelabelten Daten muss für die Modellvalidierung in disjunkte Trainings- und Testpartitionen unterteilt werden. In diesem Versuch kommt sowohl eine einfache Partitionierung in Trainings- und Testdaten als auch eine Kreuzvalidierung zum Einsatz ([KI-Vorlesung](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/Einfuehrung_Kuenstliche_Intelligenz/WS1516/06_PartLernen1.pdf)). Machen Sie sich mit dem Prinzip der Kreuzvalidierung (Abbildung unten) vertraut.\n",
    "\n",
    "5. Den meisten Machine Learning-Algorithmen können kategoriale Parameter nicht direkt übergeben werden. Diese Parameter werden typisch *One-Hot* encodiert. Machen Sie sich mit diesem Prinzip vertraut.\n",
    "\n",
    "6. In diesem Versuch soll ein Multilayer-Perzeptron (MLP) als Klassifikator eingesetzt werden. Machen Sie sich mit dem MLP vertraut. [KI-Vorlesung](https://www.mi.hdm-stuttgart.de/mib/studium/intern/skripteserver/skripte/Einfuehrung_Kuenstliche_Intelligenz/WS1516/09_PartLernen4.pdf), [MLP in Scikit-Learn](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "**Prinzip überwachtes Lernen und Validierung:**\n",
    "![Prinzip überwachtes Lernen](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/SupervisedLarningSchemaValidation.png \"Überwachtes Lernen Schema\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Prinzip der 10-fachen Kreuzvalidierung:**\n",
    "\n",
    "![Kreuzvalidierung](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/CrossValidation.jpg \"Cross-Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durchführung\n",
    "## Datenzugriff\n",
    "Die Daten sind in insgesamt 7 .csv Files organisiert (das File sample_submission.csv wird nicht benötigt). Die einzelnen .csv Dateien sind z.T. sehr groß. In diesem Fall bietet es sich an, nicht das ganze File in einen Pandas-Dataframe zu laden, sondern das .csv-File zunächst in eine Datenbank zu schreiben und dann auf diese dediziert zuzugreifen. \n",
    "\n",
    "_Tipp:_ Mit der auf dem Skripteserver bereitgestellten Datei _brandMap.txt_, können die chinesischen Schriftzeichen in den Markennamen übersetzt werden.\n",
    "\n",
    "**Aufgaben:**\n",
    "\n",
    "1. Lesen Sie jedes der .csv Files in chunks von jeweils ca. 20000 Zeilen in einen Pandas Dataframe ein und schreiben Sie die Daten chunk für chunk in eine SQLite Database. Für das Einlesen ist die Pandas-Methode [read_csv()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) mit dem Parameter _chunksize_ zu verwenden. Für das schreiben der Daten aus dem Pandas Dataframe in die SQLite Datenbank ist die Pandas-Methode [to_sql()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html) zu verwenden. Für jedes .csv File soll in der SQLite-DB eine eigene Tabelle angelegt werden. Als DB-connector soll eine engine-Instanz des _SQLAlchemy_-Pakets mit der Methode create\\_engine() angelegt werden. Siehe z.B. [SQLAlchemy Doku](http://docs.sqlalchemy.org/en/latest/core/engines.html).\n",
    "\n",
    "2. Nachdem alle Tabellen der DB angelegt sind, sollen aus jeder Tabelle die ersten 10 Zeilen mit der Pandas Methode [read_sql_query()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_query.html) abgefragt und angezeigt werden. Ausserdem ist für jede Tabelle die Größe (Anzahl der Zeilen) auszugeben.\n",
    "3. Wie viele verschiedene devices befinden sich in der Tabelle, welche die Daten aus gender\\_age\\_train.csv enthält?\n",
    "4. Wie viele verschiedene devices befinden sich in der Tabelle, welche die Daten aus events.csv enthält?\n",
    "5. Wie viele verschiedene devices kommen in beiden dieser Tabellen vor? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stored phone_brand_device_model\n",
      "stored gender_age_test\n",
      "stored app_labels\n",
      "stored label_categories\n",
      "stored events\n",
      "stored app_events\n",
      "stored gender_age_train\n",
      "stored sample_submission\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "import glob\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///MobileUser.db')\n",
    "\n",
    "#Connect sqlite\n",
    "conn = engine.connect()\n",
    "\n",
    "def readinchunks(tablename,conn,filename,chunksize):\n",
    "    for chunk in pd.read_csv(filename, chunksize=20000, iterator=True, encoding='utf-8'):\n",
    "        chunk.to_sql(name=tablename, con=conn, if_exists='append')\n",
    "    print 'stored', tablename\n",
    "        \n",
    "#Read all CSVs\n",
    "chunksize = 20000\n",
    "path = \"Ressource/Data/GenderAgePrediction/*.csv\"\n",
    "for filename in glob.glob(path):\n",
    "    \n",
    "    rawdata = pd.DataFrame()\n",
    "    pd.read_csv(filename)\n",
    "    \n",
    "    tablename = filename.replace('.csv','').split('/')[-1]\n",
    "    \n",
    "    readinchunks(tablename,conn,filename,chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table: app_events\n",
      "count: 32473067\n",
      "   index  event_id               app_id  is_installed  is_active\n",
      "0      0         2  5927333115845830913             1          1\n",
      "1      1         2 -5720078949152207372             1          0\n",
      "2      2         2 -1633887856876571208             1          0\n",
      "3      3         2  -653184325010919369             1          1\n",
      "4      4         2  8693964245073640147             1          1\n",
      "5      5         2  4775896950989639373             1          1\n",
      "6      6         2 -8022267440849930066             1          0\n",
      "7      7         2  9112463267739110219             1          0\n",
      "8      8         2 -3725672010020973973             1          0\n",
      "9      9         2  7167114343576723123             1          1\n",
      "\n",
      "\n",
      "table: app_labels\n",
      "count: 459943\n",
      "   index               app_id  label_id\n",
      "0      0  7324884708820027918       251\n",
      "1      1 -4494216993218550286       251\n",
      "2      2  6058196446775239644       406\n",
      "3      3  6058196446775239644       407\n",
      "4      4  8694625920731541625       406\n",
      "5      5  8694625920731541625       407\n",
      "6      6  1977658975649789753       406\n",
      "7      7  1977658975649789753       407\n",
      "8      8  7311663864768030840       256\n",
      "9      9  5902120154267999338       256\n",
      "\n",
      "\n",
      "table: events\n",
      "count: 3252950\n",
      "   index  event_id            device_id            timestamp  longitude  \\\n",
      "0      0         1    29182687948017175  2016-05-01 00:55:25     121.38   \n",
      "1      1         2 -6401643145415154744  2016-05-01 00:54:12     103.65   \n",
      "2      2         3 -4833982096941402721  2016-05-01 00:08:05     106.60   \n",
      "3      3         4 -6815121365017318426  2016-05-01 00:06:40     104.27   \n",
      "4      4         5 -5373797595892518570  2016-05-01 00:07:18     115.88   \n",
      "5      5         6  1476664663289716375  2016-05-01 00:27:21       0.00   \n",
      "6      6         7  5990807147117726237  2016-05-01 00:15:13     113.73   \n",
      "7      7         8  1782450055857303792  2016-05-01 00:15:35     113.94   \n",
      "8      8         9 -2073340001552902943  2016-05-01 00:15:33       0.00   \n",
      "9      9        10 -8195816569128397698  2016-05-01 00:41:31     119.34   \n",
      "\n",
      "   latitude  \n",
      "0     31.24  \n",
      "1     30.97  \n",
      "2     29.70  \n",
      "3     23.28  \n",
      "4     28.66  \n",
      "5      0.00  \n",
      "6     23.00  \n",
      "7     34.70  \n",
      "8      0.00  \n",
      "9     26.04  \n",
      "\n",
      "\n",
      "table: gender_age_test\n",
      "count: 112071\n",
      "   index            device_id\n",
      "0      0  1002079943728939269\n",
      "1      1 -1547860181818787117\n",
      "2      2  7374582448058474277\n",
      "3      3 -6220210354783429585\n",
      "4      4 -5893464122623104785\n",
      "5      5 -7560708697029818408\n",
      "6      6   289797889702373958\n",
      "7      7  -402874006399730161\n",
      "8      8  5751283639860028129\n",
      "9      9  -848943298935149395\n",
      "\n",
      "\n",
      "table: gender_age_train\n",
      "count: 74645\n",
      "   index            device_id gender  age agegroup\n",
      "0      0 -8076087639492063270      M   35   M32-38\n",
      "1      1 -2897161552818060146      M   35   M32-38\n",
      "2      2 -8260683887967679142      M   35   M32-38\n",
      "3      3 -4938849341048082022      M   30   M29-31\n",
      "4      4   245133531816851882      M   30   M29-31\n",
      "5      5 -1297074871525174196      F   24   F24-26\n",
      "6      6   236877999787307864      M   36   M32-38\n",
      "7      7 -8098239495777311881      M   38   M32-38\n",
      "8      8   176515041953473526      M   33   M32-38\n",
      "9      9  1596610250680140042      F   36   F33-42\n",
      "\n",
      "\n",
      "table: label_categories\n",
      "count: 930\n",
      "   index  label_id              category\n",
      "0      0         1                  None\n",
      "1      1         2        game-game type\n",
      "2      2         3      game-Game themes\n",
      "3      3         4        game-Art Style\n",
      "4      4         5     game-Leisure time\n",
      "5      5         6   game-Cutting things\n",
      "6      6         7    game-Finding fault\n",
      "7      7         8  game-stress reliever\n",
      "8      8         9              game-pet\n",
      "9      9        10           game-Answer\n",
      "\n",
      "\n",
      "table: phone_brand_device_model\n",
      "count: 187245\n",
      "   index            device_id phone_brand   device_model\n",
      "0      0 -8890648629457979026          小米             红米\n",
      "1      1  1277779817574759137          小米           MI 2\n",
      "2      2  5137427614288105724          三星      Galaxy S4\n",
      "3      3  3669464369358936369       SUGAR           时尚手机\n",
      "4      4 -5019277647504317457          三星  Galaxy Note 2\n",
      "5      5  3238009352149731868          华为           Mate\n",
      "6      6 -3883532755183027260          小米          MI 2S\n",
      "7      7 -2972199645857147708          华为          G610S\n",
      "8      8 -5827952925479472594          小米    MI One Plus\n",
      "9      9 -8262508968076336275        vivo            S7I\n",
      "\n",
      "\n",
      "table: sample_submission\n",
      "count: 112071\n",
      "   index            device_id    F23-  F24-26  F27-28  F29-32  F33-42    F43+  \\\n",
      "0      0  1002079943728939269  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "1      1 -1547860181818787117  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "2      2  7374582448058474277  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "3      3 -6220210354783429585  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "4      4 -5893464122623104785  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "5      5 -7560708697029818408  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "6      6   289797889702373958  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "7      7  -402874006399730161  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "8      8  5751283639860028129  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "9      9  -848943298935149395  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833   \n",
      "\n",
      "     M22-  M23-26  M27-28  M29-31  M32-38    M39+  \n",
      "0  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "1  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "2  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "3  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "4  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "5  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "6  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "7  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "8  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "9  0.0833  0.0833  0.0833  0.0833  0.0833  0.0833  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "tablelist = list(conn.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\"))\n",
    "for row in tablelist:\n",
    "    print 'table:', row['name']\n",
    "    print 'count:', conn.execute(\"SELECT MAX(_ROWID_) FROM \"  + row['name']).fetchone()[0]\n",
    "    print pd.read_sql_query(\"select * from \" + row['name'] + \" limit 10\", conn)\n",
    "    print '\\n'\n",
    "\n",
    "#for filename in glob.glob(path):\n",
    "#    tablename = filename.replace('.csv','').split('/')[-1]\n",
    "\n",
    "#    print pd.read_sql_query(\"select * from app_labels limit 10\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "device_ids = conn.execute(\"SELECT DISTINCT count(device_id) FROM gender_age_train ORDER BY device_id;\").fetchone()[0]\n",
    "print device_ids\n",
    "\n",
    "#for id in device_ids:\n",
    "#    print id[0]\n",
    "\n",
    "#4\n",
    "\n",
    "device_ids = conn.execute(\"SELECT DISTINCT count(device_id) FROM gender_age_train ORDER BY device_id;\").fetchone()[0]\n",
    "print device_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74645\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deskriptive Statistik\n",
    "\n",
    "In der obigen Teilaufgabe sollte die Schnittstelle zwischen Pandas Dataframes und Datenbanken (hier SQLite) demonstriert werden. Diese Art von Datenhandling eignet sich besonders im Fall sehr großer Datenmengen, die nicht im Arbeitsspeicher gehalten werden können. Die Dateien in diesem Versuch sind tatsächlich nicht so groß, dass sie nicht als ganzes in Pandas-Dataframes geladen werden könnten. In allen folgenden Teilversuchen ist Ihnen freigestellt, ob Sie mit der Datenbank-Variante oder der in-memory Variante (alle Daten im Pandas-Dataframe) arbeiten.\n",
    "\n",
    "### Verteilung der User über die Gender-Age-Gruppen\n",
    "\n",
    "Die Menge aller User wird in 12 verschiedene Gender-Age-Groups unterteilt. Bestimmen Sie die Verteilung der User in der gender\\_age\\_train-Tabelle über diese 12 Gruppen und viusalisieren Sie diese Verteilung in einem [Matplolib Bar Chart](http://matplotlib.org/api/pyplot_api.html). \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der User über die Smartphone-Marken\n",
    "\n",
    "1. Bestimmen Sie die Anzahl der verschiedenen Devices und die Anzahl der verschiedenen Marken in der Tabelle *phone\\_brand\\_device\\_model*.\n",
    "\n",
    "2. Fügen Sie dem Pandas Dataframe mit der *gender_age_train*-Tabelle eine Spalte _brand_ hinzu und schreiben Sie in diese Spalte den Markennamen des zur jeweiligen Zeile gehörenden Device.\n",
    "3. Schreiben Sie den um den Markennamen erweiterten Dataframe in ein File *gender\\_age\\_brand\\_train.csv*.\n",
    "4. Bestimmmen Sie mittels der Dataframe-Methode *value_counts()* die Anzahl der Devices pro Marke. \n",
    "5. Stellen Sie diese Verteilung der Devices über die Marken für die 20 häufigsten Marken grafisch mit einem *Matplotlib-bar-chart dar.*\n",
    "6. Untersuchen Sie jetzt die Verteilung der Devices über die Marken pro Gender-Age-Group. Gibt es eine Korrelation zwischen Gender-Age-Group und Häufigkeit der Marken? Überlegen sie sich eine Visualisierung mit der eine derartige Korrelation bestätigt oder widerlegt werden kann. Implementieren Sie die Visualisierung und zeigen Sie anhand dieser Visualisierung mögliche Korrelationen zwischen Gender-Age-Group und Markenhäufigkeit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatio-Temporale Analyse des Verhaltens einzelner User\n",
    "\n",
    "1. Wählen Sie aus der *events*-Tabelle ein Device, für das mindestens 30 events mit zugewiesenen Geokordinaten vorliegen.\n",
    "2. Stellen Sie alle Aufenthaltsorte des zu diesem Device gehörenden Users in einer *gmaps-Heatmap* dar. Informationen hierzu finden Sie in der [gmaps-Doku]( https://github.com/pbugnion/gmaps). Für den Zugriff auf gmaps benötigen Sie einen Google-API-Key (siehe [gmaps authentication](http://jupyter-gmaps.readthedocs.io/en/latest/authentication.html))\n",
    "3. Clustern Sie die 2-dimensionalen Geodaten des ausgewählten Users mit dem [DBSCAN-Algorithmus von scikit-learn](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html). Die Parameter des Algorithmus sind so zu wählen, dass wesentlich unterschiedliche Orte des Users in unterschiedlichen Clustern landen.\n",
    "4. Stellen Sie den zeitlichen Verlauf der Events des ausgewählten Users im unten dargestellten Stil visuell dar. Auf der horizontalen Achse ist die Zeit relativ zur Zeit des ersten Events in Sekunden dargestellt. Auf der vertikalen Achse ist die Anzahl der bisherigen Events des Users aufgetragen. Mit jedem Event wird der Wert auf der vertikalen Achse um 1 erhöht. Die Farbe der Marker im Graph gibt den Aufenthaltscluster an. Für jeden in der vorigen Teilaufgabe gefundenen Aufenthaltscluster wird eine unterschiedliche Farbe benutzt (Im Beispiel unten wurden nur 2 Cluster gefunden). Diskutieren Sie das Verhalten des Users anhand des Graphs.\n",
    "\n",
    "![Abbildung Zeitliches Auftreten der Events](https://www.hdm-stuttgart.de/~maucher/ipnotebooks/DataMining//Bilder/tempbehave.PNG \"Events über der Zeit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anmerkung: In den vorigen Aufgaben war das Vorgehen relativ konkret vorgegeben. In den folgenden Aufgaben sind die Vorgaben bewußt knapp gehalten. Ihre Kreativität ist gefragt.\n",
    "\n",
    "1. Überlegen Sie sich aus welchen Merkmalen, die aus den vorhandenen Daten extrahiert werden können, möglichst gut die Gender-Age-Group vorhergesagt werden kann.\n",
    "2. Extahieren Sie diese Merkmale aus den Daten für möglichst viele (mindestens 20.000) User (devices) aus der Tabelle *gender_age_train*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender-Age-Group Prediction\n",
    "1. In der vorigen Aufgabe wurde für jeden User (device) ein Merkmalsvektor berechnet. Die Menge der Merkmalsvektoren aller User aus der Tabelle *gender_age_train* bildet die Eingabe-Matrix $X$ für die Klassifikationsalgorithmen. Die Soll-Ausgabe Vektor $y$ wird durch die *gender_age_group* der User gebildet. Bringen Sie die Matrix aller Eingabevektoren in eine Form, in der\n",
    "    * alle kategorialen Parameter *One-Hot*-encodiert sind [Scikit-Learn One-Hot-Encoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder).\n",
    "    * alle Merkmale eine Varianz von 1 aufweisen. Benützen Sie hierfür die [Scikit-Learn Methode scale](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale).\n",
    "2. Teilen Sie die Datensätze in $X$ und $y$ in eine Trainings- und eine Testpartition auf - im Verhältnis $3/4$ für Training, $1/4$ für Test. \n",
    "3. Trainieren Sie mit der Trainingspartition ein [Multilayer-Perzeptron](http://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "4. Testen Sie das gelernte Modell mit der Testpartition. Für die Auswertung sollte die [Accurracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) und die [Confusion Matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) bestimmt werden. Finden Sie eine Parametereinstellung, die zu einer möglichst guten Accuracy führt. Interpretieren Sie die Confusion Matrix.\n",
    "5. Wenden Sie nun eine [5-fache Kreuzvalidierung](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) an und bestimmen Sie damit eine möglichst gute Parametereinstellung.\n",
    "6. Mit welchen Parametern erzielen Sie die beste Accurracy? Wie hoch ist diese dann? Diskutieren Sie das Ergebnis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
